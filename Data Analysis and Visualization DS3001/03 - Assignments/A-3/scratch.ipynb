{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>TF 1</th>\n",
       "      <th>TF 2</th>\n",
       "      <th>TF 3</th>\n",
       "      <th>TF 4</th>\n",
       "      <th>TF 5</th>\n",
       "      <th>IDF</th>\n",
       "      <th>TF*IDF 1</th>\n",
       "      <th>TF*IDF 2</th>\n",
       "      <th>TF*IDF 3</th>\n",
       "      <th>TF*IDF 4</th>\n",
       "      <th>TF*IDF 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>2/6</td>\n",
       "      <td>2/6</td>\n",
       "      <td>2/6</td>\n",
       "      <td>2/5</td>\n",
       "      <td>2/6</td>\n",
       "      <td>log(5/5) = 0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mat</td>\n",
       "      <td>1/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/5</td>\n",
       "      <td>1/6</td>\n",
       "      <td>log(5/2) = 0.398</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat</td>\n",
       "      <td>1/6</td>\n",
       "      <td>1/6</td>\n",
       "      <td>1/6</td>\n",
       "      <td>0/5</td>\n",
       "      <td>0/6</td>\n",
       "      <td>log(5/3) = 0.222</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/5</td>\n",
       "      <td>1/6</td>\n",
       "      <td>log(5/1) = 0.699</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>floor</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/5</td>\n",
       "      <td>1/6</td>\n",
       "      <td>log(5/1) = 0.699</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>on</td>\n",
       "      <td>1/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/5</td>\n",
       "      <td>1/6</td>\n",
       "      <td>log(5/2) = 0.398</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chased</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>1/5</td>\n",
       "      <td>0/6</td>\n",
       "      <td>log(5/1) = 0.699</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>flew</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>1/6</td>\n",
       "      <td>0/5</td>\n",
       "      <td>0/6</td>\n",
       "      <td>log(5/1) = 0.699</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>over</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>1/6</td>\n",
       "      <td>0/5</td>\n",
       "      <td>0/6</td>\n",
       "      <td>log(5/1) = 0.699</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sat</td>\n",
       "      <td>1/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/5</td>\n",
       "      <td>0/6</td>\n",
       "      <td>log(5/1) = 0.699</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dog</td>\n",
       "      <td>0/6</td>\n",
       "      <td>1/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>1/5</td>\n",
       "      <td>0/6</td>\n",
       "      <td>log(5/2) = 0.398</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>at</td>\n",
       "      <td>0/6</td>\n",
       "      <td>1/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/5</td>\n",
       "      <td>0/6</td>\n",
       "      <td>log(5/1) = 0.699</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bird</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>1/6</td>\n",
       "      <td>1/5</td>\n",
       "      <td>0/6</td>\n",
       "      <td>log(5/2) = 0.398</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>barked</td>\n",
       "      <td>0/6</td>\n",
       "      <td>1/6</td>\n",
       "      <td>0/6</td>\n",
       "      <td>0/5</td>\n",
       "      <td>0/6</td>\n",
       "      <td>log(5/1) = 0.699</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word TF 1 TF 2 TF 3 TF 4 TF 5               IDF  TF*IDF 1  TF*IDF 2  \\\n",
       "0      the  2/6  2/6  2/6  2/5  2/6    log(5/5) = 0.0     0.000     0.000   \n",
       "1      mat  1/6  0/6  0/6  0/5  1/6  log(5/2) = 0.398     0.066     0.000   \n",
       "2      cat  1/6  1/6  1/6  0/5  0/6  log(5/3) = 0.222     0.037     0.037   \n",
       "3       is  0/6  0/6  0/6  0/5  1/6  log(5/1) = 0.699     0.000     0.000   \n",
       "4    floor  0/6  0/6  0/6  0/5  1/6  log(5/1) = 0.699     0.000     0.000   \n",
       "5       on  1/6  0/6  0/6  0/5  1/6  log(5/2) = 0.398     0.066     0.000   \n",
       "6   chased  0/6  0/6  0/6  1/5  0/6  log(5/1) = 0.699     0.000     0.000   \n",
       "7     flew  0/6  0/6  1/6  0/5  0/6  log(5/1) = 0.699     0.000     0.000   \n",
       "8     over  0/6  0/6  1/6  0/5  0/6  log(5/1) = 0.699     0.000     0.000   \n",
       "9      sat  1/6  0/6  0/6  0/5  0/6  log(5/1) = 0.699     0.116     0.000   \n",
       "10     dog  0/6  1/6  0/6  1/5  0/6  log(5/2) = 0.398     0.000     0.066   \n",
       "11      at  0/6  1/6  0/6  0/5  0/6  log(5/1) = 0.699     0.000     0.116   \n",
       "12    bird  0/6  0/6  1/6  1/5  0/6  log(5/2) = 0.398     0.000     0.000   \n",
       "13  barked  0/6  1/6  0/6  0/5  0/6  log(5/1) = 0.699     0.000     0.116   \n",
       "\n",
       "    TF*IDF 3  TF*IDF 4  TF*IDF 5  \n",
       "0      0.000      0.00     0.000  \n",
       "1      0.000      0.00     0.066  \n",
       "2      0.037      0.00     0.000  \n",
       "3      0.000      0.00     0.116  \n",
       "4      0.000      0.00     0.116  \n",
       "5      0.000      0.00     0.066  \n",
       "6      0.000      0.14     0.000  \n",
       "7      0.116      0.00     0.000  \n",
       "8      0.116      0.00     0.000  \n",
       "9      0.000      0.00     0.000  \n",
       "10     0.000      0.08     0.000  \n",
       "11     0.000      0.00     0.000  \n",
       "12     0.066      0.08     0.000  \n",
       "13     0.000      0.00     0.000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Sentences\n",
    "Sentence1 = \"The cat sat on the mat.\"\n",
    "Sentence2 = \"The dog barked at the cat.\"\n",
    "Sentence3 = \"The bird flew over the cat.\"\n",
    "Sentence4 = \"The dog chased the bird.\"\n",
    "Sentence5 = \"The mat is on the floor.\"\n",
    "\n",
    "# Convert sentences to lowercase and split into words\n",
    "def tokenize(sentence):\n",
    "    sentence = sentence.replace(\".\", \"\")\n",
    "    return sentence.lower().split()\n",
    "\n",
    "# Tokenize all sentences\n",
    "words_1, words_2, words_3, words_4, words_5 = tokenize(Sentence1), tokenize(Sentence2), tokenize(Sentence3), tokenize(Sentence4), tokenize(Sentence5)\n",
    "\n",
    "# Vocabulary (unique words across all sentences)\n",
    "vocabulary = list(set(words_1 + words_2 + words_3 + words_4 + words_5))\n",
    "\n",
    "# Initialize a dictionary to hold term frequencies (TF) for all sentences\n",
    "tf_data = {'Word': vocabulary}\n",
    "\n",
    "# Calculate TF for each sentence\n",
    "def calculate_tf(sentence_words, vocab):\n",
    "    tf = []\n",
    "    sentence_len = len(sentence_words)\n",
    "    for word in vocab:\n",
    "        tf.append(f\"{sentence_words.count(word)}/{sentence_len}\")  # Format as 'count/total'\n",
    "    return tf\n",
    "\n",
    "# Calculate raw TF for numerical TF*IDF calculation\n",
    "def calculate_raw_tf(sentence_words, vocab):\n",
    "    tf = []\n",
    "    sentence_len = len(sentence_words)\n",
    "    for word in vocab:\n",
    "        tf.append(sentence_words.count(word) / sentence_len)\n",
    "    return tf\n",
    "\n",
    "# Calculate TF for all sentences\n",
    "tf_data['TF 1'] = calculate_tf(words_1, vocabulary)\n",
    "tf_data['TF 2'] = calculate_tf(words_2, vocabulary)\n",
    "tf_data['TF 3'] = calculate_tf(words_3, vocabulary)\n",
    "tf_data['TF 4'] = calculate_tf(words_4, vocabulary)\n",
    "tf_data['TF 5'] = calculate_tf(words_5, vocabulary)\n",
    "\n",
    "# Calculate raw TF for TF-IDF\n",
    "raw_tf_1 = calculate_raw_tf(words_1, vocabulary)\n",
    "raw_tf_2 = calculate_raw_tf(words_2, vocabulary)\n",
    "raw_tf_3 = calculate_raw_tf(words_3, vocabulary)\n",
    "raw_tf_4 = calculate_raw_tf(words_4, vocabulary)\n",
    "raw_tf_5 = calculate_raw_tf(words_5, vocabulary)\n",
    "\n",
    "# Calculate Document Frequency (DF)\n",
    "def calculate_df(vocab, sentences):\n",
    "    df = []\n",
    "    num_sentences = len(sentences)\n",
    "    for word in vocab:\n",
    "        count = sum([1 for sentence in sentences if word in sentence])\n",
    "        df.append(count)\n",
    "    return df\n",
    "\n",
    "# Calculate Inverse Document Frequency (IDF) with log transformation\n",
    "def calculate_idf(df, num_docs):\n",
    "    return [f\"log({num_docs}/{count}) = {0 if count == 0 else round(math.log10(num_docs / count), 3)}\" for count in df]\n",
    "\n",
    "# Calculate raw IDF for numerical TF*IDF calculation\n",
    "def calculate_raw_idf(df, num_docs):\n",
    "    return [0 if count == 0 else math.log10(num_docs / count) for count in df]\n",
    "\n",
    "# Calculate DF and IDF\n",
    "sentences = [words_1, words_2, words_3, words_4, words_5]\n",
    "df = calculate_df(vocabulary, sentences)\n",
    "idf = calculate_idf(df, len(sentences))\n",
    "raw_idf = calculate_raw_idf(df, len(sentences))\n",
    "\n",
    "# Add IDF to the dataframe\n",
    "tf_data['IDF'] = idf\n",
    "\n",
    "# Calculate TF * IDF for all sentences\n",
    "tf_data['TF*IDF 1'] = [round(a * i, 3) for a, i in zip(raw_tf_1, raw_idf)]\n",
    "tf_data['TF*IDF 2'] = [round(b * i, 3) for b, i in zip(raw_tf_2, raw_idf)]\n",
    "tf_data['TF*IDF 3'] = [round(c * i, 3) for c, i in zip(raw_tf_3, raw_idf)]\n",
    "tf_data['TF*IDF 4'] = [round(d * i, 3) for d, i in zip(raw_tf_4, raw_idf)]\n",
    "tf_data['TF*IDF 5'] = [round(e * i, 3) for e, i in zip(raw_tf_5, raw_idf)]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(tf_data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1: Bag of Words Vectors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>are</th>\n",
       "      <th>around</th>\n",
       "      <th>at</th>\n",
       "      <th>earth</th>\n",
       "      <th>east</th>\n",
       "      <th>in</th>\n",
       "      <th>moon</th>\n",
       "      <th>night</th>\n",
       "      <th>revolves</th>\n",
       "      <th>rises</th>\n",
       "      <th>sets</th>\n",
       "      <th>stars</th>\n",
       "      <th>sun</th>\n",
       "      <th>the</th>\n",
       "      <th>visible</th>\n",
       "      <th>west</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence 1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence 3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence 4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence 5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            are  around  at  earth  east  in  moon  night  revolves  rises  \\\n",
       "Sentence 1    0       0   0      0     1   1     0      0         0      1   \n",
       "Sentence 2    0       0   0      0     0   1     0      0         0      0   \n",
       "Sentence 3    0       1   0      1     0   0     0      0         1      0   \n",
       "Sentence 4    0       1   0      1     0   0     1      0         1      0   \n",
       "Sentence 5    1       0   1      0     0   0     0      1         0      0   \n",
       "\n",
       "            sets  stars  sun  the  visible  west  \n",
       "Sentence 1     0      0    1    2        0     0  \n",
       "Sentence 2     1      0    1    2        0     1  \n",
       "Sentence 3     0      0    1    2        0     0  \n",
       "Sentence 4     0      0    0    2        0     0  \n",
       "Sentence 5     0      1    0    1        1     0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Sentences\n",
    "Sentence1 = 'The sun rises in the east.'\n",
    "Sentence2 = 'The sun sets in the west.'\n",
    "Sentence3 = 'The earth revolves around the sun.'\n",
    "Sentence4 = 'The moon revolves around the earth.'\n",
    "Sentence5 = 'The stars are visible at night.'\n",
    "\n",
    "# Convert sentences to lowercase and split into words (remove punctuation as well)\n",
    "def tokenize(sentence):\n",
    "    sentence = sentence.replace(\".\", \"\")  # Remove period\n",
    "    return sentence.lower().split()\n",
    "\n",
    "# Tokenize all sentences\n",
    "sentences = [Sentence1, Sentence2, Sentence3, Sentence4, Sentence5]\n",
    "tokenized_sentences = [tokenize(sentence) for sentence in sentences]\n",
    "print('tokenized_sentences', tokenized_sentences)\n",
    "\n",
    "# Create the vocabulary (unique words across all sentences)\n",
    "vocabulary = sorted(list(set([word for sentence in tokenized_sentences for word in sentence])))\n",
    "print('vocabulary', vocabulary)\n",
    "\n",
    "# Create the Bag of Words (BoW) vector for each sentence\n",
    "def create_bow_vector(sentence_words, vocab):\n",
    "    vector = [sentence_words.count(word) for word in vocab]\n",
    "    return vector\n",
    "\n",
    "# Create the BoW vectors for all sentences\n",
    "bow_vectors = [create_bow_vector(sentence, vocabulary) for sentence in tokenized_sentences]\n",
    "\n",
    "# Convert BoW vectors to a DataFrame for a cleaner view\n",
    "df_bow = pd.DataFrame(bow_vectors, columns=vocabulary, index=[f'Sentence {i+1}' for i in range(len(sentences))])\n",
    "\n",
    "# Display the Bag of Words vectors\n",
    "print(\"Part 1: Bag of Words Vectors\")\n",
    "df_bow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Part 2: Cosine Similarity\n",
      "Cosine Similarity between Sentence 1 and Sentence 2: 0.750\n",
      "Cosine Similarity between Sentence 1 and Sentence 5: 0.289\n",
      "Cosine Similarity between Sentence 3 and Sentence 4: 0.875\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate cosine similarity\n",
    "def cosine_sim(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "# Calculate cosine similarities\n",
    "cos_sim_1_2 = cosine_sim(bow_vectors[0], bow_vectors[1])  # Sentence 1 and Sentence 2\n",
    "cos_sim_1_5 = cosine_sim(bow_vectors[0], bow_vectors[4])  # Sentence 1 and Sentence 5\n",
    "cos_sim_3_4 = cosine_sim(bow_vectors[2], bow_vectors[3])  # Sentence 3 and Sentence 4\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nPart 2: Cosine Similarity\")\n",
    "print(f\"Cosine Similarity between Sentence 1 and Sentence 2: {cos_sim_1_2:.3f}\")\n",
    "print(f\"Cosine Similarity between Sentence 1 and Sentence 5: {cos_sim_1_5:.3f}\")\n",
    "print(f\"Cosine Similarity between Sentence 3 and Sentence 4: {cos_sim_3_4:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression with handcrafted features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['What', 'truly', 'sets', 'this', 'book', 'apart', 'is', 'the', 'depth', 'of', 'emotion', 'it', 'evokes', '.', 'I', 'laughed', ',', 'I', 'cried', ',', 'and', 'I', 'felt', 'my', 'heart', 'race', 'with', 'anticipation', 'during', 'the', 'most', 'gripping', 'moments', '.', 'The', 'themes', 'explored', 'in', 'this', 'story', 'are', 'both', 'timely', 'and', 'timeless', ',', 'touching', 'on', 'the', 'complexities', 'of', 'human', 'nature', ',', 'the', 'power', 'of', 'friendship', ',', 'and', 'the', 'triumph', 'of', 'hope', 'in', 'the', 'face', 'of', 'adversity', '.', 'I', 'cannot', 'recommend', 'this', 'book', 'enough', '.', 'It', 'is', 'a', 'masterpiece', 'of', 'modern', 'literature', 'that', 'deserves', 'a', 'place', 'on', 'every', 'bookshelf', '.', 'Whether', 'you', \"'\", 're', 'a', 'seasoned', 'reader', 'or', 'just', 'looking', 'for', 'a', 'captivating', 'story', 'to', 'dive', 'into', ',', 'this', 'book', 'will', 'not', 'disappoint', '.', 'Prepare', 'to', 'be', 'transported', 'on', 'an', 'unforgettable', 'journey', 'that', 'will', 'stay', 'with', 'you', 'for', 'a', 'lifetime', '.'] \n",
      " 133\n",
      "x1 (log of Word count): 4.890349128221754\n",
      "x2 (number of punctuations): 14\n",
      "x3 (number of positive words): 11\n",
      "x4 (number of negative words): 7\n",
      "x5 (ratio of capitalized words to total words): 0.06766917293233082\n"
     ]
    }
   ],
   "source": [
    "text_passage=\"\"\"What truly sets this book apart is the depth of emotion it evokes. I laughed, I cried, and I\n",
    "felt my heart race with anticipation during the most gripping moments. The themes\n",
    "explored in this story are both timely and timeless, touching on the complexities of\n",
    "human nature, the power of friendship, and the triumph of hope in the face of adversity. I\n",
    "cannot recommend this book enough. It is a masterpiece of modern literature that\n",
    "deserves a place on every bookshelf. Whether you're a seasoned reader or just looking\n",
    "for a captivating story to dive into, this book will not disappoint. Prepare to be\n",
    "transported on an unforgettable journey that will stay with you for a lifetime.\"\"\"\n",
    "\n",
    "# Each training observation would be represented by the 5 crafted features shown in the following table.\n",
    "\n",
    "# Features\n",
    "\n",
    "# 1. log of Word count\n",
    "\n",
    "# 2. number of punctuations (period, comma, apostrophe, quotation, question, exclamation, colon,\n",
    "# etc.)\n",
    "\n",
    "# 3. number of positive words\n",
    "\n",
    "# 4. number of negative words\n",
    "\n",
    "# 5. ratio of capitalized words (words starting with capital letter) to total words\n",
    "\n",
    "# Dictionary for positive and negative words is given below:\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "\n",
    "# Dictionary for positive and negative words\n",
    "Positivedictionary = ['Good', 'unforgettable', 'masterpiece', 'depth', 'laughed', 'timeless', 'captivating', 'happy', 'triumph', 'friendship', 'modern', 'lifetime', 'gripping', 'enjoy', 'proud']\n",
    "Negativedictionary = ['Not', 'cannot', 'disappoint', 'sad', 'cried', 'hopeless', 'adversity', 'waste', 'weird', 'complexities', 'anger', 'seasoned', 'anticipation', 'bad', 'rude']\n",
    "\n",
    "# Split text while keeping punctuation\n",
    "tokens = re.findall(r'\\b\\w+\\b|[!\"#$%&\\'()*+,-./:;<=>?@[\\]^_`{|}~]', text_passage)\n",
    "print(string.punctuation)\n",
    "# Calculate features\n",
    "x1 = math.log(len(tokens))\n",
    "x2 = sum(text_passage.count(p) for p in string.punctuation)\n",
    "x3 = sum([text_passage.count(word) for word in Positivedictionary])\n",
    "x4 = sum([text_passage.count(word) for word in Negativedictionary])\n",
    "x5 = sum([1 for word in tokens if word[0].isupper()]) / len(tokens)\n",
    "\n",
    "# Print tokens to verify\n",
    "print(tokens,'\\n',len(tokens))\n",
    "\n",
    "# Print feature values\n",
    "print(f\"x1 (log of Word count): {x1}\")\n",
    "print(f\"x2 (number of punctuations): {x2}\")\n",
    "print(f\"x3 (number of positive words): {x3}\")\n",
    "print(f\"x4 (number of negative words): {x4}\")\n",
    "print(f\"x5 (ratio of capitalized words to total words): {x5}\")\n",
    "# Your task is to update the weights once, using a stochastic gradient descent algorithm. Assume all initial\n",
    "# weights set to 0.2 and learning rate Î±=0.5. Also compute the Loss function: binary cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capitalized Words: ['What', 'I', 'I', 'I', 'The', 'I', 'It', 'Whether', 'Prepare']\n",
      "Count of Capitalized Words: 9\n"
     ]
    }
   ],
   "source": [
    "# Extract capitalized words\n",
    "capitalized_words = [word for word in tokens if word[0].isupper()]\n",
    "\n",
    "# Count the capitalized words\n",
    "capitalized_count = len(capitalized_words)\n",
    "\n",
    "# Display the list and count\n",
    "print(\"Capitalized Words:\", capitalized_words)\n",
    "print(\"Count of Capitalized Words:\", capitalized_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2, 0.2, 0.2, 0.2, 0.2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "w= np.array([0.2 for i in range(5)])\n",
    "alpha=0.5\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9993839730694641,\n",
       " 0.0005463499798894489,\n",
       " 0.0006162167530866405,\n",
       " array([0.20150629, 0.20431219, 0.20338815, 0.20215609, 0.20002084]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def binary_cross_entropy_loss(y_pred, y_true):\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "# Compute the predicted value\n",
    "y_pred_true = sigmoid(np.dot(w, np.array([x1, x2, x3, x4, x5])))\n",
    "\n",
    "# weight update\n",
    "w = w - alpha * (y_pred_true - 1) * np.array([x1, x2, x3, x4, x5])\n",
    "\n",
    "loss_slide = 1 - sigmoid(np.dot(w, np.array([x1, x2, x3, x4, x5])))\n",
    "loss = binary_cross_entropy_loss(y_pred_true, 1)\n",
    "\n",
    "y_pred_true, loss_slide, loss, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
