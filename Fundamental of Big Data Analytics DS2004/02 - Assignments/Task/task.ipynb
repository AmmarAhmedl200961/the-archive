{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install MRjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install mrjob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Get Word Count per Day\n",
    "use composite key Map/Reduce\n",
    "\n",
    "<date, word, count>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%file` not found.\n"
     ]
    }
   ],
   "source": [
    "%%file task1.py\n",
    "\n",
    "# file magic to create a file called task1.py\n",
    "# file twitter-data.txt is of format: date, message, location, metadata\n",
    "from mrjob.job import MRJob\n",
    "import re\n",
    "class MRWordFrequencyCount(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        # Split the line into fields \n",
    "        date, message,location,*other_metadata = line.split(',') # Extract the date and message\n",
    "\n",
    "        date = date.strip()\n",
    "\n",
    "        message = message.strip() # Extract words from the message\n",
    "        words = re.findall(r'\\w+', message.lower()) # Emit key-value pairs where the key is a composite key consisting of the date and word, \n",
    "        # and the value is 1\n",
    "\n",
    "        for word in words:\n",
    "\n",
    "            yield (date, word), 1\n",
    "\n",
    "    def reducer(self, key, values): # Aggregate the counts for each word on each date\n",
    "        yield key[0], (key[1], sum(values))\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MRWordFrequencyCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory C:\\Users\\druzm\\AppData\\Local\\Temp\\task1.druzm.20240221.155920.431952\n",
      "Running step 1 of 1...\n",
      "job output is in C:\\Users\\druzm\\AppData\\Local\\Temp\\task1.druzm.20240221.155920.431952\\output\n",
      "Streaming final output from C:\\Users\\druzm\\AppData\\Local\\Temp\\task1.druzm.20240221.155920.431952\\output...\n",
      "Removing temp directory C:\\Users\\druzm\\AppData\\Local\\Temp\\task1.druzm.20240221.155920.431952...\n"
     ]
    }
   ],
   "source": [
    "! python task1.py twitter-data.txt > task1_output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Get total word count\n",
    "re-use the output from Task 1 (word count per day) partially aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting task2.py\n"
     ]
    }
   ],
   "source": [
    "%%file task2.py\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRTotalWordCount(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        _, word_count = line.split('\\t')\n",
    "        word, count = eval(word_count)\n",
    "        yield word, int(count)\n",
    "\n",
    "    def reducer(self, key, counts):\n",
    "        yield key, sum(counts)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRTotalWordCount.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory C:\\Users\\druzm\\AppData\\Local\\Temp\\task2.druzm.20240221.170108.149569\n",
      "Running step 1 of 1...\n",
      "job output is in C:\\Users\\druzm\\AppData\\Local\\Temp\\task2.druzm.20240221.170108.149569\\output\n",
      "Streaming final output from C:\\Users\\druzm\\AppData\\Local\\Temp\\task2.druzm.20240221.170108.149569\\output...\n",
      "Removing temp directory C:\\Users\\druzm\\AppData\\Local\\Temp\\task2.druzm.20240221.170108.149569...\n"
     ]
    }
   ],
   "source": [
    "! python task2.py task1_output.txt > task2_output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('for', 1)\n",
      "('pti', 2)\n",
      "('vote', 1)\n",
      "('wins', 1)\n",
      "('pti', 1)\n",
      "('supporter', 1)\n",
      "('behindtheskipper', 1)\n"
     ]
    }
   ],
   "source": [
    "# mapper test\n",
    "with open('task1_output.txt', 'r') as file:\n",
    "    task1_output = file.readlines()\n",
    "    \n",
    "def mapper_task1_output(line):\n",
    "    _, word_count = line.split('\\t')\n",
    "    word, count = eval(word_count)\n",
    "    return word, int(count)\n",
    "\n",
    "for line in task1_output:\n",
    "    print(mapper_task1_output(line))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
