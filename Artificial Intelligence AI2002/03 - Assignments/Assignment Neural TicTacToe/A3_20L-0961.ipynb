{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing a Neural Network for Tic-Tac-Toe, using numpy only\n",
    "\n",
    "##### Neural Network Architecture:\n",
    "\n",
    "Input Layer: 9 nodes, corresponding to the 9 squares on the Tic-Tac-Toe board.\n",
    "Hidden Layer: 100 nodes, utilizing the sigmoid activation function.\n",
    "Output Layer: 9 nodes, employing the softmax function for a probability distribution over possible moves.\n",
    "Initialization of Weights and Biases:\n",
    "Training Algorithm:\n",
    "\n",
    "\n",
    "Data Generation:\n",
    "\n",
    "Generate training data by employing a self-play strategy or other suitable methods.\n",
    "\n",
    "Initialization:\n",
    "\n",
    "Initialize the weights and biases of the neural network randomly.\n",
    "Gameplay:\n",
    "\n",
    "Play the game of Tic-Tac-Toe using the neural network to make the next move.\n",
    "\n",
    "Training Loop:\n",
    "\n",
    "Repeat the following steps until a stopping criterion is met:\n",
    "\n",
    "If the neural network wins or ties the game, stop training.\n",
    "If the game continues, calculate the error of the neural network's output.\n",
    "\n",
    "Backpropagation:\n",
    "\n",
    "Update the weights and biases of the neural network using the backpropagation algorithm with an appropriate learning rate.\n",
    "\n",
    "Stopping Criterion:\n",
    "\n",
    "Define a specific stopping criterion, such as achieving a certain win rate or reaching a predefined performance threshold.\n",
    "\n",
    "Training Details:\n",
    "\n",
    "Define evaluation metrics, such as win rate and tie rate, to track the neural network's performance during training.\n",
    "\n",
    "Additional Considerations:\n",
    "\n",
    "Implement a mechanism to handle draws during training, specifying how the network will adapt.\n",
    "\n",
    "Include sections on validation and testing to ensure the neural network's generalization to unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ammar\\AppData\\Local\\Temp\\ipykernel_6264\\2806268925.py:83: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit(target_backend =\"cuda\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play against the AI!\n",
      "AI is player 1 and you are player -1\n",
      "If you want to pass move, enter -1 for any row or column\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ammar\\AppData\\Local\\Temp\\ipykernel_6264\\2806268925.py:83: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"train\" failed type inference due to: \u001b[1mUntyped global name 'check_win':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'function'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_6264\\2806268925.py\", line 91:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit(target_backend =\"cuda\")\n",
      "C:\\Users\\ammar\\AppData\\Local\\Temp\\ipykernel_6264\\2806268925.py:83: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"train\" failed type inference due to: \u001b[1m\u001b[1mCannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_6264\\2806268925.py\", line 86:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit(target_backend =\"cuda\")\n",
      "c:\\Users\\ammar\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"train\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_6264\\2806268925.py\", line 83:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\Users\\ammar\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_6264\\2806268925.py\", line 83:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Users\\ammar\\AppData\\Local\\Temp\\ipykernel_6264\\2806268925.py:83: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"train\" failed type inference due to: \u001b[1mUntyped global name 'check_win':\u001b[0m \u001b[1m\u001b[1mCannot determine Numba type of <class 'function'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_6264\\2806268925.py\", line 91:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit(target_backend =\"cuda\")\n",
      "c:\\Users\\ammar\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"train\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_6264\\2806268925.py\", line 86:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\Users\\ammar\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_6264\\2806268925.py\", line 86:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: -1\n",
      "Iteration 1000: 1\n",
      "Iteration 2000: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ammar\\AppData\\Local\\Temp\\ipykernel_6264\\2806268925.py:41: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(x) / np.sum(np.exp(x))\n",
      "C:\\Users\\ammar\\AppData\\Local\\Temp\\ipykernel_6264\\2806268925.py:41: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.exp(x) / np.sum(np.exp(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3000: 1\n",
      "Iteration 4000: -1\n",
      "Iteration 5000: 1\n",
      "Iteration 6000: -1\n",
      "Iteration 7000: -1\n",
      "Iteration 8000: -1\n",
      "Iteration 9000: -1\n",
      "Iteration 10000: 1\n",
      "Iteration 11000: -1\n",
      "Iteration 12000: 1\n",
      "Iteration 13000: 1\n",
      "Iteration 14000: 1\n",
      "Iteration 15000: -1\n",
      "Iteration 16000: 1\n",
      "Iteration 17000: -1\n",
      "Iteration 18000: 1\n",
      "Iteration 19000: -1\n",
      "Iteration 20000: -1\n",
      "Iteration 21000: -1\n",
      "Iteration 22000: -1\n",
      "Iteration 23000: 1\n",
      "Iteration 24000: 1\n",
      "Iteration 25000: -1\n",
      "Iteration 26000: -1\n",
      "Iteration 27000: 1\n",
      "Iteration 28000: -1\n",
      "Iteration 29000: -1\n",
      "Iteration 30000: -1\n",
      "Iteration 31000: 1\n",
      "Iteration 32000: -1\n",
      "Iteration 33000: 1\n",
      "Iteration 34000: 1\n",
      "Iteration 35000: 1\n",
      "Iteration 36000: 1\n",
      "Iteration 37000: -1\n",
      "Iteration 38000: 1\n",
      "Iteration 39000: 1\n",
      "Iteration 40000: 1\n",
      "Iteration 41000: 1\n",
      "Iteration 42000: 1\n",
      "Iteration 43000: -1\n",
      "Iteration 44000: 1\n",
      "Iteration 45000: -1\n",
      "Iteration 46000: 1\n",
      "Iteration 47000: 1\n",
      "Iteration 48000: -1\n",
      "Iteration 49000: -1\n",
      "Iteration 50000: -1\n",
      "Iteration 51000: 1\n",
      "Iteration 52000: -1\n",
      "Iteration 53000: -1\n",
      "Iteration 54000: 1\n",
      "Iteration 55000: -1\n",
      "Iteration 56000: -1\n",
      "Iteration 57000: 1\n",
      "Iteration 58000: 1\n",
      "Iteration 59000: 1\n",
      "Iteration 60000: -1\n",
      "Iteration 61000: 1\n",
      "Iteration 62000: -1\n",
      "Iteration 63000: -1\n",
      "Iteration 64000: 1\n",
      "Iteration 65000: 1\n",
      "Iteration 66000: -1\n",
      "Iteration 67000: -1\n",
      "Iteration 68000: 1\n",
      "Iteration 69000: 1\n",
      "Iteration 70000: -1\n",
      "Iteration 71000: -1\n",
      "Iteration 72000: -1\n",
      "Iteration 73000: 1\n",
      "Iteration 74000: 1\n",
      "Iteration 75000: -1\n",
      "Iteration 76000: 1\n",
      "Iteration 77000: 1\n",
      "Iteration 78000: -1\n",
      "Iteration 79000: 1\n",
      "Iteration 80000: 1\n",
      "Iteration 81000: -1\n",
      "Iteration 82000: 1\n",
      "Iteration 83000: 1\n",
      "Iteration 84000: 1\n",
      "Iteration 85000: -1\n",
      "Iteration 86000: 1\n",
      "Iteration 87000: 1\n",
      "Iteration 88000: -1\n",
      "Iteration 89000: -1\n",
      "Iteration 90000: 1\n",
      "Iteration 91000: -1\n",
      "Iteration 92000: -1\n",
      "Iteration 93000: 1\n",
      "Iteration 94000: -1\n",
      "Iteration 95000: -1\n",
      "Iteration 96000: 1\n",
      "Iteration 97000: -1\n",
      "Iteration 98000: -1\n",
      "Iteration 99000: 1\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[1. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0. -1.]]\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0. -1.]]\n",
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0. -1. -1.]]\n",
      "[[ 1.  0.  0.]\n",
      " [ 1.  1.  0.]\n",
      " [ 0. -1. -1.]]\n",
      "Player -1 wins!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import jit, cuda\n",
    "\n",
    "class AI():\n",
    "    \"\"\"\n",
    "    The neural network consists of three layers: an input layer, a hidden layer, and an output layer.\n",
    "    The input layer has 9 nodes, which correspond to the 9 cells of the 3x3 tic-tac-toe board.\n",
    "    The hidden layer has 100 nodes, and the output layer has 9 nodes, which also correspond to the 9 cells of the board.\n",
    "    The output of the network is a probability distribution over the 9 cells, indicating the likelihood of each cell being the best move.\n",
    "\n",
    "    The forward method performs the forward propagation, where the input (the board state) is passed through the network to generate the output (the move probabilities).\n",
    "    The backward method performs the backward propagation, where the weights and biases are updated based on the error between the predicted and actual output.\n",
    "    The actual output in this case is determined by the reward received after making a move.\n",
    "    The reward is typically 1 for a win, -1 for a loss, and 0 for a draw or an ongoing game.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Initialize the game board as a 3x3 matrix filled with zeros\n",
    "        self.board = np.zeros((3, 3))\n",
    "        # Set the starting player\n",
    "        self.player = 1\n",
    "        # Initialize the weights for the input layer (9 nodes) to the hidden layer (100 nodes)\n",
    "        self.weights1 = np.random.randn(9, 100)\n",
    "        # Initialize the weights for the hidden layer (100 nodes) to the output layer (9 nodes)\n",
    "        self.weights2 = np.random.randn(100, 9)\n",
    "        # Initialize the bias for the hidden layer (100 nodes)\n",
    "        self.bias1 = np.random.randn(100)\n",
    "        # Initialize the bias for the output layer (9 nodes)\n",
    "        self.bias2 = np.random.randn(9)\n",
    "        # Set the learning rate for the gradient descent\n",
    "        self.learning_rate = 0.01\n",
    "        # Set the initial epsilon value for the epsilon-greedy strategy\n",
    "        self.epsilon = 1.0\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        # Define the sigmoid activation function\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def softmax(self, x):\n",
    "        # Define the softmax activation function\n",
    "        return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "    def forward(self):\n",
    "        # Perform the forward propagation\n",
    "        # Flatten the board to a 1D array and pass it through the input layer to the hidden layer\n",
    "        self.layer1 = self.sigmoid(np.dot(self.board.flatten(), self.weights1) + self.bias1)\n",
    "        # Pass the output of the hidden layer to the output layer\n",
    "        self.output = self.softmax(np.dot(self.layer1, self.weights2) + self.bias2)\n",
    "\n",
    "    def backward(self, reward):\n",
    "        # Perform the backward propagation\n",
    "        # Update the weights and biases based on the error between the predicted and actual output\n",
    "        self.weights1 -= self.learning_rate * np.outer(self.board.flatten(), np.dot(self.weights2, (self.output - self.board.flatten()))) * reward\n",
    "        self.weights2 -= self.learning_rate * np.outer(self.layer1, (self.output - self.board.flatten())) * reward\n",
    "        self.bias1 -= self.learning_rate * np.dot(self.weights2, (self.output - self.board.flatten())) * reward\n",
    "        self.bias2 -= self.learning_rate * (self.output - self.board.flatten()) * reward\n",
    "            \n",
    "    def make_move(self):\n",
    "        self.forward()\n",
    "        move = np.argmax(self.output)\n",
    "        i = move // 3\n",
    "        j = move % 3\n",
    "        if self.board[i, j] == 0:\n",
    "            self.board[i, j] = self.player\n",
    "            self.player *= -1\n",
    "        else:\n",
    "            self.board[np.random.randint(3), np.random.randint(3)] = self.player\n",
    "            self.player *= -1\n",
    "            \n",
    "    def ismoveValid(self, i, j):\n",
    "        # check if user passed the move i.e. -1\n",
    "        if i == -1 or j == -1:\n",
    "            return -1\n",
    "        # check values of i and j provided by user\n",
    "        if i<0 or i>2 or j<0 or j>2:\n",
    "            return 1\n",
    "        # check if the position is already occupied\n",
    "        if self.board[i, j] != 0:\n",
    "            return 1\n",
    "        return 0\n",
    "         \n",
    "    # run computation on GPU\n",
    "    @jit(target_backend =\"cuda\")\n",
    "    def train(self, iterations):\n",
    "        # Train the AI for a specified number of iterations\n",
    "        for i in range(iterations):\n",
    "            # Reset the board and player for each game\n",
    "            self.board = np.zeros((3, 3))\n",
    "            self.player = 1\n",
    "            # Play the game until someone wins\n",
    "            while check_win(self.board) == 0:\n",
    "                self.make_move()\n",
    "            # Calculate the reward based on the game outcome\n",
    "            reward = get_reward(self.board)\n",
    "            # Update the weights and biases based on the reward\n",
    "            self.backward(reward)\n",
    "            # Print the game outcome every 1000 iterations\n",
    "            if i % 1000 == 0:\n",
    "                print(\"Iteration \" + str(i) + \": \" + str(check_win(self.board)))\n",
    "            # Decay the epsilon value\n",
    "            self.epsilon *= 0.99\n",
    "\n",
    "            \n",
    "    def play_game(self):\n",
    "        self.board = np.zeros((3, 3))\n",
    "        self.player = 1\n",
    "        while check_win(self.board) == 0:\n",
    "            print(self.board)\n",
    "            if self.player == 1:\n",
    "                i = int(input(\"Enter row for player \" + str(self.player) + \": \"))\n",
    "                j = int(input(\"Enter column for player \" + str(self.player) + \": \"))\n",
    "                if make_move(self.board, self.player, i, j):\n",
    "                    self.player *= -1\n",
    "            else:\n",
    "                self.make_move()\n",
    "        print(\"Player \" + str(self.player * -1) + \" wins!\")\n",
    "        \n",
    "    def play_against_human(self):\n",
    "        self.board = np.zeros((3, 3))\n",
    "        self.player = 1\n",
    "        while check_win(self.board) == 0:\n",
    "            print(self.board)\n",
    "            if self.player == 1:\n",
    "                i = int(input(\"Enter row for player \" + str(self.player) + \": \"))\n",
    "                j = int(input(\"Enter column for player \" + str(self.player) + \": \"))\n",
    "                \n",
    "                # invalid i, j\n",
    "                if self.ismoveValid(i, j) == 1:\n",
    "                    print(\"Invalid move! Try again\")\n",
    "                    continue\n",
    "                # the player passed the move i.e. -1\n",
    "                elif self.ismoveValid(i, j) == -1:\n",
    "                    self.player *= -1\n",
    "                    continue\n",
    "                # combining both conditions in one line\n",
    "                if make_move(self.board, self.player, i, j):\n",
    "                    self.player *= -1\n",
    "            else:\n",
    "                # perform the forward propagation\n",
    "                self.forward()\n",
    "                # get the move probabilities from the output layer\n",
    "                move_probs = self.output\n",
    "                # sort the moves based on the probabilities\n",
    "                sorted_moves = np.argsort(move_probs)[::-1]\n",
    "                for move in sorted_moves:\n",
    "                    # convert the move to board coordinates\n",
    "                    i = move // 3\n",
    "                    j = move % 3\n",
    "                    # if the move is valid, make the move and break the loop\n",
    "                    if make_move(self.board, self.player, i, j):\n",
    "                        self.player *= -1\n",
    "                        break   \n",
    "        print(\"Player \" + str(self.player * -1) + \" wins!\")\n",
    "    \n",
    "    \n",
    "# tic-tac-toe from scratch\n",
    "# Initialize the board\n",
    "def init_board():\n",
    "    return np.zeros((3, 3))\n",
    "\n",
    "# Check if a player has won\n",
    "def check_win(board):\n",
    "    for i in range(3):\n",
    "        if np.all(board[i, :] == 1) or np.all(board[:, i] == 1):\n",
    "            return 1\n",
    "        elif np.all(board[i, :] == -1) or np.all(board[:, i] == -1):\n",
    "            return -1\n",
    "    if np.all(np.diag(board) == 1) or np.all(np.diag(np.fliplr(board)) == 1):\n",
    "        return 1\n",
    "    elif np.all(np.diag(board) == -1) or np.all(np.diag(np.fliplr(board)) == -1):\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "# Make a move\n",
    "def make_move(board, player, i, j):\n",
    "    if board[i, j] == 0:\n",
    "        board[i, j] = player\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Calculate reward based on game outcome\n",
    "def get_reward(board):\n",
    "    result = check_win(board)\n",
    "    if result == 1:\n",
    "        return 1.0  # AI wins\n",
    "    elif result == -1:\n",
    "        return -1.0  # AI loses\n",
    "    else:\n",
    "        return 0.0  # Draw\n",
    "\n",
    "# Play against the AI\n",
    "print(\"Play against the AI!\")\n",
    "print(\"AI is player 1 and you are player -1\")\n",
    "print(\"If you want to pass move, enter -1 for any row or column\")\n",
    "ai = AI()\n",
    "ai.train(100000)\n",
    "ai.play_against_human()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
