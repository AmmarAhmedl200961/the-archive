{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n",
      "Iteration 1, loss = 0.50119556\n",
      "Iteration 2, loss = 0.34310053\n",
      "Iteration 3, loss = 0.30126178\n",
      "Iteration 4, loss = 0.27104769\n",
      "Iteration 5, loss = 0.25187250\n",
      "Iteration 6, loss = 0.23397156\n",
      "Iteration 7, loss = 0.21657527\n",
      "Iteration 8, loss = 0.20283371\n",
      "Iteration 9, loss = 0.19073292\n",
      "Iteration 10, loss = 0.18142667\n",
      "Iteration 11, loss = 0.16795125\n",
      "Iteration 12, loss = 0.15390801\n",
      "Iteration 13, loss = 0.14608573\n",
      "Iteration 14, loss = 0.13943018\n",
      "Iteration 15, loss = 0.12955005\n",
      "Iteration 16, loss = 0.12229597\n",
      "Iteration 17, loss = 0.11568305\n",
      "Iteration 18, loss = 0.11174523\n",
      "Iteration 19, loss = 0.10556216\n",
      "Iteration 20, loss = 0.09538746\n",
      "Accuracy: 88.76%\n",
      "[[1217    2   14   23    2    1  154    0    7    0]\n",
      " [   3 1350    1   16    4    0    4    0    0    0]\n",
      " [  28    2 1129    9   77    1  122    0    2    0]\n",
      " [  75    9   10 1249   29    0   44    0    0    0]\n",
      " [   6    6  146   46 1052    0  139    0    3    0]\n",
      " [   1    0    0    0    0 1315    0   21    3   25]\n",
      " [ 177    4   89   30   42    1 1118    0   15    1]\n",
      " [   0    0    1    0    0   43    0 1337    2   35]\n",
      " [   5    0    3    5    5    5   20    1 1330    1]\n",
      " [   0    1    0    1    0   13    1   38    0 1329]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the Fashion-MNIST dataset\n",
    "X, y = fetch_openml('Fashion-MNIST', version=1, return_X_y=True)\n",
    "# The Fashion-MNIST dataset is a collection\n",
    "# of  Zalando's  article images. It contains 60,000 images for the training set and 10,000 images for\n",
    "# the test set data (we will discuss the test and training datasets along with the validation dataset\n",
    "# later). These are 28 x 28 grayscale images and belong to the labels of 10 different classes.\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create a MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=20, alpha=0.0001,\n",
    "                    solver='adam', verbose=10, random_state=1,\n",
    "                    learning_rate_init=0.001)\n",
    "\n",
    "# print classes found in the dataset\n",
    "print('Classes:', np.unique(y))\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "print('Accuracy: {:.2f}%'.format(acc * 100))\n",
    "\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01176471 0.01176471 0.01176471 ... 0.00392157 0.00392157 0.00392157]\n",
      " [0.26666668 0.26666668 0.26666668 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.99607843 0.99607843 0.99607843 ... 0.42745098 0.4117647  0.40392157]\n",
      " [0.4392157  0.4392157  0.4392157  ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.03921569 0.03921569 0.03921569]] \n",
      " [1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1]\n",
      "Accuracy: 94.74%\n",
      "[[ 3  0]\n",
      " [ 1 15]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a function to load and preprocess the images\n",
    "def load_images(path):\n",
    "    \"\"\" Load images from the given path , classify them as normal or covid and resize them to 150x150 pixels.\n",
    "    then convert them to grayscale and return images(x) and labels(y) as numpy arrays.\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    for folder in os.listdir(path):\n",
    "        label = 0 if folder == 'normal' else 1\n",
    "        for file in os.listdir(os.path.join(path, folder)):\n",
    "            img = cv2.imread(os.path.join(path, folder, file))\n",
    "            # resize the image to 150x150 pixels\n",
    "            img = cv2.resize(img, (150, 150))\n",
    "            # convert to grayscale\n",
    "            img = img.astype('float32') / 255\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load the images\n",
    "X, y = load_images('dataset')\n",
    "\n",
    "# Flatten the images\n",
    "X = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(X_test,'\\n' ,y_test)\n",
    "\n",
    "# Create a MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "print('Accuracy: {:.2f}%'.format(acc * 100))\n",
    "\n",
    "# print the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
