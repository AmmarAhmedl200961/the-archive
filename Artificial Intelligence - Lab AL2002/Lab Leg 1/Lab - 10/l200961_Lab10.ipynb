{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ammar\\AppData\\Local\\Temp\\ipykernel_18172\\252128158.py:74: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -np.sum(y_true * np.log(y_pred)) / m\n",
      "C:\\Users\\ammar\\AppData\\Local\\Temp\\ipykernel_18172\\252128158.py:74: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -np.sum(y_true * np.log(y_pred)) / m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (864,5) into shape (864,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 149\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39m# Compute the accuracy on the validation set\u001b[39;00m\n\u001b[0;32m    148\u001b[0m y_val_pred \u001b[39m=\u001b[39m forward_pass(X_val\u001b[39m.\u001b[39mreshape(X_val\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), weights, biases)\n\u001b[1;32m--> 149\u001b[0m y_val_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49margmax(y_val_pred, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    150\u001b[0m val_acc \u001b[39m=\u001b[39m accuracy_score(y_val, y_val_pred)\n\u001b[0;32m    152\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m, Train Loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Val Acc: \u001b[39m\u001b[39m{\u001b[39;00mval_acc\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1216\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[39mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[39m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m kwds \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mkeepdims\u001b[39m\u001b[39m'\u001b[39m: keepdims} \u001b[39mif\u001b[39;00m keepdims \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m-> 1216\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39m\u001b[39margmax\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     52\u001b[0m bound \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, method, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m bound \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     wrap \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(asarray(obj), method)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     44\u001b[0m \u001b[39mif\u001b[39;00m wrap:\n\u001b[0;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, mu\u001b[39m.\u001b[39mndarray):\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (864,5) into shape (864,)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Define a function to load and preprocess the images\n",
    "def load_images(path):\n",
    "    \"\"\" Load images from the given path , classify them based on their flower type and resize them to 150x150 pixels.\n",
    "    then convert them to grayscale and return images(x) and labels(y) as numpy arrays.\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_dict = {'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}\n",
    "    for folder in os.listdir(path):\n",
    "        label = label_dict[folder]\n",
    "        for file in os.listdir(os.path.join(path, folder)):\n",
    "            img = cv2.imread(os.path.join(path, folder, file))\n",
    "            # convert to grayscale\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            # resize the image to 150x150 pixels\n",
    "            img = cv2.resize(img, (150, 150))\n",
    "            # scale pixel values to range [0, 1]\n",
    "            img = img.astype('float32') / 255\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the images\n",
    "X, y = load_images('flowers')\n",
    "\n",
    "# 1. Preprocess the data by scaling\n",
    "# the pixel values to the range [0, 1], and split the dataset into training and validation sets.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Set the number of neurons in each layer\n",
    "n_input = 150 * 150\n",
    "n_hidden1 = 64\n",
    "n_hidden2 = 32\n",
    "n_output = 5\n",
    "\n",
    "# 2. Initialize the weights and biases of the MLP using random values.\n",
    "weights = {\n",
    "    'w1': np.random.randn(n_input, n_hidden1),\n",
    "    'w2': np.random.randn(n_hidden1, n_hidden2),\n",
    "    'w3': np.random.randn(n_hidden2, n_output)\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': np.random.randn(n_hidden1),\n",
    "    'b2': np.random.randn(n_hidden2),\n",
    "    'b3': np.random.randn(n_output)\n",
    "}\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "def forward_pass(x, weights, biases):\n",
    "    # Compute the output of the first hidden layer\n",
    "    z1 = np.dot(x, weights['w1']) + biases['b1']\n",
    "    a1 = np.maximum(z1, 0) # ReLU activation function\n",
    "\n",
    "    # Compute the output of the second hidden layer\n",
    "    z2 = np.dot(a1, weights['w2']) + biases['b2']\n",
    "    a2 = np.maximum(z2, 0) # ReLU activation function\n",
    "\n",
    "    # Compute the output of the output layer\n",
    "    z3 = np.dot(a2, weights['w3']) + biases['b3']\n",
    "    a3 = softmax(z3, axis=1) # Softmax activation function\n",
    "\n",
    "    return a3, a1, a2\n",
    "\n",
    "# Define the loss function (cross-entropy loss)\n",
    "def loss(y_true, y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    loss = -np.sum(y_true * np.log(y_pred)) / m\n",
    "    return loss\n",
    "\n",
    "# Define the derivative of the ReLU activation function\n",
    "def relu_derivative(z):\n",
    "    return (z > 0).astype(int)\n",
    "\n",
    "# Define the backward pass function\n",
    "def backward_pass(x, y_true, y_pred, a1, a2, weights):\n",
    "    m = y_true.shape[0]\n",
    "    # Compute the gradient of the loss with respect to z3\n",
    "    dz3 = y_pred - y_true\n",
    "    # Compute the gradient of the loss with respect to w3 and b3\n",
    "    dw3 = np.dot(a2.T, dz3) / m\n",
    "    db3 = np.sum(dz3, axis=0) / m\n",
    "\n",
    "    # Compute the gradient of the loss with respect to z2\n",
    "    da2 = np.dot(dz3, weights['w3'].T)\n",
    "    dz2 = da2 * relu_derivative(a2)\n",
    "    # Compute the gradient of the loss with respect to w2 and b2\n",
    "    dw2 = np.dot(a1.T, dz2) / m\n",
    "    db2 = np.sum(dz2, axis=0) / m\n",
    "\n",
    "    # Compute the gradient of the loss with respect to z1\n",
    "    da1 = np.dot(dz2, weights['w2'].T)\n",
    "    dz1 = da1 * relu_derivative(a1)\n",
    "    # Compute the gradient of the loss with respect to w1 and b1\n",
    "    dw1 = np.dot(x.T, dz1) / m\n",
    "    db1 = np.sum(dz1, axis=0) / m\n",
    "\n",
    "    gradients = {\n",
    "        'dw1': dw1,\n",
    "        'dw2': dw2,\n",
    "        'dw3': dw3,\n",
    "        'db1': db1,\n",
    "        'db2': db2,\n",
    "        'db3': db3\n",
    "    }\n",
    "    \n",
    "    return gradients\n",
    "\n",
    "# Define the update_weights function\n",
    "def update_weights(weights, biases, gradients, learning_rate):\n",
    "    weights['w1'] -= learning_rate * gradients['dw1']\n",
    "    weights['w2'] -= learning_rate * gradients['dw2']\n",
    "    weights['w3'] -= learning_rate * gradients['dw3']\n",
    "    \n",
    "    biases['b1'] -= learning_rate * gradients['db1']\n",
    "    biases['b2'] -= learning_rate * gradients['db2']\n",
    "    biases['b3'] -= learning_rate * gradients['db3']\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the learning rate and number of epochs\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "\n",
    "# Train the MLP for 10 epochs\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    a3, a1, a2 = forward_pass(X_train.reshape(X_train.shape[0], -1), weights, biases)\n",
    "    \n",
    "    # Compute the loss\n",
    "    y_train_one_hot = np.eye(n_output)[y_train]\n",
    "    train_loss = loss(y_train_one_hot, a3)\n",
    "    \n",
    "    # Backward pass\n",
    "    gradients = backward_pass(X_train.reshape(X_train.shape[0], -1), y_train_one_hot, a3, a1=a1,a2=a2 ,weights=weights)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    update_weights(weights, biases, gradients, learning_rate)\n",
    "    \n",
    "    # Compute the accuracy on the validation set\n",
    "    y_val_pred = forward_pass(X_val.reshape(X_val.shape[0], -1), weights, biases)\n",
    "    y_val_pred = np.argmax(y_val_pred, axis=1)\n",
    "    val_acc = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "\n",
    "# Evaluate the final accuracy of the trained MLP on the test set\n",
    "y_val_pred = forward_pass(X_val.reshape(X_val.shape[0], -1), weights, biases)\n",
    "y_val_pred = np.argmax(y_val_pred, axis=1)\n",
    "test_acc = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(f'Test Acc: {test_acc:.4f}')\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Plot the ROC curve for the classifier\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_val_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
