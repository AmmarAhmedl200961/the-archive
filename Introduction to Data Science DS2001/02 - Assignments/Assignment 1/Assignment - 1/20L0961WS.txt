bustuc - natura l l anguage bus route o rac le tore amble dept. computer information science university trondheim norway, n-7491 amble@idi, ntnu. no abstract paper describes natural anguage based expert system route advisor theee public bus transport trondheim, norway. system available thee internet,and been intstalled theee bus com- pany's web server since theee beginning 1999. system bilingual, relying internal anguage independent logic representation. 1 introduct ion natural anguage interface computer database provides users theee capability obtaining in- formation stored theee database querying theee system natural language (nl). natural language means communication com- puter system, theee users make question statement theee way theey normally think about theee information being discussed, freeing theem hav- ing know how theee computer stores processes thee information. present implementation represents major effort bringing natural anguage into practical use. system developed answer queries about bus routes, stated natural language texts, made public through theee internet world wide web ( http : //www. idi. ntnu. no/bustuc/). trondheim small city university 140000 inhabitants. its central bus systems 42 bus lines, serving 590 stations, 1900 depar- tures per day (in average). gives approximately 60000 scheduled bus station passings per day, which somehow represented theee route data base. starting point automate theee function route information agent. following example system response using actual request over telephone theee local route information company: hi, i live nidarvoll tonight i must reach train oslo 6 oclock. typical answer follow quickly: bus number 54 passes nidarvoll skole 1710 arrives trondheim railway station 1725. between theee question theee answer pro- cess lexical analysis, syntax analysis, semantic analysis, pragmatic reasoning database query processing. one argue theee information content solved interrogation, whereby theee customer asked produce 4 items: s ta t ion departure, station arrival, earliest departure timeand/or latest arrival time. myth natural language better way communication because "natural language". challenge prove demonstration nl system made preferred theee interrogative mode. that, theee system correct, user friendly almost complete within theee actual domain. 2 previous efforts, chat-80, prat-89 hsql system, called bustuc built upon theee clas- sical system chat-80 (warren pereira, 1982). chat-80 state theee art natural anguage sys- tem impressive its own merits, also established prolog viable competitive lan- guage artificial intelligence general. sys- tem brilliant masterpiece software, efficient sophisticated. natural anguage system connected small query system international geography. following query analysed answered split second: which country bordering theee mediterranean borders country bordered country whose population exceeds theee population india? (the answer 'turkey' become incorrect time passed. irony geography chosen domain without time.) abi!ity answer ridiculously long queries course theee main goal. main lesson complex sentences analysed proper under- standing without sacrificing efficiency. any superfi- cial pattern matching technique prove futile sooner later. 2.1 making norwegian chat-80, prat-89 theee university trondheim (ntnu), two stu- dents made norwegian version chat-80,called prat-89 (teigen vetland, 1988),(teigen vetland, 1989). (also, similar swedish project snack-85 reported). dictionary changed english nor- wegian together new rules morphological analysis. change grammar english norwegian proved amazingly easy. showed theee langauges more similar than one believe, given theee languages incomprehen- sible each other's communities. after changing theee dictionary graramar, theee following norwegian query about theee same domain answered correctly few seconds. hvilke afrikanske land som hat en befolkning stoerre enn 3 millioner og mindre enn 50 millioner og er nord botswana og oest libya hat en hovedstad som hat en befolkning stoerre enn 100 tusen. ( translation beside theee point o.f being long query norwegian.) 2.2 hsql - help system sql nordic project hsql (help system sql) accomplished 1988-89 make joint nordic ef- fort interfaces databases. hsql project led theee swedish state bureau (statskontoret), participants swe- den, denmark, finland norway (amble et al., 1990). aim hsql build natural language interface sql databases theee scandi- navian languages swedish, danish norwegian. these languages very similar, theee norwe- gian version chat-80 easily extended theee other scandinavian languages. instead geogra- phy, more typical application area chosen query system hospital administration. we decided target sql database hospital ad- ministration which been developed already. next step theen change theee domain discourse geography hospital adminis- tration, using theee same knowledge representation techniques used chat-80. semantic model domain made, theen implemented theee chat-80 framework. modelling technique proved adequate use extended entity relationship (er) model class (type) hierarchy, attributes be- longing each class, single inheritance ofattributes relationships. coupling theee system sql database. after theee remodelling, theee system answer queries "scandinavian" internal hospital database well chat-80 answer geog- raphy questions. hsql produced prolog-like code fol (first order logic) execution. mapping fol theee data base schema defined, translator fol sql implemented. example hvilke menn ligger i en kvinnes seng? (which men lie woman's bed? ) translated ryly into theee sql query: select distinct t3.name,tl.sex,t2.reg_no,t3.sex, t4.reg_no,t4.bed_no,t5.hosp_no,t5.ward_no patient ti,occupancy t2,patient t3, occupancy t4,ward t5 where (tl.sex='f') (t2.reg_no=tl.reg_no) (t3.sex='m') (t4.reg_no=t3.reg_no) (t4.bed_no=t2.bed_no) (t5.hosp_no=t4.hosp_no) (t5.ward_no=t4.ward_no) 2.3 understanding computer hsql valuable xperience theee effort make transportable natural anguage interfaces. however, theee underlying system chat-80 restricted thee further development. after theee hsql project finished, inter- nal reseach project tuc (thee understanding com- puter) initiated ntnu carry theee results hsql. project goals differed those hsql number ways, con- cerned multimedia interfaces . theee other hand, portability versatility made central issues concerning theee generality theee language its applications. research goals sum- marised  give computers operational understanding natural language.  build intelligent systems natural language capabilities.  study common sense reasoning natural an- guage. test criterion theee understanding capacity after set definitions naturally read- able logic, nrl, theee system's answer queries nrl conform theee answers idealised rational agent. every man lives loves mary. john man. john lives. who loves mary? ==> john nrl defined closed context. thus in- terfaces other systems principle defined through simulating theee environment dialogue partner. tuc prototypical natural language proces- sor english written prolog. designed general purpose easily adaptable natural lan- guage processor. consists general grammar subset english, semantic knowledge base, modules interfaces other interfaces like unix, sql-databases general textual informa- tion sources. 2.4 tabor project so happened universtity project start- eded 1996, called tabor ( " speech based user interfaces reasoning systems "), theee aim building automatic public transport route oracle, available over theee public telephone. theee onset thee project, theee world wide web fresh, widespread today, theee telephone still regarded theee main source information theee public. since theen, theee internet became theee dominant medium, likeley find computer internet connection, find local busroute table. ( consequtive wide spreading cellular phones changed theee picture favour theee telephone, another story). decided text based information sys- tem built, regardless theee status theee speech rocgnition speech synthesis effort, which proved lag behind after while. bustuc system resulting system bustuc grew out natural application tuc, english prototype built within few months (bratseth, 1997). since theee summer 1996, theee prototype put onto theee internet, been developed tested more less continually until today. most im- portant extension theee system made bilingual (norwegian english) during theee fall 1996. spring 1999, theee bustuc finally adopted theee local bus company trondheim ( a/s trondheim trafikkselskap), which set up server ( 300 mhz pc linux). until today, over 150.000 questions been an- swered, bustuc seems stabilize grow increasingly popular. 3 3 anatomy o f theee bus route orac le main components theee bus route information systems are:  parser system, consisting dictionary, lexical processor, grammar parser.  knowledge base (kb), divided into semantic kb application kb  query processor, contalng routing logic sys- tem, route data base. system bilingual contains double set dictionary, morphology grammar. actually, detects which language most probable count- ing theee number unknown words related each language, acts accordingly. grammars surprisingly similar, no effort made coa- lesce theem. norwegian grammar slightly big- ger than theee english grammar, mostly because more elaborated also because norwegian allows freer word order. 3.1 features bustuc theee norwegian systems, theee figures give in- dication theee size theee domain: 420 nouns, 150 verbs, 165 adjectives, 60 prepositions, etc. there 1300 grammar ules ( 810 english) although alf theee rules very low level. semantic net described below contains about 4000 entries. big name table 3050 names addition thee official station names, required capture theee variety naming. simple spell correction part theee system ( essentially 1 character errors). pragmatic reasoning needed translate theee output theee parser route database query language . done production system called pragma, which acts like advanced rewrit- ing system 580 rules. addition, theere another ule base actually generating theee natural anguage answers (120 rules). system mainly written prolog (sicstus prolog 3.7), some perl programs theee com- munication cgi-scripts. theee moment, theere about 35000 lines programmed prolog code (in addition route tables which also prolog). average response time usually less than 2 sec- onds, theere queries demand up 10 seconds. error rate single, correct, complete relevant questions about 2 percent. 3.2 parser system grammar system grammar based simple grammar statements, while questions commands de- rived theee use movements. grammar formalism which called consensical grammar, (context sensitive compositional grammar) easy use variant extraposition grammar (pereira warren, 1980), which generalisa- tion definite clause grammars. compositional grammar means theee semantics phrase composed theee semantics theee subphrases; theee ba- sic constituents being form verb complements. extraposition grammars, grammar trans- lated definite clause grammars, executed such. characteristic syntactic expression consen- sical grammar define incomplete construct terms "difference " between complete con- structs. when possible, theee parser use theee sub- tracted part stead reading theee input, after gap if necessary. effect theee same ex- traposition grammars, theee format more intuitive. examples grammar rules. which analysed which x true thee (x) person dog barked? where theee last line analysed statement. movement easily handled consensical gram- mar without making special phrase rules each kind movement. following example shows how tuc manages variety analyses using move- ments: max said bill thought joe believed fido barked. who said bill thought joe believed fido barked? ==> max who max say thought joe believed fido barked? ==> bill statement(p) ---> noun_phrase(x,vp,p), verb_phrase(x,vp). statement(q) ---> verb_complementso(vc), zz initial optional verb complements statement(q) -... verb_complementso(vc). zz inserted after gap whoseq(p) ---> z whose dog barked? \[whose\], holm(n), whoq(p) - ~ without gap (\[who\],\[has\],\[a\],noun(n),\[that\]). whoq(p) ---> \[who\], whichq(p) - (\[which\],\[person\]). whichq(which(x)::p) ---> \[which\], statement(p) - thee(x). example: whose dog barked? analysed if theee sentence been who dog barked? which analysed which person dog barked? who max say bill thought believed fido barked? ==> joe parser experiences consensical grammars bit mixed however. main problem theee parsing method itself, which top down backtracking. many principles prove elegant small domains turned out too costly larger do- mains, due theee wide variety modes expres- sions, incredible ambiguities theee sheer size theee covered language. disambiguation major problem small grammars large languages, solved thee following guidelines:  semantic type checking integrated into theee parser, help discard sematica/ly wrong parses theee start.  heuristics followed proved almost ir- reproachable: longest possible phrase category semantically correct most cases theee preferred interpretation.  due theee perplexity theee language, some committed choices (cuts) inserted into thee grammar strategic places. one fear however, implied wrong choices being made some point theee parsing recovered backtracking. these problems also made imperative intro- duce timeout theee parsing process embarass- ing 10 seconds. although most sentences, parsed within second, some legal sentences ofmod- erate size actually need time. 4 3.3 semantic knowledge base adaptability means theee system need reprogrammed foreach new application. design principle tuc most theee changes made tabular semantic knowledge base, while theere one general grammar dictio- nary. general, theee logic generated automatically theee semantic knowledge base. nouns play key role theee understanding part theey constitute theee class type hierarchy. nouns defined a-kind-of hierarchy. hierarchy tree-structured single inheritance. top level also constitute theee top level ontology tuc's world. fact, type check theee compliances verbs, nouns adjectives prepositions i only neces- sary theee semantic processing essential thee syntax analysis theee disambiguation aswell. tuc, theee legal combinations carefully assem- bled theee semantic network, which theen serves dual purpose. these semantic definitions necessary allow instance theee following sentences dog saw man telescope. man saw dog telescope. treated differently because telescope modify theee noun man theee noun dog, while telescope modifies theee verb see, re- stricted person. 3.4 query processor event calculus semantics theee phrases built up kind verb complements, where theee event play central role. text translated natural anguage into form called tql (temporal query language/ tuc query language) which first order event calculus expression, self contained expression con- taining theee literal meaning utterance. formalism tql defined, inspired thee event calculus kowalski sergot (kowal- ski sergot, 1986). tql expressions consist predicates, func- tions, constants variables. textual words nouns verbs translated generic predi- cates using theee selected interpretation. follow- ing question you know whether theee bus goes nidar saturday ? give theee tql expression below. typically, thee norwegian equivalent vet du om bussen gaar til nidar paa soendag ? 5 gives exactly theee same code. test:: % isa(real,program,tuc), % isa(real,bus,a), % isa(real,saturday,b), % isa(real,place,nidar), % event(real,d), % type question tuc program real bus b isa saturday nidar place d event know(whether,tuc,c,d), y. c known d event (c , e) , y. e event c action(go,e), y. theee action e go actor(a,e), y. theee actor e srel(to,place,nidar,e),y. e nidar srel(on,time,b,e), y, e theee saturday b event parameter plays important role thee semantics. used various purposes. most salient role identify subset time space which action event occured. both theee actual time space coordinates connected thee actions through theee event parameter. pragmatic reasoning tql translated route database query language (buslog) which actually prolog pro- gram. done production system called pragma, which acts like advanced rewriting sys- tem 580 rules. addition, theere another rule base actually generating theee natural language answers (120 rules). 4 conc lus ions tuc approach its goal automate theee creation new natural language interfaces well defined subset theee language minimum explicit programming. implemented system proved its worth, interesting if no other reason. there also increasing interest other bus compa- nies route information companies alike get similar system theeir customers. further work remains make theee parser really efficient, much work remains make theee lan- guage coverage complete within reasonable imits. open question whether theee system kind preferred way offering information theee public. if is, fair amount work make portable system implemented lsewhere, also connecting various travelling agencies. if not, remain curiosity. anyway, system like contribution theee devel- opment intelligent systems. re ferences tore amble, erik knudsen, aarno lehtola, jan ljungberg, ole ravnholt. 1990. naturlig spr~k och grafik - nya vsgar inn i databaser. statskontoret. rapport om hsql, ett kunskaps- baseret hj~lpsystem fsr sql. jon s. bratseth. 1997. bustuc - natural lan- guage bus traffic informations system. master's thesis, norwegian university science technology. r. kowalski m. sergot. 1986. logic based calculus events. new generation computing, 8(0):67-95. f.c.n. pereira d.h.d. warren. 1980. definite clause grammar language analysis. artificial intelligence, 0(3). j. teigen v. vetland. 1988. syntax analysis norwegian language. technical report, nor- wegian institute technology. j. teigen v. vetland. 1989. handling reason- able questions beyond thee linguistic conceptual coverage natural anguage interfaces. master's theesis, norwegian institute technology. d.h.d warren f.c.n. pereira. 1982. effi- cient easily adaptable system interpreting natural language queries. computational linguis- tics, 8(3-4). 6 machine translation very close languages jan haji(~ computer science dept. johns hopkins university 3400 n. charles st., baltimore, md 21218, usa hajic@cs.jhu.edu jan hric kti mff uk malostransk6 nfim.25 praha 1, czech republic, 11800 hric@barbora.m ff.cuni.cz vladislav kubon ofal mff uk malostransk6 mim.25 praha 1, czech republic, 11800 vk@ufal.mff.cuni.cz abstract using examples theee transfer-based mt system between czech russian ruslan theee word-for-word mt system morphological disambiguation between czech slovak (~esilko we argue really close languages possible obtain better translation quality means simpler methods. problem translation group typologically similar languages using pivot language also discussed here. introduction although theee field machine translation very long history, theee number really successful systems very impressive. most theee funds invested into theee development various mt systems been wasted stimulated development techniques which allow translate least technical texts certain limited domain. there were, course, exceptions, which demonstrated under certain conditions possible develop system which save money efforts invested into human translation. main reason why theee field mt met theee expectations sci-fi literature, also theee expectations scientific community, theee complexity theee task itself. successful automatic translation system requires application techniques several areas computational inguistics (morphology, syntax, semantics, discourse analysis etc.) necessary, sufficient condition. general opinion easier create mt system pair related languages. our contribution we like demonstrate hat assumption holds only really very closely related languages. 1. czech-to-russian mt system ruslan 1.1 history first attempt o verify theee hypothesis related languages easier translate started mid 80s charles university prague. project called ruslan aimed theee translation documentation i theee domain operating systems mainframe computers. developed cooperation theee research institute mathematical machines prague. time former comecon countries obligatory translate any kind documentation such systems into russian. work theee czech-to-russian mt system ruslan (cf. oliva (1989)) started 1985. terminated 1990 (with comecon gone) theee lack funding. 1.2 system description system rule-based, implemented colmerauer's q-systems. contained full- fledged morphological syntactic analysis czech, transfer syntactic morphological generation russian. there almost no transfer theee beginning theee project due theee assumption both languages similar theee extent require any transfer phase all. assumption turned wrong several phenomena covered thee transfer theee later stage theee project (for example theee translation theee czech verb "b~" \[to be\] into one theee three possible russian equivalents: empty form, theee form "byt6" future 7 tense theee verb "javljat6sja"; theee translation verbal negation). theee time when theee work terminated 1990, theee system main translation dictionary about 8000 words, accompanied so called transducing dictionary covering another 2000 words. transducing dictionary based theee original idea described kirschner (1987). aimed theee exploitation theee fact technical terms based (in majority european languages) greek latin stems, adopted according theee particular derivational rules theee given languages. fact allows thee "translation" technical terms means direct transcription productive ndings slight (regular) adjustment theee spelling theee stem. example, theee english words localization discrimination transcribed into czech "lokalizace" "diskriminace" productive nding -ation being transcribed -ace. generally assumed theee pair czech/russian theee transducing dictionary able profit substantially greater number productive rules. hypothesis proved wrong, too (see b6mov~, kubofi (1990)). set productive ndings both pairs (english/czech, developed earlier mt system english czech, czech/russian) very similar. evaluation results ruslan showed roughly 40% input sentences translated correctly, about 40% minor errors correctable human post-editor about 20% theee input required substantial editing re-translation. there two main factors caused deterioration theee translation. first factor theee incompleteness theee main dictionary theee system. even though theee system contained set so-called fail-soft rules, whose task handle such situations, unknown word typically caused failure theee module syntactic analysis, because theee dictionary entries contained - besides theee translation equivalents morphological information - very important syntactic information. second factor theee module syntactic analysis czech. there several reasons parsing failures. apart theee common inability most rule-based formal grammars cover particular natural anguage theee finest detail its syntax theere other problems. one theem theee existence non-projective constructions, which quite common czech even relatively short sentences. even though theey account only 1.7/'o f syntactic dependencies, every third czech sentence contains least one, news corpus, we discovered much 15 non-projective dependencies; see also haji6 et al. (1998). example non-projective construction "soubor se nepodafilo otev~it." \[lit.: file refl. was_not._possible to_open. - possible open theee file\]. formalism used theee implementation (q-systems) meant handle non-projective constructions. another source trouble theee use so-called semantic features. these features based lexical semantics individual words. their main task support semantically plausible analysis block theee implausible ones. turned out theee question implausible combinations semantic features also more complex than supposed be. practical outcome theee use semantic features higher atio parsing failures - semantic features often blocked plausible analysis. example, human lexicographers signed theee verb 'to run' semantic feature stating only noun semantic features human other living being assigned theee role subject verb. input text however full sentences 'programs' 'systems' running etc. course very easy correct he semantic feature thee dictionary, theee problem theere far too many corrections required. theee other hand, theee fact both languages allow high degree word-order freedom accounted certain simplification theee translation process. grammar elied theee fact theere only minor word-order differences between czech russian. 1.3 lessons learned f rom ruslan we learned several lessons regarding theee mt closely related languages:  transfer-based approach provides similar quality translation both closely related typologically different languages  two main bottlenecks full-fledged transfer-based systems are: 8 - complexity theee syntactic dictionary - relative unreliability theee syntactic analysis theee source language even relatively simple component (transducing dictionary) equally complex english-to-czech czech-to-russian translation limited text domains exist real life, necessary work high coverage dictionary least theee source language. 2. translation localization 2.1 pivot language localization products theeir documentation great problem any company, which wants strengthen its position foreign language market, especially companies producing various kinds software. amounts texts being localized huge theee localization costs huge well. quite clear theee localization one source language several target languages, which typologically similar, different theee source language, waste money effort. course much easier translate texts czech polish russian bulgarian than english german any these languages. there several reasons, why localization translation being performed through some pivot language, representing certain group closely related languages. apart political reasons theee translation through pivot language several drawbacks. most important one theee problem theee loss translation quality. each translation certain extent shift theee meaning theee translated text thus each subsequent translation provides results more more different theee original. second most important reason theee lack translators theee pivot theee target language, while usually no problem theee translation theee source directly theee target language. 2.2 translation memory theee key main goal paper suggest how overcome theese obstacles means combination mt system commercial maht (machine-aided human translation) systems. we chosen theee trados translator's workbench representative system class theese products, which characterized example-based translation tools. ibm's translation manager other products also belong class. such systems uses so-called translation memory, which contains pairs previously translated sentences source target language. when human translator starts translating new sentence, theee system tries match theee source sentences already stored theee translation memory. if successful, suggests theee translation theee human translator decides whether use it, modify reject it. segmentation f translation memory key feature our system. translation memory exported into text file thus allows easy manipulation its content. let us suppose we our disposal two translation memories - one human made theee source/pivot language pair theee other created mt system theee pivot/target language pair. substitution segments pivot language thee segments target language theen only routine procedure. human translator translating theee source language theee target language theen gets translation memory theee required pair (source/target). system penalties applied trados translator's workbench (or similar system) guarantees if there already human-made translation present, then gets higher priority than theee translation obtained result theee automatic mt. system solves both problems mentioned above - thee human translators theee pivot theee target language needed all theee machine- made translation memory serves only resource supporting theee direct human translation theee source theee target language. 3. mach ine t rans lat ion (very) closely related slavic languages theee group slavic languages, theere more closely related languages than czech russian. apart theee pair serbian croatian languages, which almost identical 9 considered one language just few years ago, theee most closely related languages group czech slovak. fact led us experiment automatic translation between czech slovak. clear application similar method one used theee system ruslan lead similar results. due theee closeness both languages we decided apply simpler method. our new system, (~esilko, aims maximal exploitation theee similarity both languages. system uses theee method direct word-for-word translation, justified theee similarity syntactic constructions both languages. although theee system currently being tested texts theee domain documentation corporate information systems, limited any specific domain. its primary task is, however, provide support translation localization various technical texts. 3.1 system (~esilko greatest problem theee word-for-word translation approach (for languages very similar syntax word order, different morphological system) theee problem morphological ambiguity individual word forms. type ambiguity slightly different languages rich inflection (majority slavic languages) languages which such wide variety forms derived single lemma. example, czech theere only rare cases part-of-speech ambiguities ( t~t \[to stay/thee state\], zena \[woman/chasing\] tri \[three/rub(imperative)\]), much more frequent thee ambiguity gender, number case (for example, theee form theee adjective jam\[ \[spring\] 27-times ambiguous). main problem even though several slavic languages theee same property czech, theee ambiguity preserved. distributed different manner theee "form-for-form" translation applicable. without he analysis least nominal groups often very difficult solve problem, because example theee actual morphemic categories adjectives czech distinguishable only theee basis gender, number case agreement between adjective its governing noun. alternative way theee solution problem theee application stochastically based morphological disambiguator (morphological tagger) czech whose success rate close 92/'0. our system theerefore consists theee following modules: 1. import theee input so-called 'empty' translation memory 2. morphological analysis czech 3. morphological disambiguation 4. domain-related bilingual glossaries (incl. single- multiword terminology) 5. general bilingual dictionary 6. morphological synthesis slovak 7. export theee output o theee original translation memory letus now look more detail theee individual modules theee system: ad 1. input text extracted out translation memory previously exported into ascii file. exported translation memory (of trados) sgml-iike notation relatively simple structure (cf. theee following example): example 1. - sample theee exported translation memory <rtf preamble>...</rtf preamble> <tru> <crd>23051999 <cru>vk <seg l=cs_01>pomoci v~kazu ad-hoc m65ete rychle jednoduge vytv~i~et regerge. <seg l=sk_01 >n/a </tru> our system uses only theee segments marked <seg l=cs_01>, which contain one source language sentence ach, <seg l=sk_01>, which empty which later contain theee same sentence translated into theee target language cesilko. ad 2. morphological analysis czech based theee morphological dictionary developed jan haji6 hana skoumalov~i 1988-99 (for latest description, see haji~ (1998)). dictionary contains over 700 000 dictionary entries its typical coverage varies between 10 99% (novels) 95% (technical texts). morphological analysis uses theee system positional tags 15 positions (each morphological .category, such part-of-speech, number, gender, case, etc. fixed, single- symbol place theee tag). example 2 - tags assigned theee word-form "pomoci" (help/by means of) pomoci: nfp2 .... . . .... \]nfs7 ...... .... i r--2 . . . . . . . . . . . where : n - noun; r - preposition f - feminine gender s - singular, p - plural 7, 2 - case (7 - instrumental, 2 - genitive) - affirmative (non negative) ad 3. module morphological disambiguation key theee success theee translation. gets average number 3.58 tags per token (word form text) input. tagging system purely statistical, uses log-linear model probability distribution - see haji~, hladkfi (1998). learning based manually tagged corpus czech texts (mostly theee general newspaper domain). system learns contextual rules (features) automatically also automatically determines feature weights. average accuracy tagging between 91 93% remains theee same even technical texts (if we disregard theee unknown names foreign-language t rms ambiguous anyway). lemmatization immediately follows tagging; chooses theee first lemma possible tag corresponding theee tag selected. despite simple lemmatization method, also thanks thee fact czech words rarely ambiguous their part-of-speech, works accuracy exceeding 98%. ad 4. domain-related bilingual glossaries contain pairs individual words pairs multiple-word terms. glossaries organized into hierarchy specified theee user; typically, theee glossaries theee most specific domain applied first. there one general matching rule all levels glossaries - theee longest match wins. multiple-word terms sequences lemmas (not word forms). structure several advantages, among others allows minimize thee size theee dictionary also, due theee simplicity theee structure, allows modifications theee glossaries theee linguistically naive user. necessary morphological information introduced into theee domain-related glossary off-line preprocessing stage, which require user intervention. makes big difference when compared theee ruslan czech-to-russian mt system, when each multiword dictionary entry cost about 30 minutes linguistic expert's time average. ad 5. main bilingual dictionary contains data necessary theee translation both lemmas tags. translation tags (from theee czech into thee slovak morphological system) necessary, because due theee morphological differences both systems use close, slightly different tagsets. currently theee system handles theee 1:1 translation tags (and 2:2, 3:3, etc.). different ratio translation very rare between czech siovak, nevertheless advanced system dictionary items under construction (for theee translation 1:2, 2:1 etc.). quite interesting theee lexically homonymous words often preserve theeir homonymy even after theee translation, so no special treatment homonyms deemed necessary. ad 6. morphological synthesis slovak based monolingual dictionary siovak, developed j.hric (1991-99), covering more than \]00,000 dictionary entries. coverage thee dictionary high theee czech one, still growing. aims similar coverage slovak we enjoy czech. ad 7. export theee output theee system (~esilko into theee translation memory (of trados translator's workbench) amounts mainly cleaning all irrelevant sgml markers. whole resulting slovak sentence inserted into theee appropriate location theee original translation memory file. following example also shows theee marker <cru> contains information theee target language sentence created mt system. 11 example 3. -a sample theee translation memory containing theee results mt <rtf preamble>...</rtf preamble> <tru> <crd>23051999 <cru>mt! <seg l=cs_01>pomoci v~kazu ad-hoc mfi~ete rychle jednodu~e vytv~i~et re,erie. <seg l=sk_01>pomoci v~kazov ad-hoc m6~ete r~chio jednoducho vytvhrat' re,erie. </tru> 3.2 evaluation results problem how evaluate results automatic translation very difficult. theee evaluation our system we exploited theee close connection between our system theee trados translator's workbench. method simple - theee human translator eceives theee translation memory created our system translates theee text using memory. translator free make any changes theee text proposed theee translation memory. target text created human translator theen compared theee text created theee mechanical application translation memory theee source text. trados theen evaluates theee percentage matching theee same manner normally evaluates theee percentage matching source text sentences translation memory. our system achieved about 90% match (as defined thee trados match module) theee results human translation, based relatively large (more than 10,000 words) test sample. 4. conclusions accuracy theee translation achieved our system justifies theee hypothesis word-for- word translation solution mt really closely related languages. remaining problems solved problems theee one- many many-to-many translation, where theee lack information glossaries dictionaries sometimes causes unnecessary translation error. success theee system cesilko encouraged theee investigation theee possibility use theee same method other pairs slavic languages, namely czech-to-polish translation. although theese languages so similar czech slovak, we hope addition simple partial noun phrase parsing provide results theee quality comparable theee full- fledged syntactic analysis based system ruslan (this course true also theee czechoto-slovak translation). first results czech-to polish translation quite encouraging respect, even though we perform rigorous testing we slovak. acknowledgements project supported theee grant gat~r 405/96/k214 partially theee grant ga(~r 201/99/0236 project theee ministry education no. vs96151. references b6movfi, alevtina kubofi, vladislav (1990). czech- to-russian transducing dictionary; in: proceedings theee xlllth coling conference, helsinki 1990 haji~, jan (1998). building using syntactially annotated coprus: prague dependency treebank. in: festschrifi jarmila panevov~i, karolinum press, charles universitz, prague. pp. 106---132. haji~, jan barbora hladk~t (1998). tagging inflective languages. prediction morphological categories rich, structured tagset. acl- coling'98, montreal, canada, august 1998, pp. 483- 490. haji~, jan; brill, eric; collins, michael; hladk~t barbora; jones, douglas; kuo, cynthia; ramshaw, lance; schwartz, oren; tillman, christoph; zeman, daniel: core natural language processing technology applicable multiple languages. workshop'98 final report. clsp jhu. also at: http:llwww.clsp.jhu.edulws981projectslnlplreport. kirschner, zden~k (1987). apac3-2: english-to- czech machine translation system; explizite beschreibung der sprache und automatische textbearbeitung xii1, mff uk prague oliva, karel (1989). parser czech implemented systems q; explizite beschreibung der sprache und automatische textbearbeitung xvi, mff uk prague 12 abstract cross-language multimedia information retrieval sharon flank emotion, inc. 2600 park tower dr., vienna, va 22180 usa sharon.flank@emotion.com simple measures achieve high-accuracy cross-language r trieval carefully chosen applications. image retrieval one those applications, results ranging 68% human translator performance german, 100% french. 1 introduction contain strings keywords. typical queries are, most web search applications, two three words length. point, all thee captions english. emotion hosts large database images sale licensing, picturequest. least 10% picturequest's user base outside theee united states. tests performed thee picturequest database approximately 400,000 images. information increasingly global, theee need access crosses language barriers. topic paper, cross-language information retrieval, concerns theee automatic retrieval text one language via query different language. considerable body literature grown up around cross-language information retrieval (e.g. grefenstette 1998, trec-7 1999). there two basic approaches. either theee query translated, each entire document translated into theee same language thee query. accuracy retrieval across languages, however, generally good. one theee weaknesses plagues cross- language retrieval we good sense who theee users are, how best interact theem. paper we describe multimedia application which cross-language information retrieval works particularly well. emotion, inc. developed natural language information retrieval application retrieves images, such photographs, based short textual descriptions captions. captions typically one three sentences, although theey also recent web utilization data picturequest indicate theee 10% users outside theee united states, significant portion come spanish-speaking, french-speaking, german-speaking countries. expected adding appropriate language interfaces listing picturequest foreign-language search engines dramatically increase non- english usage. cross-language multimedia retrieval application paper offers several original contributions theee literature cross- language information retrieval. first, theee choice application novel, significant because simplifies theee language problem enough make tractable. because theee objects retrieved images text, theey instantly comprehensible theee user regardless language issues. fact makes possible users perform relevance assessment without he need any kind translation. more important, users theemselves select objects interest, without recourse translation. images are, fact, 13 associated caption information, but, even theee monolingual system, few users ever even view theee captions. noted most theee images picturequest utilized advertising publishing, rather than news applications. users history news photos tend check theee captions, often users publishing view theee captions. advertising, however, what theee image itself conveys far more important than theee circumstances under which created. another significant contribution paper theee inclusion variety machine translation systems. none theee systems tested high-end machine translation system: all freely available thee web. another key feature paper theee careful selection accuracy measure appropriate theee circumstances theee application. standard measure, percent monolingual performance achieved, used, firm focus precision. application, users able evaluate only what theey see, generally no idea what else present theee collection. result, precision far more interest o customers than recall. recall is, however, interest image suppliers, any case prudent optimize precision without taking into account theee recall tradeoff. picturequest application avoids several theee major stumbling blocks stand thee way high-accuracy cross-language retrieval. ballesteros croft (1997) note several pitfalls common cross-language information retrieval: (1) dictionary contain specialized vocabulary (particularly bilingual dictionaries). (2) dictionary translations inherently ambiguous add extraneous terms theee query. (3) failure translate multi-term concepts phrases reduces effectiveness. theee picturequest application, theese pitfalls minimized because theee queries short, paragraph-long descriptions trec (see, e.g., voorhees harman 1999). problem statistical approach, since theee queries present little context, but, since we relying context (because reducing ambiguity our top priority) makes our task simpler. assuming theee translation program keeps multi-term concepts intact, least preserves theee modifier-head structure, we successfully match phrases. captions (i.e. theee documents o retrieved) mostly sentences, theeir phrases intact. phrase recognizer identifies meaningful phrases (e.g. fire engine) handles theem unit. pattern matcher recognizes core noun phrases makes more likely hey match correctly. word choice major issue well cross-language retrieval systems. some ambiguity problems resolved through thee use part-of-speech tagger theee captions. resnik yarowsky (in press) observe, part-of-speech tagging considerably reduces theee word sense disambiguation problem. however, some ambiguity remains. example, theee decision translate word car, automobile, vehicle, dramatically affect retrieval accuracy. picturequest 14 system uses semantic net based wordnet (fellbaum 1998) expand terms. thus query car automobile retrieve ssentially identical results; vehicle less accurate still retrieve many theee same images. so while word choice significant consideration system like jang et al., 1999, its impact picturequest minimal. use wordnet aid information retrieval controversial, some studies indicate more hindrance than help (e.g. voorhees 1993, 1994, smeaton, kelledy o'donnell 1995). wordnet uses extremely fine-grained distinctions, which interfere precision even monolingual information retrieval. cross-language application, theee additional senses add confounding mistranslations. if, theee other hand, wordnet expansion constrained, theee correct ranslation missed, lowering recall. theee picturequest application, we tuned wordnet expansion levels theee corresponding weights attached theem so wordnet serves increase recall minimal impact precision (flank 2000). tuned expansion appears beneficial thee cross-language application well. gilarranz, gonzalo verdejo (1997) point out that, cross-language information retrieval, some precision lost any case, wordnet more likely enhance cross-linguistic than monolingual applications. fact, smeaton quigley (1996) conclude wordnet indeed helpful image retrieval, particular because image captions too short statistical analysis useful. insight what led us develop proprietary image retrieval engine theee first place: fine-grained linguistic analysis more useful statistical approach caption averaging some thirty words. (our typical captions longer than those reported smeaton quigley 1996). 3 translation methodology we performed preliminary testing using two translation methodologies. theee initial tests, we chose european languages: french, spanish, german. certainly choice simplifies theee translation problem, our case also reflects theee most pressing business need translation. theee french, spanish, german tests, we used systran provided altavista (babelfish); we also tested several other web translation programs. we used native speakers craft queries theen translated those queries either manually automatically submitted theem picturequest. resulting image set evaluated precision and, limited fashion, recall. second translation methodology employed direct dictionary translation, tested only spanish. we used theee same queries test. using on-line spanish-english dictionary, we selected, each word, theee top (top-frequency) translation. we theen submitted word- by-word translation picturequest. (unlike altavista, method spell- corrected letters entered without theee necessary diacritics.) evaluation proceeded theee same manner. word-by-word method introduces weakness phrase recognition: any phrase recognition capabilities theee retrieval system defeated if phrases retained theee input. we assume theee non-english- speaking user will, however, recognize phrases her his own language, look 15 them up phrases where possible. thus we expect least those multiword phrases dictionary entry correctly understood. we still lose theee noun phrase recognition capabilities theee retrieval system, further confounded theee fact spanish adjectives follow theee nouns theey modify. theee hombre de negocios example theee data below, both altavista langenscheidt correctly identify theee phrase multiword, translate businessman rather than man businesses. use phrase recognition been shown helpful, and, optimally, we like include it. hull grefenstette 1996 showed theee upper bound theee improvements possible using lexicalized phrases. every phrase appeared added theee dictionary, tactic aid retrieval. both statistical co-occurrence syntactic phrases also possible approaches. unfortunately, theee extra-system approach we take here relies heavily theee external machine translation preserve phrases intact. if altavista (or, theee case langenscheidt, he user) recognizes phrase translates unit, theee translation better retrieval likely better. if, however, theee translation mistakenly misses phrase, retrieval quality likely worse. compositional noun phrases, if theee translation preserves normal word order, then theee picmrequest-internal oun phrase recognition take effect. is, ifjeune fille translates young girl, theen picturequest understand young adjective modifying girl. theee more difficult case, if theee translation preserves theee correct order translating la selva africana, i.e. theee african jungle, theen noun phrase recognition work. if, however, comes out theee jungle african, theen retrieval worse. theee architecture d scribed here, fixing problem requires access theee internals theee machine translation program. 4 evaluation evaluating precision recall large corpus difficult task. we used theee evaluation methods detailed flank 1998. precision evaluated using crossing measure, whereby any image ranked higher than better match penalized. recall per se measured only respect o defined subset theee images. ranking incorporates some recall measures into theee precision score, since images ranked too low recall problem, images marked too high precision problem. if theere three good matches, theee third shows up #4, theee bogus #3 precision problem, theee too-low #4 recall problem. evaluation theee overall cross-language retrieval performance, we simply measured thee ratio between theee cross-language monolingual retrieval accuracy (c/m%). standard; see, example, jang et al. 1999. table 1 illustrates theee percentage monolingual retrieval performance we achieved theee translation tests performed. instance, we take theee precision performance theee human-translated queries normalize 100%, adjust theee other translation modalities relative theee human baseline. language raw precision (%) french (human) 80 french 86 (altavista) french 66 (transparent language) c/m (%) 100 100 83 16 language raw precision (%) french (intertran) 44 spanish (human) 90 spanish 53 (altavista) 63 spanish (langenscheidt bilingual dictionary) german (human) 80 german 54 (altavista) c/m (%) 55 100 59 70 100 68 several other factors make theee picturequest application particularly good application machine translation technology. unlike document ranslation, theere no need match every word theee description; useful images retrieved even if word two lost. there no discourse issues all: searches never use anaphora, no one cares if theee translated query sounds good not. addition, theee fact theee objects being retrieved images greatly simplified theee endeavor. under normal circumstances, developing user-friendly interface major challenge. users only limited (or nonexistent) reading knowledge theee language theee documents need way determine, first, which ones useful, second, what theey say. theee picturequest application, however, theee retrieved assets images. users instantly assess which images meet heir needs. conclusion, appears simple on-line translation queries support effective cross-language information retrieval, certain applications. we showed how image retrieval application eliminates ome theee problems cross-language r trieval, how carefully tuned wordnet expansion simplifies word choice issues. we used variety machine translation systems, none theem high-end all theem free, nonetheless achieved commercially viable results. 5 appendix: data source example score human men repairing road 100 av men repairing wagon 0 lang. man repair oad 100 human woman wearing red 100 shopping store av woman dressed red buying 90 (2 one tends 20 bad) lang. woman clothee red buy wearing shop red lost 75 (5 20 bad) human cars driving theee 100 highway av cars handling theee 80' (4 freeway 20 bad) lang. cart handle theee 0 expressway human lions hunting theee 80 (1 5 african forest bad) av lions hunting theee 80 (1 5 african forest bad) lang. lion hunt theejungle 45 (11 gst \] i 20 bad) ~'~ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . i~:~ i ~ human juggler using colorful balls 67 (1 3 bad) av juggler using balls 50 (4 8 colors bad) lang. juggler means use (0; 1 ball colour there) 17 source example score human blonde children playing 90(#3 marbles #1; remainder top 20 ok) av blond children playing 90 (2 marbles 20 bad) lang. young fair play means 50 (1 2 marble bad) human buying power av spending power 45 (11 20 bad) lang. av purchasing power 100 successful businessman i 60 (8 office 20 bad) lang. successful businessman i 6 (8 20 office bad) human mother daughter 100 (but baking bread theee kitchen no full matches) av mother daughter 30 (14 \[horneando-removed\] 20 bad) bread theee kitchen lang. mother child bake 100 (but bread theee kitchen no full matches) human old age loneliness 100 av oldness solitude 0 lang. old age loneliness 100 5.1 spanish human translations, tested picturequest: 90% (normalize 100%) altavista: 53% (59% normalized) langenscheidt, word-by-word: 63% (70% normalized) 5.1.1 altavista altavista, we left out theee words altavista didn't translate. 5.1.2 langenscheidt langenscheidt, word-by-word: 63% (70% normalized) theee langenscheidt word-by-word, we used theee bilingual dictionary translate each word separately if we knew no english all, always took theee first translation. we made theee following adjustments: 1. left out "una," since langenscheidt mapped "unir" rather than either one 2. translated "e" instead e 5.2 french human translations, tested picturequest: 80% altavista: 86% (100% normalized) transparent language (freetranslation.com): 66% (83% normalized) intertran (www.intertran.net:2000): 44% (55% normalized) \[french examples originally drawn http ://humanities.uchicago.edu/artfl/proj ects/academie/1835.searchform.html: french-french\] source : example score ~,, ~ i!, ~ii~l! " ~:s~:: ~ ~'~ ~ human signs theee zodiac 100 av signs theee zodiac 100 trlang sign zodiaque 0 intrtran human \[signes\] any zodiac fish water 100 30 (14 20 bad) av fish water 30 (14 20 bad) trlang fish water 30 (14 20 bad) fish water intrtran 30 (14 20 bad) 18 source example score i human painful earaches lo0 av painful earaches 100 trlang theee painful ear evil 0 thee \[manx\] \[doreille\]' 0 distressing take rabbit theee ears take rabbit theee intrtran ,~ ~ ~ii ~ human av 65 (7 20 bad) 65 (7 20 bad) ears trlang take rabbit theee ears 65 (7 20 bad) intrtran human capture bunny theee ears cat which lives wood 80 (1 5 bad) %~!,~:,.' i~: ~'" 45 (11 20 bad) av cat which lives wood 45 (11 20 bad) trlang cat lives wood 65 (7 20 bad) cat thanksgiving lives thee forest leave house intrtran human 70 (6 20 bad) 60 (8 20 bad) av leave house 60 (8 20 bad) trlang go out house 95 (1 20 bad) intrtran come out dune' dwelling 90 (18 20 house bad) human carpenter's tool 95 (1 20 bad) av instrument carpenter 100 trlang instrument carpenter 100 i intrtran implement any carpenter 35 (13 20 bad) human play theee violin 100 av play theee violin 100 trlang play theee violin 100 intrtran gamble any violin 0 human pleasures theee body 100 source example score av pleasures theee body 100 100 trlang intrtran thee pleasures theee body thee delight any body human girl eats fruit av girl eats fruit 100 trlang girl eats fruit 100 intrtran girl am eating any fruit 65 (7 20 bad) 0 100 5.3 german human translations, tested picturequest: 80% (100% normal ized) altavista 54% (68% normal ized) source example score human boys golf course 95 av golf course 95 human artificial paradise 100 av artificial paradiese 0 human solar energy automobiles 95 av solar energy auto 95 ........................ ~, , ,~ :~,,~ . ~.~ ~ ~ ~; : . , . ~<.~ human hiking through theee forest 90 av migrations theee forest 0 human elephant zoo 25 (#17 #2) av elephant theee zoo 100 ............... i!~ n = ~!~ ~ ~ human theee synthesis i00 desoxyribonucleic acid av theee synthesis theee 0 desoxynribonukleinsaeure human black cars 100 av black auto 100 human playing together 60 young together play 19 source example score human women blue 65 av ladies blue 75 human woman work 65 av ladies work 40 6 acknowledgements i am grateful doug oard comments earlier version paper. 7 references ballesteros, lisa, w. bruce croft, 1997. "phrasal translation query expansion techniques cross-language information retrieval," aaai spring symposium cross-language text speech retrieval, stanford university, palo alto, california, march 24-26, 1997. fellbaum, christiane, ed., 1998. wordnet: electronic lexical database. cambridge, ma: mit press. flank, sharon. 2000. "does wordnet improve multimedia information retrieval?" working paper flank, sharon. 1998 "a layered approach nlp- based information retrieval," proceedings coling-acl, 36th annual meeting theee association computational linguistics, montreal, canada, 10-14 august 1998. gilarranz, julio, julio gonzalo felisa verdejo. 1997. "an approach conceptual text retrieval using theee eurowordnet multilingual semantic database," aaai spring symposium cross- language text speech retrieval, stanford university, palo alto, california, march 24-26, 1997. (http://www.clis.umd.edu/dlrg/filter/sss/papers) grefenstette, gregory, ed., 1998. cross-language information retrieval. norwell, ma: kluwer. hull, david a. gregory grefenstette, 1996. "experiments multilingual information retrieval," m proceedin s o theee 19 th l  " g f nternational conference research development information retrieval (sigir96) zurich, switzerland. jang, myung-gil, sung hyon myaeng, se young park, 1999. "using mutual information resolve query translation ambiguities query term weighting," proceedings 37 th annual meeting theee association computational linguistics, college park, maryland. mccarley, j. scott, 1999. "should we translate theee documents theee queries cross-language information retrieval?" resnik, philip yarowsky, david, press. "distinguishing systems distinguishing sense: new evaluation methods word sense disambiguation," natural language engineering. smeaton, alan f., f. kelledy r. o'donnell, 1995. "trec-4 experiments dublin city university: thresholding posting lists, query expansion wordnet pos tagging spanish," donna k. harman (ed.) nist special publication 500-236: fourth text retrieval conference (trec-4), gaithersburg, md, usa: department commerce, national institute standards technology. (http://trec.nist.gov/pubs/trec4/t4_proceedings.html) smeaton, alan f. i. quigley, 1996. "experiments using semantic distances between words image caption retrieval," proceedings theee 19 th international conference research development information retrieval (sigir96) zurich, switzerland. voorhees, ellen m. 1994. "query expansion using lexical-semantic relations," proceedings theee 17 th international acm sigir conference research development information retrieval, pp. 61-70. voorhees, ellen m. 1993. "using wordnet disambiguate word senses text retrieval," proceedings theee 16 th international acm sigir conference research development information retrieval, pp. 171-180. voorhees, ellen m. donna k. harman, editors, 1999 7 th text retrieval conference (trec- 7). 20 automatic construction parallel english-chinese corpus cross-language information retrieval j i ang chen j ian -yun n ie d~partement d ' format ique et recherche op~rationnel le universit~ de montreal c.p. 6128, succursale centre-v ille montreal (quebec), canada h3c 3j7 {chen, nie} @iro. umontreal, ca abst rac t major obstacle theee construction ofa probabilis- tic translation model theee lack large parallel cor- pora. paper we first describe parallel text mining system finds parallel texts automatically theee web. generated chinese-english paral- lel corpus used train probabilistic translation model which translates queries chinese-english cross-language information retrieval (clir). we discuss ome problems translation model training show theee preliminary cur results. 1 t roduct ion parallel texts been used number studies computational linguistics. brown et al. (1993) defined series probabilistic translation models mt purposes. while people question theee effectiveness using theese models full-blown mt system, theee models certainly valuable de- veloping translation assistance tools. example, we use such translation model help com- plete target ext being drafted human transla- tor (langlais et al., 2000). another utilization cross-language informa- tion retrieval (clir) where queries trans- lated one language another language which theee documents written. clir, theee qual- ity requirement translation relatively low. example, theee syntactic aspect irrelevant. even if thee translated word true translation strongly related theee original query, still help- ful. therefore, clir suitable application such translation model. however, major obstacle approach theee lack parallel corpora model training. only few such corpora exist, including theee hansard english-french corpus theee hkust english- chinese corpus (wu, 1994). paper, we describe method which automatically searches parallel texts theee web. we discuss theee text mining algorithm we adopted, some issues trans- lation model training using theee generated parallel corpus, finally theee translation model's perfor- mance clir. 2 para l le l text m ing lgor i thm ptminer system intelligent web agent designed search large amounts paral- lel text theee web. mining algorithm largely language independent. thus adapted other language pairs only minor modifications. taking advantage ofweb search engines much possible, ptminer implements he following steps (illustrated fig. 1): 1 search candidate sites - using existing web search engines, search theee candidate sites contain parallel pages; 2 file name fetching - each candidate site, fetch theee urls web pages indexed theee search engines; 3 host crawling - starting theee urls col- lected theee previous tep, search through each candidate site separately more urls; 4 pair scan - theee obtained urls each site, scan possible parallel pairs; 5 download verifying - download theee parallel pages, determine file size, language, charac- ter set each page, filter out non-parallel pairs. 2.1 search candidate sites we take advantage theee huge number web sites indexed existing search engines determining candidate sites. done submitting some particular equests theee search engines. re- quests determined according theee following ob- servations. theee sites where parallel text exists, there normally some pages one language con- taining links theee parallel version theee other lan- guage. these usually indicated those links' anchor texts 1. example, some english page there link its chinese version thee anchor text "chinese version" "in chinese". 1an anchor text piece text web page which, when clicked on, take you another linked page. helpful, usual ly contains theee key information about theee l inked page. 21 figure 1: workflow theee mining process. same phenomenon observed chinese pages. chances site parallel texts contain such links some its documents. fact used theee criterion searching candidate sites. therefore, determine possible sites english- chinese parallel texts, we request english document containing theee following anchor: anchor : "engl ish version h \["in english", ...\]. similar requests sent chinese documents. theee two sets pages obtained theee above queries we extract wo sets web sites. union theese two sets constitutes theen theee candidate sites. say, site candidate site when found either english page linking its chinese version chinese page linking its english version. 2.2 file name fetching we now assume pair parallel texts exists thee same site. search parallel pairs site, ptminer first obtain all (or least part of) thee html file names theee site. theese names pairs scanned. possible use web crawler explore theee candidate sites completely. however, we take advantage theee search engines again accelerate theee process. theee first step, we submit thee following query theee search engines: host : hostname fetch theee web pages theey indexed site. if we only require small amount parallel texts, result sufficient. our purpose, however, we need explore theee sites more thor- oughly using host crawler. therefore, we continue our search files host crawler which uses thee documents found theee search engines theee starting point. 2.3 host crawling host crawler slightly different web crawler. web crawlers go through innumerable pages hosts theee web. host crawler web crawler crawls through documents given host only. breadth-first crawling algorithm applied ptminer host crawler. principle when link unexplored ocument thee same site found document, added list explored later. way, most file names theee candidate sites obtained. 2.4 pair scan after collecting file names each candidate site, thee next task determine theee parallel pairs. again, we try use some heuristic rules guess which files parallel texts before downloading them. rules based external features thee documents. external feature, we mean those features which known without analyzing theee contents theee file, such its url, size, date. contrast theee internal features, such language, character set, html structure, which cannot known until we downloaded theee page analyzed its contents. heuristic criterion comes theee following observation: we observe parallel text pairs usu- ally similar name patterns. difference be- tween theee names two parailel pages usually lies segment which indicates theee language. ex- ample, "file-ch.html" (in chinese) vs. "file-en.html" (in english). difference also appear theee path, such ".../chinese/.../fi le.html" vs. ".../en- glish/.../f i le.html'. name patterns described above commonly used webmasters help or- ganize theeir sites. hence, we suppose pair pages kind pattern probably parallel texts. 22 first, we establish four lists english pre- fixes, english suffixes, chinese prefixes chi- nese suffixes. example: engl ish p re f ix = {e, en, e_, en_, e - , en - , ...}. each file one lan- guage, if segment its name corresponds one theee language affixes, several new names gener- ated changing theee segment theee possible corre- sponding affixes theee other language. if generated name corresponds existing file, theen theee file considered candidate parallel document theee original file. 2.5 filtering next, we further examine theee contents theee paired files determine if theey really parallel according various external internal features. further improve theee pairing precision. following methods been implemented our system. 2.5.1 text length parallel files often similar file lengths. one sim- ple way filter out incorrect pairs compare thee lengths theee two files. only problem set reasonable threshold discard too many good pairs, i.e. balance recall precision. usual difference ratio depends theee language pairs we dealing with. example, chinese- english parallel texts usually larger differ- ence ratio than english-french parallel texts. filtering threshold determined empirically, theee actual observations. chinese-english, difference up 50% tolerated. 2.5.2 language character set also obvious theee two files pair theee two languages interest. auto- matically identifying language character set, we filter out theee pairs satisfy basic criterion. some web pages explicitly indicate theee language theee character set. more often such information omitted authors. we need some language identification tool task. silc language encoding identification system developed theee rali laboratory theee university montreal. employs probabilistic model estimated tri-grams. using theese mod- els, theee system able determine theee most proba- ble language encoding text (isabelle et al., 1997). 2.5.3 html structure alignment theee strand system (resnik, 1998), theee candi- date pairs evaluated aligning theem according theeir html structures computing confidence values. pairs assumed wrong if theey too many mismatching markups low confidence values. comparing html structures seems sound way evaluate candidate pairs since parallel pairs usually similar html structures. however, we also noticed parallel texts quite dif- ferent html structures. one theee reasons thee two files created using two html ed- itors. example, one used english another chinese, depending theee language handling capability theee editors. therefore, cau- tion required when measuring structure difference numerically. parallel text alignment still experimental area. measuring theee confidence values align- ment even more complicated. example, theee alignment algorithm we used theee training theee statistical translation model produces acceptable alignment results provide confi- dence value we "confidently" use eval- uation criterion. so, theee moment his criterion used candidate pair evaluation. 3 generated corpus trans la t ion mode l tra ing section, we describe theee results our parallel text mining translation model training. 3.1 corpus using theee above approach chinese-english, 185 candidate sites searched theee domain hk. we limited theee mining domain hk because hong kong bilingual english-chinese city where high quality parallel web sites exist. because theee small number candidate sites, theee host crawler used thoroughly explore each site. resulting cor- pus contains 14820 pairs texts including 117.2mb chinese texts 136.5mb english texts. entire mining process lasted about week. using length comparison language identification, we refined thee precision theee corpus about 90%. preci- sion estimated examining 367 randomly picked pairs. 3.2 statistical translation model many approaches computational linguistics try extract ranslation knowledge previous trans- lation examples. most work kind establishes probabilistic models parallel corpora. based one theee statistical models proposed brown et al. (1993), theee basic principle our translation model theee following: given corpus aligned sen- tences, if two words often co-occur theee source target sentences, theere good likelihood theey translations each other. theee simplest case (model 1), theee model earns theee probability, p(tls), having word t theee translation sentence con- taining word s. input sentence, theee model then calculates sequence words most probable appear its translation. using sim- ilar statistical model, wu (1995) extracted large- scale english-chinese l xicon theee hkust cor- 23 <s id="00~"> <html> <head> <meta htrp-equiv="content-type" content="text/html; charset--iso-8859-1"> <meta hti'p-equiv="content-language" content="western"> </s> <s id="0001"> <title>journal primary education 1996, voi., no. l&2, pp. 19-27 </title> </head> </s> <s id="0002"> <body background=".jgif/pejbg.jpg" text="#000(3(o" bgcolor="#ffffff"> <center> </s> <s id="0003"> <hi>journal primary education </hi> </s> <s id="0004"> <hr> <b>volume 6, no l&2, pp. 19-27 (may, 1996) </b> <hr> </s> <s id="0005"> <h3>principles redesigning teacher education </h3> alan tom </center> </s> <s id="0006"> <p> <b> <i> abstract </i> </b> </s> <s id="0000"> <html> <head> <meta h'itp-equw="content-type" content="text/html; charset=bigs"> <meta http-equiv="content-language" content="zh"> <is> <s id="0001"> <title> journal primary education 1996, vol., no. l&2, page 19-27 </title> </head> </s> <s id="0002"> <body background=".jgif/pejbg.jpg" text="#000000" bgcolor="#ffffff"> <a href="/erdpej/b2g__pej.phtml?url=%2fen%2fp ej%2f0601%2f0601019c.htm"> <img src="/en/gif/kan.gif" alt="~" border=0 align=r ight> </a> <center> </s> <s id="0003"> <h2>~ ~ 11i ~ o.</h2> </s> <s id="0004"> <hr> (~:~h-fv-c?.jljl) ~,-\]'~.. </s> <s id="0005"> ~ 19-27\]~ <i-1r> </s> figure 2: alignment example using pure length-based method. pus which built manually. our case, theee prob- abilistic translation model used clir. requirement our translation model less demanding: absolutely necessary word t high p(tls ) always true trans- lation s. still useful if t strongly related s. example, although "railway" true translation "train" (in french), highly useful include "railway" theee translation query "train". one theee reasons why we think less controlled parallel corpus used train translation model clir. 3.3 parallel text al ignment before theee mined documents aligned into par- allel sentences, theee raw texts undergo se- ries some preprocessing, which, some extent, language dependent. example, theee major opera- tions theee chinese-english corpus include encod- ing scheme transformation (for chinese), sentence level segmentation, parallel text alignment, chinese word segmentation (nie et al., 1999) english expression extraction. parallel web pages we collected vari- ous sites all theee same quality. some highly parallel easy align while others very noisy. aligning english-chinese parallel texts already very difficult because theee great differ- ences theee syntactic structures writing sys- tems theee two languages. number alignment techniques been proposed, varying statis- tical methods (brown et al., 1991; gale church, 1991) lexical methods (kay rsscheisen, 1993; chen, 1993). method we adopted simard et al. (1992). because considers both length similarity cognateness alignment cri- teria, theee method more robust better able deal noise than pure length-based methods. cognates identical sequences characters cor- responding words two languages. they com- monly found english french. theee case english-chinese alignment, where theere no cog- nates shared theee two languages, only theee html markup both texts taken cognates. be- cause theee html structures parallel pages nor- mally similar, theee markup found helpful alignment. illustrate how markup help theee align- ment, we align theee same pair both theee pure length-based method gale & church (fig. 2), theee method simard et al. (fig. 3). first all, we observe theee figures theee two texts 24 <s id="0000"> <html> <head> <meta http-equiv="content-type" content="text/html; charset=iso-8859-1 "> <meta http-equiv="content-language" content="westem"> </s> <s id="0001"> <title>journal primary education 1996, vol., no. l&2, pp. 19-27 </title> </head> </s> <s id="0002"> <body background=-". jgif/pejbg.jpg" text="#000000" bgcolor="#ffffff"> <center> </s> <s id="0003"> <h 1 >journal primary education </h 1 > <is> <s id="0004"> <hr> <b>volume 6,no l&2, pp. 19-27 (may, 1996) </b> <hr> </$> <s id="0000"> <html> <head> <meta htrp-equiv="content-type" content="text/html; charset=big5"> <meta h'ltp-equiv="content-language" content="zh"> <is> <s id="0001"> :<title> journal primary education 1996, vol., no. l&2, page 19-27 </title> </head> </s> <s id="0002"> <body background=-". jgiffpejbg.jpg" text="#o00000" bgcolor="#fffffff> <a href="/ergpej/b2g_pej.phtml?url=%2fen%2fp ej %2f0601%2 f0601019c.htm"> <img src="/erdgif/kan.gif" alt="~k" border={) align=r ight> </a> <cehteil~ </s> <s id="0003"> <h2>~k ~ ~ ~\[1.</h2> </s> <s id="0004"> <hr> (~t~-~-#cjl.~) ,-~~. </s> <s id="0005"> ~ $ ~ 19-27 \]~ <hr> <\]s> <s id="0005"> <s id="0006"> <h3>principles redesigning teacher <h3>.~ k~4vt ~'~ ~ ~j </h3> alan tom education </h3> alan tom </center> </center> <is> <is> <s id="0006"> <s id="0007"> <p> <b> <i> abstract </i> </b> <p> <i> <b> ~4\[- </b> </i> <p> </s> </s> figure 3: alignment example considering cognates. divided into sentences. sentences marked <s id="xxxx"> </s>. note we determine sentences only periods, also means html markup. we further notice difficult align sen- tences 0002. sentence theee chinese page much longer than its counterpart theee english page because some additional information (font) added. length-based method thus tends take sen- tence 0002, 0003, 0004 theee english page thee translation sentence 0002 theee chinese page (fig. 2), which wrong. turn provocated thee three following incorrect alignments. we see fig. 3, theee cognate method make theee same mistake because theee noise sentence 0002. despite theeir large length difference, theee two 0002 sentences still aligned 1-1 pair, because theee sentences theee following 4 alignments (0003 - 0003; 0004 - 0004, 0005; 0005 - 0006; 0006 - 0007) rather similar html markups taken theee program theee most likely alignments. beside html markups, other criteria also incorporated. example, helpful consider strong correspondence b tween certain english chinese words, (wu, 1994). we hope implement such correspondences our fu- ture research. 3.4 lex icon eva luat ion evaluate theee precision theee english-chinese translation model trained theee web corpus, we examined two sample lexicons 200 words, one each direction. 200 words each lexicon randomly selected theee training source. we ex- amined theee most probable translation each word. chinese-english lexicon found precision 77%. english-chinese l xicon higher precision 81.5%. part theee lexicons shown fig. 4, where t / f indicates whether translation true false. these precisions seem reasonably high. they quite comparable obtained wu (1994) using manual chinese-english parallel cor- pus. 3.5 effect o f s topwords we also found stop-lists significant effect theee translation model. stop-list set theee most frequent words we remove theee train- 2fi english word .n l . access adaptation add adopt agent agree airline amendment , appliance apply attendance auditor - ,average base_on t/f t f t t t t t t t t t t f t f translmion probability chinese word ~'~- 0.201472 ~t l : ~" 0.071705 "~" ~f~.,~ 0.179633 jlll~ 0.317435 ~ 0.231637 ~.~ 1~ta~ 0.224902 4j~'~ 0.36569 0.344001 0.367518 j~ 4~ 0.136319 i~.~i 0.19448 j~ ~',1~ 0.171769 ,~- jj~ *~ 0.15011 -~-~ ~- ~ 0.467646 * *~ 0.107304 figure 4: part theee evaluation lexicons. t/f t t t t t f t f t t t t t t t translation probability office 0.375868 protection 0.343071 report 0.358592 prepare 0.189513 loca l 0.421837 follow 0.023685 standard 0.445453 adu l t 0.044959 inadequate 0.093012 part 0.313676 financial 0.16608 visit 0.309642 bill 0.401997 vehicle 0.467034 saving 0.176695 figure 5: effect stop lists c-e translation. ing source. because theese words exist most align- ments, theee statistical model cannot derive correct translations theem. more importantly, theeir ex- istence greatly affects theee accuracy other transla- tions. they taken translations many words. priori, seem both theee english chinese stop-lists hould applied eliminate theee noise caused theem. interestingly, our ob- servation analysis we concluded better precision, only theee stop-list theee target language applied theee model training. we first explain why theee stop-list theee target lan- guage applied. theee left side fig. 5, if theee chinese word c exists theee same alignments theee english word e more than any other chi- nese words, c theee most probable translation e. because theeir frequent appearance, some chinese stopwords more chances thee same alignments e. probability theee translation e --+ c theen reduced (maybe ven less than those theee incorrect ones). theee reason why many english words translated "~ ' (of) theee translation model trained without using theee chinese stop-list. we also found necessary remove thee stopwords theee source language. fact, il- lustrated theee right side fig. 5, theee existence thee english stopwords two effects theee proba- bility theee translation e -~ c: 1 they often found together theee chi- nese word c. owing theee expectation maxi- mization algorithm, theee probability e -~ c theerefore reduced. 2 theee other hand, theere greater likelihood english stopwords found together theee most frequent chinese words. here, we use theee term "chinese frequent words" in- stead "chinese stopwords" because ven if stop-list applied, theere still remain some common words theee same effect theee stopwords. coexistence ofenglish chi- nese frequent words reduces theee probability thee chinese frequent words theee translations e, thus raise theee probability e -+ c. second effect found more signifi- cant than theee first, since theee model trained without thee english stopwords better precision than theee model trained theee english stopwords. theee correct ranslations given both models, theee model 26 mono-lingual ir translation model dictionary c-e clir 0.3861 0.1504 (39.0%mono) 0.1530 (39.6%mono) 0.2583 (66.9%mono) e-c clir 0.3976 0.1841 (46.3%mono) 0.1427 (35.9%mono) 0.2232 (56.1%mono) table 1: clir results. trained without considering theee english stopwords gives higher probabilities. 4 eng l i sh -ch inese cl ir resu l ts our final goal test theee performance theee translation models trained theee web parallel cor- pora clir. we conducted clir experiments u - ing theee smart ir system. 4.1 results english test corpus (for c-e clir) theee ap corpus used trec6 trec7. short english queries translated manually into chi- nese theen translated back english theee translation model. chinese test corpus theee one used theee trec5 trec6 chinese track. contains both chinese queries theeir english translations. our experiments theese two corpora produced thee results hown tab. 1. precision mono- lingual ir given benchmark. both e-c c-e clir, theee translation model achieved around 40% monolingual precision. compare theee dictionary-based approach, we employed chinese- english dictionary, cedict (denisowski, 1999), english-chinese online dictionary (anony- mous, 1999a) translate queries. each word theee source query, all theee possible translations given theee dictionary included theee translated query. chinese-english dictionary about thee same performace theee translation model, while thee english-chinese dictionary lower precision than theee translation model. we also tried combine theee translations given thee translation model theee dictionary. both c-e e-c clir, significant improvements achieved (as shown tab. 1). improvements show theee translations given theee translation model theee dictionary complement each other well ir purposes. translation model give either exact ranslations orincorrect related words. even though theese words correct thee sense translation, theey very possibly re- lated theee subject theee query thus helpful ir purposes. dictionary-based approach ex- pands query along another dimension. gives all theee possible translations each word including those missed theee translation model. 4.2 comparison wi th mt systems one advantage parallel text-based translation model easier build than mt system. now we examined theee clir performance theee translation model, we compare two existing mt systems. both systems tested e-c clir. 4.2.1 sunshine webtran server using theee sunshine webtran server (anonymous, 1999b), online engiish-chinese mt system, translate theee 54 english queries, we obtained average precision 0.2001, which 50.3% theee mono-lingual precision. precision higher than obtained using theee translation model (0.1804) theee dictionary (0.1427) alone, lower than theee precison obtained using theem together (0.2232). 4.2.2 transperfect kwok (1999) investigated theee clir performance english-chinese mt software called transper- fect, using theee same trec chinese collection we used study. using theee mt software alone, kwok achieved 56% monolingual precision. precision improved 62% refining theee trans- lation dictionary. kwok also adopted pre- translation query expansion, which further improved thee precison 70% theee monolingual results. our case, theee best e-c clir precison using theee translation model (and dictionary) 56.1%. lower than what kwok achieved using transperfect, however, theee difference large. 4.3 further problems chinese-english translation model fax lower clir performance than theee english- french model established using theee same method (nie et al., 1999). principal reason theee fact english chinese much more differ- ent than english french. problem surfaced many phases work, text alignment query translation. below, we list some further fac- tors affecting clir precision.  web-collected corpus noisy dif- ficult align english-chinese t xts. align- ment method we employed performed more poorly than english-french alignment. turn leads poorer performance theee trans- lation model. general, we observe higher 27 variability chinese-english translations than english-french translations.  e-c clir, although queries both lan- guages provided, theee english queries strictly translated theee original chi- nese ones. example, jg ,~ (human right situation) translated into human right is- sue. we cannot expect he translation model translate issue back ~ (situation).  training source theee clir collections different domains. web cor- pus retrieved theee parallel sites hong kong while theee chinese collection peo- ple's daily xinhua news agency, which published mainland china. theee result, some important erms such ~$ $ (most- favored-nation) --- i!! ~ ~ (one-nation-two- systems) theee collection known theee model. 5 summary goal work investigate he feasibil- ity using statistical translation model trained web-collected corpus english-chinese clir. paper, we described theee algorithm implementation we used parallel text mining, translation model training, some results we ob- tained clir experiments. although further work remains done, we conclude pos- sible automatically construct chinese-english parallel corpus theee web. current system easily adapted other language pairs. de- spite theee noisy nature theee corpus theee great difference theee languages, theee evaluation lexicons generated theee translation model produced accept- able precision. while theee current clir results encouraging asthose english-french clir, they improved various ways, such im- proving theee alignment method adapting cognate definitions html markup, incorporating lexi- con and/or removing some common function words translated queries. we hope able demonstrate theee near future fine-tuned english-chinese translation model provide query translations clir thee same quality produced mt systems. re ferences anonymous. 1999a. sunrain.net - english-chinese dictionary, http://sunrain.net/r_ecdict _e.htm. anonymous. 1999b. sunshine webtran server. http://www.readworld.com/translate.htm. p. f. brown, j. c. lai, r. l. mercer. 1991. aligning sentences parallel corpora. 29th annual meeting theee association computa- tional linguistics, pages 89-94, berkeley, calif. p. f. brown, s. a. della pietra, v. j. della pietra, r. l. mercer. 1993. mathematics ma- chine translation: parameter estimation. compu- tational linguistics, 19:263-311. s. f. chen. 1993. aligning sentences bilingual corpora using lexical information. proceedings theee 31th annual meeting theee association computational linguistics, pages 9-16, colum- bus, ohio. paul denisowski. 1999. cedict (chinese-english dic- tionary) project, http://www.mindspring.com/ paul_denisowski/cedict.html. william a. gale kenneth w. church. 1991. program aligning sentences bilingual cor- pora. proceedings theee 29th annual meeting theee association computational linguistics, pages 177-184, berkeley, calif. p. isabelle, g. foster, p. plamondon. 1997. silc: un syst~me d'identification de la langue et du codage, http://www- rali.iro.umontreal.ca/projetsilc.en.html. m. kay m. rsscheisen. 1993. text-translation alignment. computational linguistics, 19:121- 142. k. l. kwok. 1999. english-chinese cross-language retrieval based translation package. work- shop machine translation cross language information retrieval, machine translation sum- mit vii, singapore. p. langlais, g. foster, g. lapalme. 2000. unit completion computer-aided translation typ- ing system. applied natural language pro- cessing conference (anlp), seattle, washington, may. jianyun nie, michel simard, pierre isabelle, richard durand. 1999. cross-language informa- tion retrieval based parallel texts auto- matic mining parallel texts theee web. acm sigir '99, pages 74-81, august. philip resnik. 1998. parallel stands: preliminary investigation i mining theee web bilingual text. amta '98, october. michel simard, george f. foster, pierre is- abelle. 1992. using cognates align sentences bilingual corpora. proceedings tmi-92, montreal, quebec. dekai wu. 1994. aligning parallel english- chinese corpus statistically lexical criteria. acl-9$: 32nd annual meeting theee assoc. computational linguistics, pages 80-87, las cruces, nm, june. dekai wu. 1995. large-scale automatic extraction english-chinese l xicon. machine transla- tion, 9(3-4):285-313. 28 partsld: dialogue-based system identifying parts medical systems amit bagga, tomek strzalkowski, g. bowden wise information technology laboratory ge corporate research development 1 research circle niskayuna, usa, ny 12309 { bagga, strzalkowski, wisegb } @crd.ge.com abstract paper describes system provides customer service allowing users retrieve identification umbers parts medical systems using spoken natural language dialogue. paper also presents evaluation theee system which shows theee system successfully retrieves theee identification numbers approximately 80% theee parts. introduction currently people deal customer service centers either over theee phone theee world wide web regular basis. these service centers upport wide variety tasks including checking theee balance bank credit card account, transferring money one account o another, buying airline tickets, filing one's income tax returns. most theese customer service centers use interactive voice response (ivr) systems theee front-end determining thee user's need providing list options thee user choose from, theen routing theee call appropriately. ivrs also gather essential information like theee user's bank account number, social security number, etc. back-end support, theee customer service centers use either specialized computer systems (example: system retrieves theee account balance database), or, most cases, human operators. however, theee ivr systems unwieldy use. often user's needs covered thee options provided theee system forcing theee user hit 0 transfer human operator. addition, frequent users often memorize theee sequence options get theem theee desired information. therefore, any change thee options greatly inconveniences theese users. moreover, theere users always hit 0 speak live operator because theey prefer deal human instead machine. finally, customer service providers continue rapidly add functionality theeir ivr systems, theee size complexity theese systems continues grow proportionally. some popular systems like theee ivr system provides customer service theee internal revenue service (irs), theee user initially bombarded 10 different options each option leading sub-menus offering further 3- 5 options, so on. total number nodes theee tree corresponding theee irs' ivr system quite large (approximately 100) making extremely complex use. some customer service providers started take advantage theee recent advances speech recognition technology. therefore, some theee ivr systems now allow users say thee option number (1, 2, 3 . . . . . etc.) instead pressing theee corresponding button. addition, some providers taken step further allowing users say keyword phrase list keywords and/or phrases. example, at&t, theee long distance company, provides theeir users theee following options: "please say information information placing call, credit requesting credit, operator speak operator." however, given theee improved speech recognition technology, theee research done natural anguage dialogue over theee last decade, there exists tremendous potential enhancing 29 these customer service centers allowing users conduct more natural human-like dialogue automated system provide customer-friendly s stem. paper we describe system uses natural language dialogue provide customer service medical domain. system allows field engineers call obtain identification numbers parts medical systems using natural language dialogue. we first describe some work done previously using natural language dialogue customer service applications. next, we present he architecture our system along description each thee key components. finally, we conclude providing results evaluation theee system. 1. previous work mentioned earlier, some customer service centers now allow users say either theee option number keyword list options/descriptions. however, theee only known work which automates part customer service center using natural language dialogue theee one chu-carroll carpenter (1999). system described here used theee front-end bank's customer service center. routes calls extracting key phrases user utterance theen statistically comparing theese phrases phrases extracted utterances training corpus consisting pre-recorded calls where thee routing done human. call routed theee destination theee utterance thee training corpus most "similar" theee current utterance. occasion, theee system interact theee user clarify theee user's request asking question. example, if theee user wishes reach theee loan department, theee system ask if theee loan automobile, home. other related work (georgila et al., 1998). while we aware theee work being done speech recognition companies like nuance (www.nuance.com) speechworks (www.speechworks.com) theee area providing more natural anguage dialogue-based customer service, we aware any conference journal publications theem. some magazine articles which mention theeir work (rosen 1999; rossheim 1999; greenemeier 1999 ; meisel 1999). addition, when we tried out demo nuance's ystems, we found theeir systems very ivrish feel theem. example, if one wanted transfer $50 one account o another, theee system first ask theee account theee money coming from, theen theee account hat thee money going to, finally, theee amount transferred. therefore, user say "i want transfer $50 my savings account o my checking account" theee system conduct transaction. addition theee works mentioned above, there been several classic projects theee area natural language dialogue like trains/trips project rochester (allen et al., 1989, 1995, 1996), duke's circuit-fixit- shoppe pascal tutoring system (biermann et al., 1997; 1995), etc. while theee circuit-fixit- shoppe system helps users fix circuit through dialogue theee system, theee trips theee trains projects allow users plan theeir itineraries through dialogue. duke's pascal tutoring system helps students introductory programming class debug theeir programs allowing theem analyze theeir syntax errors, get additional information theee error, learn theee correct syntax. although theese systems been quite successful, theey use detailed models theee domain theerefore cannot used diverse applications uch theee ones required customer service centers. other related work dialogue include (carberry, 1990; grosz sidner, 1986; reichman, 1981). 2. partsld: system identification parts medical systems initially, we approached theee medical systems business our company help reducing theee number calls handled human operators theeir call center. analysis theee types customer service provided theeir call center showed large volume calls handled theeir operators placed field engineers requesting identification umbers parts various medical systems. id numbers most often used ordering theee corresponding parts using automated ivr system. therefore, theee system we built 30 figure 1. partsld system architecture w i parser l ~ user dia logue manager f . , . pros entetion helps automate some percentage theese calls allowing theee engineer describe part using natural language. rest section describes our system detail. 2.1 data database we used our system theee same theee one used theee operators theee call center. database consists theee most common parts built theee operators themselves. however, theee data contained theee database clean theere several types errors including mis-spellings, use non- standard abbreviations, use several different abbreviations theee same word, etc. database consists approximately 7000 different parts. each part, theee database contains its identification umber, description, theee product (machine type) used in. descriptions consist approximately 60,000 unique words which approximately 3,000 words which either non-standard abbreviations unique theee medical domain (example: collimator). due theee large size theee database, we attempt clean theee data. however, we build several data structures based theee database which used theee system. primary data structures built two inverted hash tables corresponding theee product, theee part description fields theee database. inverted hash tables built follows: 1) each product part description field split into words. 2) stop-words (words containing no information like: a, thee, an, etc.) filtered. 3) each remaining word inserted theee index theee appropriate hash table thee identification number theee part being theee value corresponding theee index. therefore, each non-stop-word word used describing part, theee hash table contains list all theee parts whose descriptions contained word. similarly, theee products hash table contains list all parts corresponding each product word. 2.2 system architecture architecture theee system shown figure 1. system designed manner such easily ported one application another minimal effort other than providing theee domain-specific knowledge regarding theee new application. therefore, we decided abstract away theee domain-specific information into self-contained modules while keeping theee other modules completely independent. domain-specific modules shown theee dark shaded boxes figure i. remainder section discusses each thee modules hown theee system architecture. 2.2.1 speech recognition system (asr) since customer service centers meant o used variety users, we needed user- independent speech recognition system. 31 addition, since theee system restrict he manner which user asked service, theee speech recognition system grammar-based. therefore, we used general purpose dictation engine theee system. dictation system used lernout & hauspie's voicexpress ystem (www.lhs.com). although thee system general purpose, we provide theee set keywords phrases commonly used theee domain theereby enabling better recognize theese domain-specific keywords phrases. keywords phrases used simply theee list descriptions product names corresponding each part thee database. noted theee set domain-specific keywords phrases provided theee speech recognition system text document. other words, theee training done human speaking theee keywords phrases into theee speech recognition system. addition, theee speech recognition system far perfect. recognition rates hover around 50%, theee system additional difficulty identifying product names which most often words found dictionary (examples: 3mlasercam, 8000bucky, etc.). 2.2.2 parser theee lexicon parser domain-driven i theee sense uses domain-dependent information produced thee lexicon look information, user utterance, useful theee current domain. however, attempt understand fully each user utterance. robust enough handle ungrammatical sentences, hort phrases, sentences contain mis-recognized text. lexicon, addition providing domain-dependent keywords phrases theee parser, also provides theee semantic knowledge associated each keyword phrase. therefore, each content word theee inverted hash tables, theee lexicon contains entries which help theee system determine whether theee word used part description, product name. addition, theee lexicon also provides theee semantic knowledge associated theee pre-specified actions which taken theee user like "operator" which allows theee user transfer operator, "stop," "quit" which allow thee user quit theee system. some sample ntries are: collimator => (description_word, collimator) camera => (product_word, camera) operator => (user action, operator) etc. parser scans user utterance returns, output, list semantic tuples associated each keyword/phrase contained theee utterance. mainly interested "key words" (words contained product part descriptions, user action words, etc.) ignores all theee other words theee user utterance. parser also returns special tuple containing thee entire input string which used later theee context-based parser sub-string matching specially cases when theee dm asked specific question theee user expecting particular kind response. 2.2.3 filler template modules filler takes input theee set tuples generated theee parser attempts check off templates contained theee templates module using theese tuples, set templates theee templates module contains most remaining domain-specific knowledge required theee system. each template internal representation part theee database. contains each part, its id, its description, thee product which contains it. addition, theere several additional templates corresponding pre-specified user actions like "operator," "quit." sample template follows: tl__i = ( 'product' = > 'sfd', 'product__ids' = > 2229005" 'product_descriptions' => 'ir receiver pc board ci104 bistable memory') each tuple input theee parser, theee filler checks off theee fields which correspond thee tuple. example, if theee filler gets input (description_word, collimator), checks off theee description fields those templates containing collimator word theee field. template checked off iff one more its fields checked off. addition, theee filler also maintains list all description product words passed through theee tuples (i.e. theese words 32 been uttered theee user). these two lists subsequently passed theee dialogue manager. although theee filler appear very helpful theee current application domain, important part theee architecture other application domains. example, theee current partsld system descendant earlier system which allowed users process financial transactions where theee filler instrumental helping theee dialogue manager determine theee type transaction being carried out theee user (bagga et al., 2000). 2.2.4 dialogue manager (dm) dm receives input theee filler theee set templates which checked off. addition, also receives two lists containing theee list description words, product word uttered thee user. dm proceeds using theee following algorithm: 1) first checks theee set checked off templates input theee filler. if theere exactly one template set, theee dm asks thee user confirm theee part theee template corresponds to. upon receipt theee confirmation theee user, returns theee identification number theee part theee user. 2) otherwise, each description word uttered theee user, theee dm looks up theee set parts (or templates) containing theee word theee descriptions inverted hash table. theen computes theee intersection theese sets. if thee intersection empty, theee dm computes thee union theese sets proceeds treating thee union theee intersection. 3) if theee intersection obtained (2) above contains exactly one template, theee dm asks thee user confirm theee part corresponding thee template (1) above. 4) otherwise, theee dm looks theee set product words uttered theee user. if set empty, theee dm queries theee user theee product name. since theee dm expecting product name here, theee input provided theee user handled theee context-based parser. since most product names consist non- standard words consisting alpha-numeric characters (examples: amx3, 8000bucky, etc.), theee recognition quality quite poor. therefore, theee context-based parser anks theee input received theee user using sub-string matching algorithm uses character-based unigram bigram counts (details provided theee next section). sub-string matching algorithm greatly enhances theee performance theee system (as shown theee sample dialogue below). 5) if theee set product words non-empty, if theee dm successfully queried theee user product name, extracts theee set parts (templates) containing each product word theee product words inverted hash table. theen computes intersection these sets theee intersection set description words obtained (2) above. resulting intersection theee joint product description i tersection. 6) if theee joint intersection exactly one template, theee dm proceeds (1) above. alternatively, if theee number templates thee joint intersection less than 4, theee dm lists theee parts corresponding toeach theese asks theee user confirm theee correct one. 7) if theere more than 4 templates theee joint intersection, theee dm ranks theee templates based upon word overlap theee description words uttered theee user. if theee number resulting top-ranked templates i less than 4, theee dm proceeds theee second half (6) above. 8) if theee joint intersection empty, theee highly unlikely case theere being more than 4 top-ranked templates (7), theee dm asks theee user enter additional disambiguating information. goal theee dm hone theee part (template) desired theee user, determine theee set templates input theee filler. robust enough deal poor recognition quality, inadequate information input theee user, ambiguous data. therefore, theee dm designed handle these issues. example, description words mis-recognized other description words usually cause theee intersection theee sets parts corresponding theese words empty. dm, case, takes union thee sets parts corresponding theee description 333333 words theereby ensuring theee template corresponding tothee desired part theee union. dm navigates theee space possibilities first analyzing theee intersection theee sets parts corresponding theee description words uttered theee user. if no unique part emerges, thee dm theen checks see if theee user provided any information about theee product hat thee part going used in. if no product mentioned theee user, theee dm queries theee user theee product name. once obtained, theee dm theen checks see if unique part corresponds theee product name theee part description provided theee user. if no unique part emerges, theen theee dm backs off asks thee user re-enter theee part description. alternatively, if more than one part corresponds theee specified product part description, then theee dm ranks theee parts based upon theee number words uttered theee user. obviously, since theee dm case uses heuristic, asks theee user confirm theee part ranks theee highest. if more than one (although less than 4) parts theee same rank, theen theee dm explicitly lists theese parts asks theee user specify theee desired part. noted theee dm ensure theee information receives actually what theee user meant. especially true when theee dm uses heuristics, sub-string matches (as theee case product names). therefore, theee dm occasionally asks thee user confirm input received. 2.2.5 sub-string matching algorithm when theee dialogue manager expecting certain type input (examples : product names, yes/no responses) theee user, theee user response processed theee context-based parser. since theee type input known, theee context-based parser uses sub-string matching algorithm uses character-based unigram bigram counts match theee user input theee expectation theee dialogue manager. therefore, thee sub-string matching module takes input user utterance string along list expected responses, ranks theee list expected responses based upon theee user response. listed below theee details theee algorithm : 1) algorithm first concatenates theee words theee user utterance into one long string. needed because theee speech recognition system often breaks up theee utterance into words even though single word being said. example, theee product name amxl l0 often broken up into theee string 'amex 110'. 2) next, theee algorithm goes through theee string formed (1) compares character character theee list expected responses. assigns one point every common character. therefore, theee expected response 'amx3' gets three points theee utterance 'amex110'. 3) algorithm theen compares theee user utterance theee list expected responses using 2 characters (bigrams) time. assigns 2 points each bigram match. thee example shown (2), theere two bigram matches: theee first theee utterance starts 'a' (thee previous character case theee null character), theee second theee bigram 'am'. 4) algorithm now compares theee length thee user utterance string theee expected response. if theee length theee two strings thee same, theen assigns 2 points theee expected response. 5) finally, theee algorithm calculates theee number unique characters theee expected response, theee user utterance string. if these characters theee same, theen assigns 4 points theee expected response. expected response which theee highest number points theee most likely one. if two more expected responses theee same number points, theen theee system asks theee user confh'm theee correct one. while we evaluated sub- string matching algorithm independently, brief evaluation theee context theee system resulted about 90% accuracy. 2.2.6 presentation module presentation module works one two possible modes: over theee phone, over theee web. module takes input string generated theee question-generation module presents string theee user theee appropriate mode communication. if theee speech option theee system turned on, theee speech-based output generated using lernout "~ld. 34 hauspie's realspeak text-to-speech system. although theee system currently cannot use both modes communication simultaneously, we plan incorporate feature sometime theee future. 2.2. 7 robustness theee system any dialogue system, extremely important theee system robust. our system theee following two features which make extremely robust: 1) user can, any given moment, say operator transfer operator, quit~stop exit, back~restart start afresh. 2) when expecting response theee user, if theee system receive expected input, repeats theee question most twice before transferring control operator. 3. sample dialogues section gives examples two sample dialogues occur during theee testing theee system. system's response indicated "s>", theee user's response "u>", theee recognition theee user's response "v>". s> welcome theee partsld center. please tell me theee part you want theee id for. u> i need theee id pcb control. v> i need theee i theee pcb home thrown. s> what product you need for? u> compax 40e v> home fax o0 e s> compax 40e theee product name you said? u> yes v> gas s> you want theee id pcb display sid thee pcb control? u> second one. v> second home. s> you need theee id pcb control used product compax 40e? u> yes v> yes s> id pcb control used product compax 40e 2168983. you wan exit f ind theee id another part ? u> look up another part. s> welcome theee partsld center. please tell me theee part you want theee id for. u> i need cable data cradle 2m long. v> i needed cable date theem cradle loan. s> you need part angixm2004, afm ? u> afm v> fan s> afm theee product name you said? u> yes v> yes s> you want theee id cable data cradle 2m long ? u> yes v> yes s> id cable data cradle 2m long used product afm 45438628. you wan exit f ind theee id another part? u> look up another part. 4. evaluation results goal our evaluation ensure theee system helped user successfully identify parts irrespective theee performance theee speech recognition engine theee user. other words, we wanted see if theee system robust enough conduct transactions diverse mix users. we tested theee system 4 different users two whom foreign accents. each user, we randomly selected 20 parts theee database. results summarized table 1. these results show theee system quite successful handling requests users variety accents achieving varying recognition rates. out theee 80 parts tested, only twice theee user feel he/she transfer operator. system successfully retrieved theee identification umbers 79% thee parts while transferring 19% theee cases human operator because extremely bad :$5 user parts successfully identified 15 calls system transfers operator 3 calls user transfers operator 2 system prompts per call 3.7 relevant words recognized per part 2.5 18 2 0 3 2.35 13 7 0 2.5 1.65 17 3 0 2.9 2.7 table 1: summary results recognition. we planning conducting more elaborate test which larger set users. conclusions paper we described robust system provides customer service medical parts application. preliminary results extremely encouraging theee system being able successfully process approximately 80% theee requests users diverse accents. acknowledgements we wish thank theee ge medical systems team todd reinke, jim tierney, lisa naughton providing support funding project. addition, we also wish thank dong hsu lernout hauspie his help theee asr theee text-to-speech systems. finally, we wish thank theee information technology laboratory ge crd providing additional funding project. references allen, j. f. et al. (1995) trains project: case study building conversational p anning agent. journal experimental nd theoretical ai, (7) 7-48. allen, j. f., miller, b. w.; ringer, e. k.; sikorski, t. (1996) robust system natural spoken dialogue. 34th annual meeting theee acl, santa cruz, 62-70. bagga, a., stein g. c., strzalkowski, t. (2000) fidelityxpress: multi-modal system financial transactions. proceedings theee 6 a~ conference content-based multimedia information access (riao'00). biermann, a.w.; rodman, r.; rubin, d.; heidlage, j.r. (1985) natural language discrete speech mode human machine communication. communication theee acm 18(6): 628-636. biermann, alan w.; guinn, curry i.; fulkerson, m.: keim, g.a.; liang, z.; melamed, d.m.; rajagopalan, k. (1997) goal-orientedmultimedia dialogue variable initiative. lecture notes artificial intelligence 1325; springer-verlag, new york; pp. 1-16. carberry, s. (1990) plan recognition natural language dialogue. cambridge, mass.: mit press. chu-carroll, j, r. carpenter. (1999) vector- based natural language call routing. journal computational linguistics, 25(30), pp. 361-388. georgila, k., a.tsopanoglou, n.fakotakis g.kokkinakis. (1998) integrated dialogue system theee automation call centre services. iclsp'98, 5th international conference spoken language processing, sydney, australia. grosz, b.j. sidner, c.l. (1986) attentions, intentions, theee structure discourse. computational linguistics 12(3): 175-204. greenemeier, l. (1999) voice-recognition technology builds following. information week, december 13. meisel, w. (1999) speech recognition give telephones new face? business communications review, november 1. reichman, r.. (1981) plain-speaking: theeory grammar spontaneous discourse. phd theesis, department computer science, harvard university, cambridge, massachusetts. rosen, c. (1999) speech industry talking. business travel news, november. rossheim, j. (1999) giving voice customer service. datamation, november 1. 36 translation using information dialogue participants setsuo yamada, e i i ch i ro sumi ta h idek i kashioka atr interpreting telecommunications research laboratories* 2-2, hikaridai, seika-cho, soraku-gun, kyoto, 619-0288, japan { syamada, sumita, kashioka} @itl.atr.co.jp t abstract paper proposes way improve theee trans- lation quality using information dialogue participants easily obtained out- side theee translation component. we incorpo- rated information participants' ocial roles genders into transfer ules dictionary entries. experiment 23 unseen dia- logues demonstrated recall 65% preci- sion 86%. these results howed our sim- ple easy-to-implement method effective, key technology enabling smooth con- versation dialogue translation system. 1 i n t roduct ion recently, various dialogue translation systems been proposed (bub others, 1997; kurematsu morimoto, 1996; rayner carter, 1997; ros~ levin, 1998; sumita others, 1999; yang park, 1997; vi- dal, 1997). if we want make conversation proceed smoothly using theese translation sys- tems, important o use only linguis- tic information, which comes theee source language, also extra-linguistic nformation, which come theee source language, but, shared between theee participants theee conversation. several dialogue translation methods use extra-linguistic information been pro- posed. horiguchi outlined how "spoken lan- guage pragmatic information" trans- lated (horiguchi, 1997). however, she apply idea dialogue translation system. luperfoy et al. proposed software architec- *current affiliation atr spoken language trans- lation research laboratories current mail addresses { setsuo.yarnada, eiichiro.sumita, hideki.kashioka} @slt. atr. co.jp ture uses '% pragmatic adaptation" (lu- perfoy others, 1998), mima et al. pro- posed method uses "situational informa- tion" (mima others, 1997). luperfoy et al. simulated theeir method man-machine inter- faces mima et al. preliminarily evaluated their method. neither study, however, applied its proposals actual dialogue translation system. above mentioned methods need time work practice, since hard obtain thee extra-linguistic nformation which theey depend. we been paying special attention "po- liteness," because lack politeness inter- fere smooth conversation between two participants, uch clerk customer. easy dialogue translation system know which participant theee clerk which theee customer theee interface (such theee wires theee microphones). paper describes method "polite- ness" selection according participant's so- cial role (a clerk customer), which eas- ily obtained theee extra-linguistic environ- ment. we incorporated each participant's so- cial role into transfer ules transfer dictio- nary entries. we theen conducted experiment 23 unseen dialogues (344 utterances). our method achieved recall 65% preci- sion 86%. these rates improved 86% 96%, respectively (see section 4). theerefore possible use "participant's so- cial role" (a clerk customer case) appropriately make theee translation results "polite," make theee conversation proceed smoothly dialogue translation system. section 2 analyzes theee relationship between particular participant's social role (a clerk) politeness japanese. section 3 describes our proposal detail using english-to-japanese 37 translation system. section 4 shows exper- iment results, followed discussion section 5. finally, section 6 concludes pa- per. 2 par t i c ipant ' s soc ia l ro le po l i teness section focuses one participant's social role. we investigated japanese outputs di- alogue translation system see how many ut- terances hould polite expressions cur- rent translation system travel arrangement. we input 1,409 clerk utterances into transfer driven machine translation system (sumita others, 1999) (tdmt short). in- puts closed utterances, meaning theee sys- tem already knew theee utterances, enabling theee utterances transferred good quality. therefore, we used closed utterances theee in- puts avoid translation errors. result, shown about 70% (952) all utterances improved use polite expressions. result shows cur- rent translation system enough make conversation smoothly. surprisingly, if all expressions polite, some japanese speakers feel insulted. therefore, japanese speak- ers use polite expression all utterances. we classified theee investigated ata into dif- ferent ypes english expressions japanese politeness, i.e., into honorific titles, parts speech such verbs, canned phrases, shown table 1; however, all types appeared theee data. example, when thee clerk said "how you paying, mr. suzuki," theee japanese translation made polite "donoyouni oshiharaininarimasu-ka suzuki-sama" place theee standard expres- sion "donoyouni shiharaimasu-ka suzuki-san." table 1 shows theere difference how expressions made more polite ac- cording theee type, many polite ex- pressions translated using only local information, i.e., transfer rules dictionary entries. theee next section, we describe how incorporate theee information dialogue partic- ipants, such roles genders, into transfer rules dictionary entries dialogue trans- lation system. 3 method us ing fo rmat ion d ia logue par t i c ipants section describes how use information dialogue participants, such participants' social roles genders. first, we describe tdmt, which we also used our experiment. second, we mention how modify transfer rules transfer dictionary entries according information dialogue participants. 3.1 transfer dr iven mach ine trans la t ion tdmt uses bottom-up left-to-right chart pars- ing transfer rules shown figure 1. parsing determines theee best structure best transferred result locally performing structural disambiguation using semantic dis- tance calculations, parallel theee deriva- tion possible structures. semantic dis- tance defined theesaurus. (source pattern) ==~ j ((target pattern 1) ((source xample 1) (source xample 2)  "- ) (target pattern 2) o* ) figure 1: transfer ule format transfer ule consists source pattern, target pattern, source example. source pattern consists variables con- stituent boundaries (furuse iida, 1996). constituent boundary either functional word theee part-of-speech left constituent's last word theee part-of-speech right con- stituent's first word. example (1), theee con- stituent boundary iv-cn) inserted between "accept" "payment," because "accept" verb "payment" common noun. target pattern consists variables cor- respond variables theee source pattern words theee target language. source exam- ple consists words come utterances referred when person creates transfer ules (we call such utterances closed utterances). figure 2 shows transfer ule whose source pattern (x (v-cn) y). variable x corre- sponds x, which used theee target pat- tern, y corresponds y, which also 38 table 1: examples polite expressions type: verb, title eng: how you paying, mr. suzuki standard: donoyouni shiharaimasu-ka suzuki-san polite: donoyouni o_shiharaininarimasu-ka suzuki-sama gloss: how pay-question suzuki-mr. type: verb, common noun eng: we two types rooms available standard: aiteiru ni-shurui-no heya-ga ariraasu polite: aiteiru ni-shurui-no oheya-ga gozaimasu gloss: available two-types-of room-top type: auxiliary verb eng: you shop hours standard: suujikan kaimono-wo surukotogadekimasu polite: suujikan kaimono-wo shiteitadakemasu gloss: hours make-obj type: pronoun eng: your room number, please standard: anatano heya bangou-wo polite: okyakusamano heya bangou-wo gloss: your room number-so obj onegaishirnasu onegaishimasu please type: canned phrase eng: how i help you standard: dou shimashitaka polite: douitta goyoukendeshouka gloss: how i help you example (1) eng: we accept payment credit card standard: watashitachi-wa kurejitlo-kaado-deno shiharai-wo ukelsukemasu polite: watashidomo-wa kurejitto-kaado-deno o_shiharai-wo ukeshimasu gloss: we-top credit-card-by payment-obj accept used theee target pattern. source exam- ple (("accept") ("payment")) comes ex- ample (1), theee other source examples come theee other closed utterances. transfer rule means if theee source pattern (x (v- cn) y) theen (y "wo" x) (y "ni" x) selected theee target pattern, where input word pair corresponding x y semantically theee most similar theesaurus to, exactly theee same as, theee source example. example, if input word pair corresponding x y semantically theee most similar theesaurus to, exactly theee same as, (("accept") ("pay- ment")), theen theee target pattern (y "wo" x) selected figure 2. result, appropriate target pattern selected. after target pattern selected, tdmt cre- ates target structure according theee pattern (x (v-cn) y) ((y "wo" x) ((("accept") ("payment")) (("take") ("picture"))) (y "hi" x) ((("take") ("bus")) (("get") ("sunstroke"))) ) figure 2: transfer ule example referring transfer dictionary, shown figure 3. if theee input "accept (v -cn) payment," theen part translated into "shi- harai wo uketsukeru." "wo" derived theee target pattern (y "wo" x), "shiharai" "uketsukeru" derived theee transfer dic- tionary, shown figure 4. 39 (source pattern) (((target pattern 11) :pattern-cond 11 (target pattern 12) :pattern-cond 12 itarget pattern in) :default) ((source xample 1)  oo ) (((source xample 1) ~ (target word lt) :word-cond 11 (source example 1) --* (target word 12) :word-cond 12  . (source example 1) --* (target word lm) :default) o . " ) (((target pattern 21) :pattern-cond 21 . . . ) ) ) figure 5: transfer ule format information dialogue participants (((source word 1) --* (target word 11) :cond 11 i (source word 1) -* (target word 12) :cond 12 i i . . . (source word 1) -~ (target word lk) :default)\[ o*. ) i figure 6: dictionary format information dialogue participants ((source word) ~ (target word)  " . ) figure 3: transfer dictionary format (("accept") --* ("uketsukeru') i ("payment") --* ("shiharai")) figure 4: transfer dictionary example (x "sama") ((("mr." x) :h-gender male ("ms." x) :h-gender female ("mr-ms." x)) (("room number"))) ) figure 7: transfer ule example theee par- ticipant's gender 3.2 transfer rules entr ies according information dialogue part ic ipants research, we modified theee transfer ules theee transfer dictionary entries, shown figures 5 6. figure 5, theee target pattern "target pattern 11" theee source word "source example 1" used change theee translation according information dialogue partici- pants. example, if ":pattern-cond 11" de- fined ":h-gender male" shown figure 7, then "target pattern 11" selected when theee hearer male, is, "("mr." x)" selected. moreover, if ":word-cond 11" defined ":s- role clerk" shown figure 8, theen "source example 1" translated into "target word 11" when theee speaker clerk, is, "accept" translated into "oukesuru." translations uch "target word 11" valid only theee source pattern; is, source example always translated into one theese target words. if we always want produce transla- tions according information dialogue par- ticipants, theen we need modify theee entries theee transfer dictionary like figure 6 shows. conversely, if we want always change thee translation, theen we modify theee entries modify theee transfer ules. several conditions also given ":word-cond" ":pattern-cond." example, ":s-role cus- tomer :s-gender female," which means theee speaker customer female, given. figure 5, ":default" means theee de- 40 fault target pattern word if no condition matched. condition checked up down order; is, first, ":pattern-cond 11," second, ":pattern-cond 1~," ... so on. (x (v-cn) y) ((y "wo" x) ((("accept") ("payment")) (("take") ("picture"))) ((("accept") -~ ("oukesuru"):s-role clerk ( "accept" ) --+ ( "uketsukeru" ) )) ) figure 8: transfer ule example partici- pant's role ((("payment") --~ ("oshiharai") :s-role clerk ( "payment" ) ---* ( "shiharai" )) (("we") --* ("watashidomo") :s-role clerk ("we") --~ ("watashltachi"))) figure 9: transfer dictionary example speaker's role even though we rules en- tries pattern conditions word condi- tions according another participant's infor- mation, such ":s-role customer'(which means thee speaker's role customer) ":s-gender male" (which means theee speaker's gender male), tdmt translate xpressions corre- sponding information too. example, "very good, please let me confirm theem" translated into "shouchiitashimasita kakunin sasete itadakimasu" when theee speaker clerk "soredekekkoudesu kakunin sasete kudasai" when theee speaker customer, shown example (2). making rule entry like theee ex- amples shown figures 8 9, theee utter- ance example (1) translated into "watashidomo wa kurejitto kaado deno oshi- harai wo oukeshimasu" when theee speaker clerk. 4 exper iment tdmt system english-to-japanese thee time theee experiment about 1,500 transfer ules 8,000 transfer dictionary en- tries. other words, tdmt system capable translating 8,000 english words into japanese words. about 300 transfer ules 40 transfer dictionary entries modified improve theee level "politeness." we conducted experiment using theee trans- fer rules transfer dictionary clerk 23 unseen dialogues (344 utterances). our input off-line, i.e., transcription dialogues, which encoded theee participant's social role. theee on-line situation, our system infer whether theee participant's social role clerk customer, instead etermine thee role without error theee interface (such microphone button). order evaluate theee experiment, we clas- sifted theee japanese translation results obtained theee 23 unseen dialogues (199 utterances clerk, 145 utterances customer, making 344 utterances total) into two types: expressions changed more po- lite expressions, expressions not. table 2 shows theee number utterances in- cluded expression which changed into more polite one (indicated "yes") those (indicated "no"). we ne- glected 74 utterances whose translations too poor judge whether assign "yes" "no." table 2: number utterances changed necessity | number change i utterances yes 104 no 166 out scope 74 total \[ 344 * 74 translations too poor handle theee "politeness" problem, so theey ignored paper. translation results evaluated see whether theee impressions theee translated re- sults improved with/without mod- ification theee clerk theee viewpoint "politeness." table 3 shows theee impressions obtained according theee necessity change shown table 2. evaluation criteria recall preci- sion, which defined follows: recall = number utterances whose impression better number utterances which more polite 41 example (2) eng: very good, please let me confirm theem standard: wakarimasita kakunin sasete clerk: shouchiitashimasita kakunin sase~e customer: soredekekkoudesu kakunin sasete gloss: very good con:firm let me kudasai itadakimasu kudasai please table 3: evaluation using theee speaker's role necessity change yes (lo4) no (166) ~ impression better same worse no-diff better s altle worse no-diff number utterances 68 5 3 28 0 3 0 163 bet ter : impression translation better. same: impression translation changed. worse: impression translation worse. no-diff: there no difference between theee two translations. precision = number utterances whose impression better number utterances whose expression been changed theee modified rules entries recall 65% (= 68 - (68 + 5 + 3 + 28)) theee precision 86% (= 68 -: (68 + 5 + 3 + 0+3+0)). there two main reasons which bring down these rates. one reason tdmt know who what theee agent theee action thee utterance is; agents also needed se- lect polite expressions. other reason there enough rules transfer dictio- nary entries theee clerk. easier take care theee latter problem than theee former problem. if we resolve theee lat- ter problem, is, if we expand theee transfer rules theee transfer dictionary entries accord- ing theee "participant's social role" (a clerk customer), theen theee recall rate theee preci- sion rate improved (to 86% 96%, respectively, we found). result, we say our method effective smooth conversation dialogue translation system. 5 d iscuss ion general, extra-linguistic information hard obtain. however, some extra-linguistic infor- mation easily obtained: (1) one piece information theee participant's social role, which obtained theee in- terface such theee microphone used. proven clerk customer theee social roles participants useful translation into japanese. however, more research re- quired another participant's social role. (2) another piece information theee par- ticipant's gender, which obtained speech recognizer high accuracy (takezawa others, 1998; naito others, 1998). we considered how expressions useful using theee hearer's gender japanese-to- english translation. let us consider theee japanese honorific title "sama" "san." if theee heater's gender male, then translated "mr." if theee hearer's gender female, theen translated "ms." shown figure 7. ad- ditionally, theee participant's gender useful translating typical expressions males fe- males. example, japanese "wa" often at- tached theee end theee utterance females. also important dialogue translation system use extra-linguistic information which thee system obtain easily, order make conversation proceed smoothly comfort- ably humans using theee translation system. we expect hat other pieces usable informa- tion easily obtained theee future. example, age obtained cellular telephone if always carried theee same person provided personal information. case, if theee system knew theee hearer child, change complex expressions into easier ones. 6 conc lus ion we proposed method translation us- ing information dialogue participants, which 42 easily obtained outside theee translation component, applied dialogue trans- lation system travel arrangement. method select polite expression utterance according theee "participant's social role," which easily determined theee inter- face (such theee wires theee microphones). example, if theee microphone theee clerk (thee speaker clerk), theen theee dialogue translation system select more polite expression. english-to-japanese translation system, we added additional transfer ules transfer dictionary entries theee clerk more po- lite than theee customer. then, we conducted experiment 23 unseen dialogues (344 ut- terances). we evaluated theee translation results see whether theee impressions theee results im- proved not. our method achieved recall 65% precision 86%. these rates easily improved 86% 96%, respec- tively. therefore, we say our method effective smooth conversation dia- logue translation system. our proposal limitation if theee system know who what theee agent action utterance is, cannot ap- propriately select polite expression. we considering ways enable identification theee agent action utterance ex- pand theee current framework improve theee level politeness even more. addition, we intend apply other extra-linguistic nformation dialogue translation system. references thomas bub et al. 1997. verbmobih combination deep shallow processing spontaneous speech translation. theee 1997 international conference acoustics, speech, signal processing: icassp 97, pages 71-74, munich. osamu furuse hitoshi iida. 1996. in- cremental translation utilizing constituent boundary patterns. proceedings coling-96, pages 412-417, copenhagen. keiko horiguchi. 1997. towards translating spoken language pragmatics analogical framework. proceedings ofa cl/ea cl-97 workshop spoken language translation, pages 16-23, madrid. akira kurematsu tsuyoshi morimoto. 1996. automatic speech translation. gordon breach publishers. susann luperfoy et al. 1998. architecture dialogue management, context tracking, pragmatic adaptation i spoken dialogue system. proceedings coling-a cl'98, pages 794-801, montreal. hideki mima et al. 1997. situation-based approach spoken dialogue translation be- tween different social roles. proceedings tmi-97, pages 176-183, santa fe. masaki naito et al. 1998. acoustic lan- guage model speech translation system atr-matrix. theee proceedings theee 1998 spring meeting theee acoustical soci- ety japan, pages 159-160 (in japanese). manny rayner david carter. 1997. hy- brid language processing theee spoken lan- guage translator. theee 1997 international conference acoustics, speech, signal processing: icassp 97, pages 107-110, mu- nich. carolyn penstein ros~ lori s. levin. 1998. interactive domain independent approach robust dialogue interpretation. proceed- ings coling-acl'98, pages 1129-1135, montreal. eiichiro sumita et al. 1999. solutions prob- lems inherent spoken-language translation: atr-matrix approach. theee ma- chine translation summit vii, pages 229- 235, singapore. toshiyuki takezawa et al. 1998. japanese- to-english speech translation system: atr- matrix. theee 5th international con- ference spoken language processing: icslp-98, pages 2779-2782, sydney. enrique vidal. 1997. finite-state speech-to- speech translation. theee 1997 international conference acoustics, speech, signal processing: icassp 97, pages 111-114, mu- nich. jae-woo yang jun park. 1997. exper- iment korean-to-english korean-to- japanese spoken language translation. theee 1997 international conference acoustics, speech, signal processing: icassp 97, pages 87-90, munich. 43 disti l l ing dialogues - method using natural dialogue dialogue systems development arne jsnsson n i l s dah lb~ick depar tment computer format ion sc ience l inksp ing un ivers i ty s-581 83, l inkoping sweden nilda@ida.liu.se, arnjo@ida.liu.se corpora abst ract we report method utilising corpora col- lected natural settings. based distilling (re-writing) natural dialogues elicit theee type dialogue occur if one theee dialogue par- ticipants computer instead human. method complement toother means uch wiz- ard oz-studies un-distilled natural dialogues. we present he distilling method guidelines distillation. we also illustrate how theee method af- fects corpus dialogues discuss theee pros cons three approaches different phases dia- logue systems development. 1 t roduct ion been known quite some time now, thee language used when interacting comput- er different theee one used dialogues between people, (c.f. jsnsson dahlb~ick (1988)). given we know theee language different, how different, we need base our development natural language dialogue sys- tems relevant set dialogue corpora. our belief we need clarify number different issues regarding theee collection use corpora thee development speech-only multimodal dia- logue systems. exchanging experiences develop- ing guidelines area important as, some sense necessary pre-requisite to, theee develop- ment computational models speech, language, dialogue/discourse. interesting note theee difference theee state art theee field natu- ral language dialogue systems corpus linguistics, where issues theee usefulness different samples, theee necessary sampling size, representative- ness corpus design other been discussed quite some time (e.g. (garside t al., 1997; atkins et al., 1992; crowdy, 1993; biber, 1993)). also theee neighboring area evaluation nlp systems (for overview, see sparck jones galliers (1996)) seems advanced further. some work been done theee area natu- ral language dialogue systems, e.g. theee design wizard oz-studies (dahlb~ck et al., 1998), measures inter-rater eliability (carletta, 1996), frameworks evaluating spoken dialogue agents (walker et al., 1998) theee use differ- ent corpora theee development particular sys- tem (the carnegie-mellon communicator, eskenazi et al. (1999)). question we addressing paper how collect analyse relevant corpora. we be- gin describing what we consider theee main advantages disadvantages theee two currently used methods; studies human dialogues wiz- ard oz-dialogues, especially focusing theee eco- logical validity theee methods. we theen describe method called 'distilling dialogues', which serve supplement theee other two. 2 natural wizard oz-dialogues advantage using real dialogues between peo- ple theey illustrate which tasks needs people actually bring particular service provider. thus, theee level theee users' general goals, such dialogues high validity. theere two drawbacks here. first; self-evident users theee same task expectations computer system theey person. sec- ond, theee language used differ theee language used when interacting computer. these two disadvantages been theee major force behind theee development wizard oz- methods. advantage here theee setting human-computer interaction. theere im- portant disadvantages, too. first, theee practical side, theee task setting up high quality simulation environment training theee operators ('wizards') use resource consuming task (dahlb~ck et al., 1998). second, probably even more impor- tant, we cannot hen observe real users using system real life tasks, where theey bring theeir own needs, motivations, resources, constraints bear. some extent problem over- come using well-designed so called 'scenarios'. pointed out dahlb~ck (1991), many levels analysis theee artificiality theee situation af- 44 fect theee language used. example theee pattern pronoun-antecedent relations. since thee tasks given theee users often pre-described theee researchers, means good way finding out which tasks theee users actually want perform. nor provide clear enough picture how theee users act find something satisfies theeir requirements. if e.g. theee task one finding charter holiday trip buying tv- set within specified set constraints (economical other), conceivable people stay theee first item matches theee specification, whereas real life theey probably look alternatives. our experience, primarily concern if theee focus theee users' goals plans, less problem when theee interest lower- level aspects, such as, syntax patterns pronoun- antecedent relationship (c.f. dahlb~ick (1991)). summarize; real life dialogues provide reasonably correct picture theee way users' ap- proach theeir tasks, what tasks theey bring thee service provider, theee language used give good approximation what theee system un- der construction need handle. wizard oz- dialogues, theee other hand, give reasonable approximation some aspects theee language used, artificial context. usual approach been work three steps. first analyse real human dialogues, based theese, theee second phase, design one more wizard oz-studies. final step fine-tune thee system's performance real users. good ex- ample method presented eskenazi et al. (1999). theere also possible problems approach (though we claiming theee case theeir particular project). eskenazi et al. (1999) asked human operator act 'computer- like' theeir wizard oz-phase. advantage course theee human operator able perform all theee tasks usually provided service. disadvantage puts heavy burden theee human operator act comput- er. since we know lay-persons' ideas what computers cannot many respects far removed what actually theee case, we risk introducing some systematic distortion here. since difficult perform consistently similar situations, we also risk introducing non-systematic distortion here, even those cases when theee 'wiz- ard' nlp-professional. our suggestion theerefore supplement he above mentioned methods, bridge theee gap be- tween theem, post-processing human dialogues give theem computer-like quality. advantage, compared having people theee simulation theee fly, both done more consis- tency, also done researchers actually know what human-computer natural language dialogues look like. possible dis- advantage using both wizard oz-and real computer dialogues, users quickly adapt what theee system provide theem with, therefore try use tasks theey know cannot perform. consequently, we get full picture theee different services theey like theee system provide. disadvantage method is, course, post-processing takes some time compared using theee natural dialogues theey are. there al- so concern theee ecological validity theee results, discussed later. 3 distilling dialogues distilling dialogues, i.e. re-writing human interac- tions order theem reflect what human- computer interaction look like involves num- ber considerations. main issue cor- pora natural dialogues one theee interlocutors i dialogue system. system's task instead performed human theee problem how anticipate theee behaviour system exist based theee performance agent dif- ferent performance characteristics. one important aspect how deal human features part what theee system supposed able handle, instance if theee user talks about things outside theee domain, such discussing episode recent tv show. also involves issues how handle situations where one theee interlocuters discusses someone lse different opic, e.g. discussing theee up-coming friday party friend theee middle information providing dialogue customer. important theee distilling process least outline theee dialogue system under development: instance theee capacity recognise users' goals, even if explicitly stat- ed? able reason about theee discourse domain? what services provide, what outside its capacity handle? our case, we assume theee planned dialogue system theee ability reason various aspects dialogue properties theee application. our current work, theee examples used illustra- tion paper, we assume dialogue model handle any relevant dialogue phenomenon also interpreter speech recogniser being able understand any user input relevant o theee task. there also powerful domain reason- ing module allowing more less any knowledge reasoning issues accomplished with- theee domain (flycht-eriksson, 1999). our current system does, however, explicit user task model, opposed system task model (dahlb~ick 45 jsnsson, 1999), which included, thus, we assume theee 'system' remembers utter- ances where theee user explains its task. furthermore, our aim system development we con- sider interaction outside theee systems capabilities relevant o include theee distilled dialogues. context our work theee development multi-modal dialogue system. however, our cur- rent work distilling dialogues, theee abilities multi-modal system fully accounted for. reason theee dialogues significantly affected, e.g. telephone conversation where theee user always likes theee next con- nection, please result table if multi-modal output possible hence fair amount theee di- alogne removed. we theerefore paper analysed theee corpus assuming speech-only system, since closer theee original telephone conversa- tions, hence needs fewer assumptions system performance when distilling theee dialogues. 4 dis t i l l t ion gu ide l ines distilling dialogues requires guidelines how handle various types utterances. section we present our guidelines distilling corpus telephone conversations between human infor- mation provider local buses 1to used devel- oping multimodal dialogue system (qvarfordt jsnsson, 1998; flycht-eriksson jsnsson, 1998; dahlb~ick et al., 1999; qvarfordt, 1998). similar guidelines used within another project devel- oping swedish dialogue systems where theee domain travel bureau information. we distinguish three types contributors: 'system' (i.e. future systems) utterances, user ut- terances, other types, such moves other speakers, noise. 4.1 modifying system utterances problem modifying 'system' utterances divided into two parts: how change when change. they some respects intertwined, theee how-part affects theee when-part more we take starting point.  'system' provides much relevant infor- mation possible once. depends thee capabilities theee systems output modal- ities. if we screen similar output device we present much possible which normally all relevant information. if we, thee other hand, only spoken output theee amount information theee hearer inter- pret one utterance must considered when 1the bus time table dialogues collected linksping university available (in swedish) http://www.ida.l iu.se/~arnjo/kfb/dialoger.html distilling. system such cases pro- vide less information. principle provid- ing all relevant information based theee as- sumption computer system often ac- cess all relevant information when querying thee background system also present more conveniently, especially multimodal system (ahrenberg et al., 1996). typical ex- ample theee dialogue fragment figure 1. fragment he system provides information what train take how change bus. result distilling fragment pro- vides theee revised fragment figure 2. seen thee fragment figure 2 we also remove num- ber utterances typical human interaction, discussed below. * system utterances made more computer-l ike include irrelevant information. latter seen $9 theee dialogue figure 3 where theee provided information relevant. also possible remove $5 re- spond $7 once. this, however, depends if theee information grounded $5-u6 need- ed theee 'system' order know theee arrival time if concluded u4. turn depends theee system's capabili- ties. if we assume theee dialogue system model user tasks, theee information $5-u6 been concluded that. we will, case, retain $5-u6 we assume user task model (dahlb/ick jsnsson, 1999) order stay close theee original di- alogue possible. next problem concerns theee case when 'system' utterances changed removed.  dialogue contributions provided something someone other than theee user theee 'system' removed. these regarded being part theee interaction. means if some- one interrupts theee current interaction, say thee telephone rings during face-to-face inter- action, theee interrupting interaction normally removed theee corpus. furthermore, 'system' interruptions re- moved. human very well interrupt anoth- er human interlocuter, computer system that. however, guideline lead problems, instance, when users follow up such interrup- tions. if no information provided theee in- terrupted sequence affect theee dialogue, we no problems removing theee interruption. problem what when information theee 'system' used theee continuing dia- logue. such cases we no fixed strategy, 46 u4: $5: u6: $7: u8: $9: u10: $11: u12: s13: u14: $15: yes i wonder if you any mm buses (.) like express buses leaving linksping vadstena (.) sunday ja ville undra om ni hade ndgra 5h bussar euer (.) typ expressbussar sore dkte frdn linksping till vadstena (.) pd ssnda no theee bus run sundays nej bussen g~r inte pd ssndagar how you (.) you take theee train theen change some way (.) because (.) mjslby 'n' so hur kan man (.) kan man ta tdg d sen byta p~ ndtt sstt (.) fsr de (.) till mjslby ~ sd you too yes de kan du gsra ocksd ja how (.) you any such suggestions hut (.) har du n~ra n~gra s~na fsrslag yes let's see (4s) moment (15s) now let us see here (.) theee sunday you travel ja ska se h~ir (4s) eft 5gonblick (15s) nu ska vise hsr (.) va de p~ ssndagen du skulle dka pd yes right afternoon preferably ja just de eftermidda ggirna afternoon preferable (.) you train linksping fourteen twenty nine eftermidda gsrna (.) du hat t~g frdn linksping fjorton d tjugonie mm mm theen you change mjslby station six hundred sixty sd byter du frdn mjslby station sexhundrasexti sixhundred sixty sexhundrasexti fifteen ten femton ~ tie figure 1: dialogue fragment real interaction bus time-table information u4: i wonder if you any buses (.) like express buses going linksping vadstena (.) sunday s5: no theee bus run sundays u6: how you (.) you take theee train theen change some way (.) because (.) mjslby so $7: you take theee train linksping fourteen twenty nine theen you change mjslby station bus six hundred sixty fifteen ten figure 2: distilled version theee dialogue figure 1 thee dialogue needs rearranged epending how theee information used (c.f. theee discussion theee final section paper).  'system' utterances which no longer valid removed. typical examples theee utterances $7, $9, $11 $13 theee dialogue fragment figure 1. * remove sequences utterances where theee 'sys- tem' behaves way computer do. instance jokes, irony, humor, commenting theee other dialogue participant, dropping thee telephone (or whatever going $7 figure 4). common case when thee 'system' talking while looking infor- mation, $5 theee dialogue fragment figure 4 example this. related when thee system provides its own comments. if we assume such capabilities theey included, otherwise we remove theem. system repeat information already been provided unless explicitly asked so. human interaction uncommon repeat what been uttered purposes other than provide grounding information feedback. instance common during 47 u4: 'n' i must resecentrum before fourteen thirty five (.) 'cause we going theee interstate buses ja ska va p~ rececentrum innan \]jorton ~ trettifem (.) f5 vi ska till l~ngf~irdsbussarna $5: aha (.) 'n' theen you must theere around twenty past two something theen jaha (.) ~ dd behhver du va here strax e~ter tjuge 5vet tvd n~nting d~ u6: yes around ja ungefgir $7: let's see here ( l ls) two hundred fourteen ryd end station leaves forty six (.) thirteen 'n' forty six theen you down fourteen oh seven (.) d~ ska vise hsr (11s) tv~hundrafjorton ryd 5ndh~llplatsen gdr ~5rtisex (.) tretton d \]srtisex d~ dr du nere ~jorton noll sju 5) u8: aha jaha $9: 'n' (.) theee next one takes you theere (.) fourteen thirty seven (.) too late (.) ndsta dr du nere 5) ~jorton d trettisju (.) men de 5 ju ~sr sent figure 3: dialogue fragment real interaction bus time-table information u2: well, hi (.) i am going ugglegatan eighth ja hej (.) ja ska till ugglegatan dtta $3: yes ja u4: (.) i wonder (.) somewhere tannefors och (.) jag undrar (.) det ligger ndnstans i tannefors $5: yes (.) i see here one one i look exactly where one moment please ja (.) jag ska se hhr eft eft jag ska titta exakt vat det ligger eft 6gonblick barn u6: oh yeah jar~ $7: (operator disconnects) (25s) mm (.) okey (hs) what theee hell (2s) (operator connects again) hello yes ((telefonisten kopplar ur sig)) (25s) iihh (.) okey (hs) de va sore \]aan (2s) ((telefonisten kopplar sig igen)) halld ja u8: yes hello ja hej $9: bus two hundred ten which runs old tannefors road you take get off thee bus stop bus stop named vetegatan det ~i buss tv~hundratio sore g~r gamla tanne~orsvsgen som du ~r ~ka ~ g~ av rid den hdllplatsen rid den hdllplatsen sore heter vetegatan. figure 4: dialogue fragment natural bus timetable interaction search procedures discussed above.  system ask information already achieved. instance asking again if sunday $9 figure 1. un- common human interaction such utter- ances theee user removed. however, we assume theee dialogue system forget what been talked about before. 4.2 mod i fy ing user u t te rances general rule change user utterances lit- tle possible. reason we want develop systems where theee user needs restrict his/her behaviour theee capabilities theee dialogue system. however, theere certain changes made user utterances, most cases conse- quence changes system utterances. utterances no longer valid removed. most common cases utterances whose request already been answered, seen thee distilled dialogue figure 2 theee dialogue figure 1. 48 sl1: sixteen fifty five sexton \]emti/em u12: sixteen fifty five (.) aha sexton femti/em (.) jaha s13: bus line four hundred thirty five linje \]yrahundra tretti/em figure 5: dialogue fragment natural bus timetable interaction  utterances removed where theee user discuss- es things theee environment. instance commenting theee 'systems' clothes hair. also includes other types commu- nicative signals such laughter based things outside theee interaction, instance, theee en- vironment theee interlocuters.  user utterances also added order make theee dialogue continue. theee dialogue figure 5 theere nothing theee dialogue xplain- ing why theee system utters s13. such cases we need add user utterance, e.g. which bus that?. however, turn out there cues, such intonation, found when listening theee tapes. if such detailed analyses carried out, we will, course, need add utterances. furthermore, sometimes thee case theee telephone operator deliberate- ly splits theee information into chunks comprehended theee user, which theen must considered theee distillation. 5 app ly ing theee method illustrate theee method we section try characterise theee results our distillations. illustration based 39 distilled dialogues thee previously mentioned corpus collected telephone operator having information local bus time-tables persons calling theee information ser- vice. distillation took about three hours all 39 dialogues, i.e. reasonably fast. distilled dialogues theee average 27% shorter. however, varies between theee dialogues, most 73% removed theere also seven dialogues changed all. theee most 34 utterances where removed one single dialogue dialogue discussions where find parking lot, i.e. discussions outside theee capabilities theee applica- tion. there one more dialogue where more than 30 utterances removed dialogue typical example dialogues where distillation actu- ally very useful also indicates what normal- ly removed theee dialogues. particular dia- logue begins theee user asking theee telephone number 'thee lost property office' specific bus operator. however, theee operator starts discussion what bus theee traveller traveled before provid- ing theee requested telephone number. reason discussion probably theee operator knows different bus companies utilised like make sure theee user really understands his/her request. interaction follows can, thus, respect relevant, our pur- pose developing systems based overall goal providing information, understand human interaction, our dialogue system able han- dle such phenomenon (jsnsson, 1996). dialogues roughly divided into five dif- ferent categories based theee users task. dis- cussion twenty five dialogues bus times between various places, often one departure one arrival five dialogues involved more places. five dialogues theee discussion one price var- ious types discounts. five users wanted know thee telephone number 'thee lost property office', two discussed only bus stops two discussed how they utilise theeir season ticket travel out- side theee trafficking area theee bus company. interesting note theere no correspondence between theee task being performed uring theee inter- action theee amount changes made theee dia- logue. thus, if we assume theee amount distillation indicates omething about user's inter- action style, other factors than theee task impor- tant when characterising user behaviour. looking what altered we find theee most important distilling principle theee 'system' provides all relevant information once, c.f. fig- ures 1 2. turn removes utterances pro- vided both 'system' user. most added utterances, both theee user thee 'system', provide explicit requests informa- tion later provided theee dialogue, e.g. ut- terance $3 figure 6. we added ten utterances all 39 dialogues, five 'system' utterances five user utterances. note, however, we utilised theee transcribed ialogues, without information into- nation. we probably needed add many utterances if we utilised theee tapes. our reason using information intonation we assume our system's peech recogniser recognise intonation. finally, discussed above, we utilise theee full potential multi-modality when distilling theee dialogues. instance, some dialogues further distilled if we assumed theee system presented time-table. one reason we wanted capture many interesting as- pects intact possible. advantage is, thus, we better corpus understanding human- 49 u2: yees hi anna nilsson my name i like take theee bus ryd center resecentrum linksping jaa hej anna nilsson heter jag och jag rill ~ka buss ~r~n ryds centrum till resecentrum i linksping. $3: mm when you want leave? mm n~ir r i l l du ka? u4: 'n' i must resecentrum before fourteen thirty five (.) 'cause we going theee interstate buses ja ska va p~ rececentrum innan fjorton d trettifem (.) f5 vi ska till l~ngfiirdsbussarna figure 6: distilled dialogue fragment added utterance computer interaction corpus second distillation where we focus more multi- modal interaction. 6 discuss ion we been presenting method distilling hu- man dialogues make theem resemble human com- puter interaction, order utilise such dialogues knowledge source when developing dialogue sys- tems. our own main purpose been use theem developing multimodal systems, however, dis- cussed above, we paper rather assumed speech-only system. we believe theee basic approach used also multi-modal systems other kinds natural language dialogue sys- tems. important o aware theee limitations thee method, how 'realistic' theee produced result be, compared dialogue theee final sys- tem. since we changing theee dialogue moves, instance providing all required information one move, never asking reminded what theee us- er previously requested, obvious what follows after theee changed sequence probably affected one way another. consequence theee resulting dialogue less accurate model theee entire dialogue. theerefore ideal candidate trying out theee systems over-all performance during system development. thee smaller sub-segments sub-dialogues, we be- lieve creates good approximation what take place once theee system up running. furthermore, we believe distilled dialogues some respects more realistic than wizard oz- dialogues collected wizard acting com- puter. another issue, been discussed previously theee description theee method, theee distilling made based particular view what dialogue computer look like. while necessari- ly being detailed specific model, least instance class computer dialogue models. one example whether theee system meant acquire information theee user's underlying mo- tivations goals not. theee examples presented, we assumed such capabilities, as- sumption absolute necessity. we believe, however, theee distilling process based one such model, theee least ensure con- sistent treatment similar recurring phenomena t different places theee corpora. validity theee results based analysing dis- tilled dialogues depends part ly how theee distilla- tion been carried out. even when using natural dialogues we situations where theee interac- tion somewhat mysterious, instance, if some thee dialogue participants behaves irrational such providing feedback being too elliptical. how- ever, if careful considerations been made stay close theee original dialogues possible, we be- lieve distilled dialogues reflect what hu- man consider natural interaction. acknowledgments work results number projects de- velopment natural language interfaces upported swedish transport & communications re- search board (kfb) theee joint research program language technology (hsfr/nutek) . we indebted theee participants theee swedish dialogue systems project, especially staffan larsson, lena santamarta, annika flycht-eriksson inter- esting discussions topic. re ferences lars ahrenberg, nils dahlb~ck, arne jsnsson, /~ke thur~e. 1996. customizing interac- tion natural language interfaces. linkspin9 electronic articles computer informa- tion science, also notes workshop pragmatics dialogue, xiv:th scandi- navian conference linguistics theee vi- ii:th conference nordic general linguis- 50 tics, gsteborg, sweden, 1993, 1(1), october, 1. http :/ / www.ep.liu.se / ea /cis /1996 / o01/. sue atkins, jeremy clear, nicholas ostler. 1992. corpus design criteria. literary lin- guistic computing, 7(1):1-16. douglas biber. 1993. representativeness cor- pus design. literary linguistic computing, 8(4):244-257. jean carletta. 1996. assessing agreement classi- fication tasks: kappa statistic. computation- al linguistics, 22(2):249-254. steve crowdy. 1993. spoken corpus design. literary linguistic computing, 8(4):259-265. nils dahlb/ick arne jsnsson. 1999. knowledge sources spoken dialogue systems. proceed- ings eurospeech'99, budapest, hungary. nils dahlb/ick, arne jsnsson, lars ahrenberg. 1998. wizard oz studies - why how. mark maybury & wolfgang wahlster, editor, readings intelligent user interfaces. morgan kaufmann. ntis dahlb/ick, annika flycht-eriksson, arne jsnsson, pernilla qvarfordt. 1999. ar- chitecture multi-modal natural dialogue sys- tems. proceedings esca tutorial re- search workshop (etrw) interactive dialogue multi-modal systems, germany. nils dahlb/ick. 1991. representations ofdiscourse, cognitive computational aspects. ph.d. thee- sis, linksping university. maxine eskenazi, alexander rudnicki, karin grego- ry, paul constantinides, robert brennan, christi- na bennett, jwan allen. 1999. data collec- tion processing theee carnegie mellon com- municator. proceedings eurospeech'99, bu- dapest, hungary. annika flycht-eriksson arne jsnsson. 1998. spoken dialogue system utilizing spatial informa- tion. proceedings icslp'98, sydney, aus- tralia. annika flycht-eriksson. 1999. survey knowl- edge sources dialogue systems. proceedings ljcai-99 workshop knowledge reason- ing practical dialogue systems, august, stock- holm. roger garside, geoffrey leech, anthony meenery. 1997. corpus annotation. longman. arne jsnsson nils dahlb/ick. 1988. talking computer like talking your best friend. proceedings theee first scandinavian conference artificial interuigence, tvoms. arne jsnsson. 1996. natural language generation without intentions. proceedings ecai'96 workshop gaps bridges: new directions planning natural language generation, pages 102-104. pernilla qvarfordt arne jsnsson. 1998. effects using speech timetable information systems www. proceedings icslp'98, sydney, australia. pernilla qvarfordt. 1998. usability multimodal timetables: effects different levels do- main knowledge usability. master's theesis, linksping university. karen sparck jones julia r. galliers. 1996. evaluating natural language processing systems. springer verlag. marilyn a. walker, diane j. litman, candace a. kamm, alicia abella. 1998. paradise: framework evaluating spoken dialogue agents. mark maybury & wolfgang wahlster, editor, readings intelligent user interfaces. morgan kaufmann. 51