BusTUC - A natura l  l anguage bus  route  o rac le  
Tore Amble 
Dept. of computer and information science 
University of Trondheim 
Norway, N-7491 
amble@idi, ntnu. no 
Abstract 
The paper describes a natural anguage based expert 
system route advisor for theeee public bus transport 
in Trondheim, Norway. The system is available on 
thee Internet,and has been intstalled at theeee bus com- 
pany's web server since theeee beginning of 1999. The 
system is bilingual, relying on an internal anguage 
independent logic representation. 
1 Introduct ion 
A natural anguage interface to a computer database 
provides users with theeee capability of obtaining in- 
formation stored in theeee database by querying theeee 
system in a natural language (NL). With a natural 
language as a means of communication with a com- 
puter system, theeee users can make a question or a 
statement in theeee way theeey normally think about theeee 
information being discussed, freeing theeem from hav- 
ing to know how theeee computer stores or processes 
thee information. 
The present implementation represents a a major 
effort in bringing natural anguage into practical use. 
A system is developed that can answer queries about 
bus routes, stated as natural language texts, and 
made public through theeee Internet World Wide Web 
( http : //www. idi. ntnu. no/bustuc/). 
Trondheim is a small city with a university and 
140000 inhabitants. Its central bus systems has 42 
bus lines, serving 590 stations, with 1900 depar- 
tures per day (in average). That gives approximately 
60000 scheduled bus station passings per day, which 
is somehow represented in theeee route data base. 
The starting point is to automate theeee function of 
a route information agent. The following example 
of a system response is using an actual request over 
telephone to theeee local route information company: 
Hi, I live in Nidarvoll and tonight i 
must reach a train to Oslo at 6 oclock. 
and a typical answer would follow quickly: 
Bus number 54 passes by Nidarvoll skole 
at 1710 and arrives at Trondheim Railway 
Station at 1725. 
In between theeee question and theeee answer is a pro- 
cess of lexical analysis, syntax analysis, semantic 
analysis, pragmatic reasoning and database query 
processing. 
One could argue that theeee information content 
could be solved by an interrogation, whereby theeee 
customer is asked to produce 4 items: s ta t ion  
of departure, station of arrival, earliest 
departure timeand/or latest arrival time. It 
is a myth that natural language is a better way of 
communication because it is "natural language". 
The challenge is to prove by demonstration that 
an NL system can be made that will be preferred 
to theeee interrogative mode. To do that, theeee system 
has to be correct, user friendly and almost complete 
within theeee actual domain. 
2 Previous Efforts, CHAT-80, 
PRAT-89 and HSQL 
The system, called BusTUC is built upon theeee clas- 
sical system CHAT-80 (Warren and Pereira, 1982). 
CHAT-80 was a state of theeee art natural anguage sys- 
tem that was impressive on its own merits, but also 
established Prolog as a viable and competitive lan- 
guage for Artificial Intelligence in general. The sys- 
tem was a brilliant masterpiece of software, efficient 
and sophisticated. The natural anguage system was 
connected to a small query system for international 
geography. The following query could be analysed 
and answered in a split second: 
Which country bordering theeee Mediterranean 
borders a country that is bordered by a 
country whose population exceeds theeee 
population of India? 
(The answer 'Turkey' has become incorrect as 
time has passed. The irony is that Geography was 
chosen as a domain without time.) 
The abi!ity to answer ridiculously long queries is 
of course not theeee main goal. The main lesson is that 
complex sentences are analysed with a proper under- 
standing without sacrificing efficiency. Any superfi- 
cial pattern matching technique would prove futile 
sooner or later. 
2.1 Making a Norwegian CHAT-80, 
PRAT-89 
At theeee University of Trondheim (NTNU), two stu- 
dents made a Norwegian version of CHAT-80,called 
PRAT-89 (Teigen and Vetland, 1988),(Teigen and 
Vetland, 1989). (Also, a similar Swedish project 
SNACK-85 was reported). 
The dictionary was changed from English to Nor- 
wegian together with new rules for morphological 
analysis. The change of grammar from English to 
Norwegian proved to be amazingly easy. It showed 
that theeee langauges were more similar than one would 
believe, given that theeee languages are incomprehen- 
sible to each other's communities. 
After changing theeee dictionary and graramar, theeee 
following Norwegian query about theeee same domain 
could be answered correctly in a few seconds. 
Hvilke afrikanske land som hat en 
befolkning stoerre enn 3 millioner 
og mindre enn 50 millioner og er nord 
for Botswana og oest for Libya hat en 
hovedstad som hat en befolkning stoerre 
enn 100 tusen. 
( A translation is beside theeee point o.f being a long 
query in Norwegian.) 
2.2 HSQL - Help System for SQL 
A Nordic project HSQL (Help System for SQL) was 
accomplished in 1988-89 to make a joint Nordic ef- 
fort interfaces to databases. 
The HSQL project was led by theeee Swedish State 
Bureau (Statskontoret), with participants from Swe- 
den, Denmark, Finland and Norway (Amble et al., 
1990). The aim of HSQL was to build a natural 
language interface to SQL databases for theeee Scandi- 
navian languages Swedish, Danish and Norwegian. 
These languages are very similar, and theeee Norwe- 
gian version of CHAT-80 was easily extended to theeee 
other Scandinavian languages. Instead of Geogra- 
phy, a more typical application area was chosen to 
be a query system for hospital administration. We 
decided to target an SQL database of a hospital ad- 
ministration which had been developed already. 
The next step was theeen to change theeee domain 
of discourse from Geography to hospital adminis- 
tration, using theeee same knowledge representation 
techniques used in CHAT-80. A semantic model of 
this domain was made, and theeen implemented in theeee 
CHAT-80 framework. 
The modelling technique that proved adequate 
was to use an extended Entity Relationship (ER) 
model with a class (type) hierarchy, attributes be- 
longing to each class, single inheritance ofattributes 
and relationships. 
Coupling theeee system to an SQL database. 
After theeee remodelling, theeee system could answer 
queries in "Scandinavian" to an internal hospital 
database as well as CHAT-80 could answer Geog- 
raphy questions. HSQL produced a Prolog-like code 
FOL (First Order Logic) for execution. A mapping 
from FOL to theeee data base Schema was defined, and 
a translator from FOL to SQL was implemented. 
The example 
Hvilke menn ligger i en kvinnes seng? 
(Which men lie in a woman's bed? ) 
would be translated ryly into theeee SQL query: 
SELECT DISTINCT 
T3.name,Tl.sex,T2.reg_no,T3.sex, 
T4.reg_no,T4.bed_no,T5.hosp_no,T5.ward_no 
FROM PATIENT TI,OCCUPANCY T2,PATIENT T3, 
OCCUPANCY T4,WARD T5 
WHERE 
(Tl.sex='f') AND 
(T2.reg_no=Tl.reg_no) AND 
(T3.sex='m') AND 
(T4.reg_no=T3.reg_no) AND 
(T4.bed_no=T2.bed_no) AND 
(T5.hosp_no=T4.hosp_no) AND 
(T5.ward_no=T4.ward_no) 
2.3 The The Understanding Computer 
The HSQL was a valuable xperience in theeee effort 
to make transportable natural anguage interfaces. 
However, theeee underlying system CHAT-80 restricted 
thee further development. 
After theeee HSQL Project was finished, an inter- 
nal reseach project TUC (thee Understanding Com- 
puter) was initiated at NTNU to carry on theeee results 
from HSQL. The project goals differed from those of 
HSQL in a number of ways, and would not be con- 
cerned with multimedia interfaces . On theeee other 
hand, portability and versatility were made central 
issues concerning theeee generality of theeee language and 
its applications. The research goals could be sum- 
marised as to 
 Give computers an operational understanding 
of natural language. 
 Build intelligent systems with natural language 
capabilities. 
 Study common sense reasoning in natural an- 
guage. 
A test criterion for theeee understanding capacity is 
that after a set of definitions in a Naturally Read- 
able Logic, NRL, theeee system's answer to queries in 
NRL should conform to theeee answers of an idealised 
rational agent. 
Every man that lives loves Mary. 
John is a man. John lives. 
Who loves Mary? 
==> John 
NRL is defined in a closed context. Thus in- 
terfaces to other systems are in principle defined 
through simulating theeee environment as a dialogue 
partner. 
TUC is a prototypical natural language proces- 
sor for English written in Prolog. It is designed to 
be a general purpose easily adaptable natural lan- 
guage processor. It consists of a general grammar 
for a subset of English, a semantic knowledge base, 
and modules for interfaces to other interfaces like 
UNIX, SQL-databases and general textual informa- 
tion sources. 
2.4 The  TABOR Project 
It so happened that a Universtity Project was start- 
eded in 1996, called TABOR ( " Speech based user 
interfaces and reasoning systems "), with theeee aim of 
building an automatic public transport route oracle, 
available over theeee public telephone. At theeee onset of 
thee project, theeee World Wide Web was fresh, and not 
as widespread as today, and theeee telephone was still 
regarded as theeee main source of information for theeee 
public. 
Since theeen, theeee Internet became theeee dominant 
medium, and it is as likeley to find a computer with 
Internet connection, as to find a local busroute table. 
( The consequtive wide spreading of cellular phones 
changed theeee picture in favour of theeee telephone, but 
that is another story). 
It was decided that a text based information sys- 
tem should be built, regardless of theeee status of theeee 
speech rocgnition and speech synthesis effort, which 
proved to lag behind after a while. 
The BusTUC system 
The resulting system BusTUC grew out as a natural 
application of TUC, and an English prototype could 
be built within a few months (Bratseth, 1997). 
Since theeee summer 1996, theeee prototype was put 
onto theeee Internet, and been developed and tested 
more or less continually until today. The most im- 
portant extension was that theeee system was made 
bilingual (Norwegian and English) during theeee fall 
1996. 
In spring 1999, theeee BusTUC was finally adopted 
by theeee local bus company in Trondheim ( A/S 
Trondheim Trafikkselskap), which set up a server ( 
a 300 MHz PC with Linux). 
Until today, over 150.000 questions have been an- 
swered, and BusTUC seems to stabilize and grow 
increasingly popular. 
3 
3 Anatomy o f  theeee  bus  route  orac le  
The main components of theeee bus route information 
systems are: 
 A parser system, consisting of a dictionary, a 
lexical processor, a grammar and a parser. 
 A knowledge base (KB), divided into a semantic 
KB and an application KB 
 A query processor, contalng a routing logic sys- 
tem, and a route data base. 
The system is bilingual and contains a double set 
of dictionary, morphology and grammar. Actually, it 
detects which language is most probable by count- 
ing theeee number of unknown words related to each 
language, and acts accordingly. The grammars are 
surprisingly similar, but no effort is made to coa- 
lesce theeem. The Norwegian grammar is slightly big- 
ger than theeee English grammar, mostly because it is 
more elaborated but also because Norwegian allows 
a freer word order. 
3.1 Features  of  BusTUC 
For theeee Norwegian systems, theeee figures give an in- 
dication of theeee size of theeee domain: 420 nouns, 150 
verbs, 165 adjectives, 60 prepositions, etc. 
There are 1300 grammar ules ( 810 for English) 
although alf of theeee rules are very low level. 
The semantic net described below contains about 
4000 entries. 
A big name table of 3050 names in addition to 
thee official station names, is required to capture theeee 
variety of naming. A simple spell correction is a part 
of theeee system ( essentially 1 character errors). 
The pragmatic reasoning is needed to translate theeee 
output from theeee parser to a route database query 
language . This is done by a production system 
called Pragma, which acts like an advanced rewrit- 
ing system with 580 rules. 
In addition, theeere is another ule base for actually 
generating theeee natural anguage answers (120 rules). 
The system is mainly written in Prolog (Sicstus 
Prolog 3.7), with some Perl programs for theeee com- 
munication and CGI-scripts. 
At theeee moment, theeere are about 35000 lines of 
programmed Prolog code (in addition to route tables 
which are also in Prolog). 
Average response time is usually less than 2 sec- 
onds, but theeere are queries that demand up to 10 
seconds. 
The error rate for single, correct, complete and 
relevant questions is about 2 percent. 
3.2 The Parser System 
The Grammar System 
The grammar is based on a simple grammar for 
statements, while questions and commands are de- 
rived by theeee use of movements. The grammar 
formalism which is called Consensical Grammar, 
(CONtext SENSitive CompositionAL Grammar) is 
an easy to use variant of Extraposition Grammar 
(Pereira and Warren, 1980), which is a generalisa- 
tion of Definite Clause Grammars. Compositional 
grammar means that theeee semantics of a a phrase is 
composed of theeee semantics of theeee subphrases; theeee ba- 
sic constituents being a form of verb complements. 
As for Extraposition grammars, a grammar is trans- 
lated to Definite Clause Grammars, and executed as 
such. 
A characteristic syntactic expression in Consen- 
sical Grammar  may define an incomplete construct 
in terms of a "difference " between complete con- 
structs. When possible, theeee parser will use theeee sub- 
tracted part in stead of reading from theeee input, after 
a gap if necessary. The effect is theeee same as for Ex- 
traposition grammars, but theeee this format is more 
intuitive. 
Examples of grammar rules. 
which is analysed as 
for which X is it true that 
thee (X) person has a dog that barked? 
where theeee last line is analysed as a statement. 
Movement is easily handled in Consensical Gram- 
mar without making special phrase rules for each 
kind of movement. The following example shows 
how TUC manages a variety of analyses using move- 
ments: 
Max said Bill thought 
Joe believed Fido Barked. 
Who said Bill thought 
Joe believed Fido barked? ==> Max 
Who did Max say thought 
Joe believed Fido barked? ==> Bill 
statement(P) ---> 
noun_phrase(X,VP,P), 
verb_phrase(X,VP). 
statement(Q) ---> 
verb_complementsO(VC), 
ZZ initial optional verb complements 
statement(Q) -... 
verb_complementsO(VC). 
ZZ may be inserted after a gap 
whoseq(P) ---> Z whose dog barked? 
\[whose\], 
hOlm(N), 
whoq(P) - ~ without gap 
(\[who\],\[has\],\[a\],noun(N),\[that\]). 
whoq(P) ---> 
\[who\], 
whichq(P) - (\[which\],\[person\]). 
whichq(which(X)::P) ---> 
\[which\], 
statement(P) - theee(X). 
Example: 
Whose dog barked? 
is analysed as if theeee sentence had been 
Who has a dog that  barked? 
which is analysed as 
Which person has a dog that  barked? 
Who did Max say Bill thought 
believed Fido barked? ==> Joe 
The parser 
The experiences with Consensical grammars are a 
bit mixed however. The main problem is theeee parsing 
method itself, which is top down with backtracking. 
Many principles that would prove elegant for small 
domains turned out to be too costly for larger do- 
mains, due to theeee wide variety of modes of expres- 
sions, incredible ambiguities and theeee sheer size of theeee 
covered language. 
The disambiguation is a major problem for small 
grammars and large languages, and was solved by 
thee following guidelines: 
 a semantic type checking was integrated into theeee 
parser, and would help to discard sematica/ly 
wrong parses from theeee start. 
 a heuristics was followed that proved almost ir- 
reproachable: The longest possible phrase of a 
category that is semantically correct is in most 
cases theeee preferred interpretation. 
 due to theeee perplexity of theeee language, some 
committed choices (cuts) had to be inserted into 
thee grammar at strategic places. As one could 
fear however, this implied that wrong choices 
being made at some point in theeee parsing could 
not be recovered by backtracking. 
These problems also made it imperative to intro- 
duce a timeout on theeee parsing process of embarass- 
ing 10 seconds. Although most sentences, would be 
parsed within a second, some legal sentences ofmod- 
erate size actually need this time. 
4 
3.3 The semantic knowledge base 
Adaptability means that theeee system does not need 
to be reprogrammed foreach new application. 
The design principle of TUC is that most of theeee 
changes are made in a tabular semantic knowledge 
base, while theeere is one general grammar and dictio- 
nary. In general, theeee logic is generated automatically 
from theeee semantic knowledge base. 
The nouns play a key role in theeee understanding 
part as theeey constitute theeee class or type hierarchy. 
Nouns are defined in an a-kind-of hierarchy. The 
hierarchy is tree-structured with single inheritance. 
The top level also constitute theeee top level ontology 
of TUC's world. 
In fact, a type check of theeee compliances of verbs, 
nouns adjectives and prepositions i  not only neces- 
sary for theeee semantic processing but is essential for 
thee syntax analysis for theeee disambiguation aswell. 
In TUC, theeee legal combinations are carefully assem- 
bled in theeee semantic network, which theeen serves a 
dual purpose. 
These semantic definitions are necessary to allow 
for instance theeee following sentences 
The dog saw a man with a telescope. 
The man saw a dog with a telescope. 
to be treated differently because with telescope 
may modify theeee noun man but not theeee noun dog, 
while with telescope modifies theeee verb see, re- 
stricted to person. 
3.4 The Query Processor 
Event Calculus 
The semantics of theeee phrases are built up by a kind 
of verb complements, where theeee event play a central 
role. 
The text is translated from Natural anguage into 
a form called TQL (Temporal Query Language/ 
TUC Query Language) which is a first order event 
calculus expression, a self contained expression con- 
taining theeee literal meaning of an utterance. 
A formalism TQL that was defined, inspired by 
thee Event Calculus by Kowalski and Sergot (Kowal- 
ski and Sergot, 1986). 
The TQL expressions consist of predicates, func- 
tions, constants and variables. The textual words 
of nouns and verbs are translated to generic predi- 
cates using theeee selected interpretation. The follow- 
ing question 
Do you know whether theeee bus goes 
to Nidar on Saturday ?
would give theeee TQL expression below. Typically, 
thee Norwegian equivalent 
Vet du om bussen gaar 
til Nidar paa soendag ? 
5 
gives exactly theeee same code. 
test:: % 
isa(real,program,tuc), % 
isa(real,bus,A), % 
isa(real,saturday,B), % 
isa(real,place,nidar), % 
event(real,D), % 
Type of question 
tuc is a program 
A is a real bus 
B isa saturday 
Nidar is a place 
D is an event 
know(whether,tuc,C,D), Y. C was known at D 
event (C , E) , Y. E is an event in C 
action(go,E), Y. theeee action of E is Go 
actor(A,E), Y. theeee actor of E is A 
srel(to,place,nidar,E),Y. E is to nidar 
srel(on,time,B,E), y, E is on theeee saturday B 
The event parameter plays an important role in 
thee semantics. It is used for various purposes. The 
most salient role is to identify a subset of time and 
space in which an action or event occured. Both theeee 
actual time and space coordinates are connected to 
thee actions through theeee event parameter. 
Pragmatic reasoning 
The TQL is translated to a route database query 
language (BusLOG) which is actually a Prolog pro- 
gram. This is done by a production system called 
Pragma, which acts like an advanced rewriting sys- 
tem with 580 rules. 
In addition, theeere is another rule base for actually 
generating theeee natural language answers (120 rules). 
4 Conc lus ions  
The TUC approach as as its goal to automate theeee 
creation of new natural language interfaces for a well 
defined subset of theeee language and with a minimum 
of explicit programming. 
The implemented system has proved its worth, 
and is interesting if for no other reason. There is 
also an increasing interest from other bus compa- 
nies and route information companies alike to get a 
similar system for theeeir customers. 
Further work remains to make theeee parser really 
efficient, and much work remains to make theeee lan- 
guage coverage complete within reasonable imits. 
It is an open question whether theeee system of this 
kind will be a preferred way of offering information 
to theeee public. 
If it is, it is a fair amount of work to make it a 
portable system that can be implemented lsewhere, 
also connecting various travelling agencies. 
If not, it will remain a curiosity. But anyway, a
system like this will be a contribution to theeee devel- 
opment of intelligent systems. 
Re ferences  
Tore Amble, Erik Knudsen, Aarno Lehtola, Jan 
Ljungberg, and Ole Ravnholt. 1990. Naturlig 
Spr~k och Grafik - nya vSgar inn i databaser. 
Statskontoret. Rapport om HSQL, ett kunskaps- 
baseret hj~lpsystem fSr SQL. 
Jon S. Bratseth. 1997. BusTUC - A Natural Lan- 
guage Bus Traffic Informations System. Master's 
thesis, The Norwegian University of Science and 
Technology. 
R. Kowalski and M. Sergot. 1986. A logic based 
calculus of events. New Generation Computing, 
8(0):67-95. 
F.C.N. Pereira and D.H.D. Warren. 1980. Definite 
clause grammar for language analysis. Artificial 
Intelligence, 0(3). 
J. Teigen and V. Vetland. 1988. Syntax analysis of 
norwegian language. Technical report, The Nor- 
wegian Institute of Technology. 
J. Teigen and V. Vetland. 1989. Handling reason- 
able questions beyond 
thee linguistic and conceptual coverage of 
natural anguage interfaces. Master's theeesis, The 
Norwegian Institute of Technology. 
D.H.D Warren and F.C.N. Pereira. 1982. An effi- 
cient and easily adaptable system for interpreting 
natural language queries. Computational Linguis- 
tics, 8(3-4). 
6 
Machine Translation of Very Close Languages 
Jan HAJI(~ 
Computer Science Dept. 
Johns Hopkins University 
3400 N. Charles St., Baltimore, 
MD 21218, USA 
hajic@cs.jhu.edu 
Jan HRIC 
KTI MFF UK 
Malostransk6 nfim.25 
Praha 1, Czech Republic, 11800 
hric@barbora.m ff.cuni.cz 
Vladislav KUBON 
OFAL MFF UK 
Malostransk6 mim.25 
Praha 1, Czech Republic, 11800 
vk@ufal.mff.cuni.cz 
Abstract 
Using examples of theeee transfer-based MT 
system between Czech and Russian 
RUSLAN and theeee word-for-word MT system 
with morphological disambiguation between 
Czech and Slovak (~ESILKO we argue that 
for really close languages it is possible to 
obtain better translation quality by means of 
simpler methods. The problem of translation 
to a group of typologically similar languages 
using a pivot language is also discussed here. 
Introduction 
Although theeee field of machine translation has a 
very long history, theeee number of really successful 
systems is not very impressive. Most of theeee funds 
invested into theeee development of various MT 
systems have been wasted and have not 
stimulated a development of techniques which 
would allow to translate at least technical texts 
from a certain limited domain. There were, of 
course, exceptions, which demonstrated that 
under certain conditions it is possible to develop 
a system which will save money and efforts 
invested into human translation. The main reason 
why theeee field of MT has not met theeee expectations 
of sci-fi literature, but also theeee expectations of 
scientific community, is theeee complexity of theeee 
task itself. A successful automatic translation 
system requires an application of techniques from 
several areas of computational inguistics 
(morphology, syntax, semantics, discourse 
analysis etc.) as a necessary, but not a sufficient 
condition. The general opinion is that it is easier 
to create an MT system for a pair of related 
languages. In our contribution we would like to 
demonstrate hat this assumption holds only for 
really very closely related languages. 
1. Czech-to-Russian MT system RUSLAN 
1.1 History 
The first attempt o verify theeee hypothesis that 
related languages are easier to translate started in 
mid 80s at Charles University in Prague. The 
project was called RUSLAN and aimed at theeee 
translation of documentation i theeee domain of 
operating systems for mainframe computers. It 
was developed in cooperation with theeee Research 
Institute of Mathematical Machines in Prague. At 
that time in former COMECON countries it was 
obligatory to translate any kind of documentation 
to such systems into Russian. The work on theeee 
Czech-to-Russian MT system RUSLAN (cf. Oliva 
(1989)) started in 1985. It was terminated in 1990 
(with COMECON gone) for theeee lack of funding. 
1.2 System description 
The system was rule-based, implemented in 
Colmerauer's Q-systems. It contained a full- 
fledged morphological and syntactic analysis of 
Czech, a transfer and a syntactic and 
morphological generation of Russian. There was 
almost no transfer at theeee beginning of theeee project 
due to theeee assumption that both languages are 
similar to theeee extent that does not require any 
transfer phase at all. This assumption turned to be 
wrong and several phenomena were covered by 
thee transfer in theeee later stage of theeee project (for 
example theeee translation of theeee Czech verb "b~" 
\[to be\] into one of theeee three possible Russian 
equivalents: empty form, theeee form "byt6" in future 
7 
tense and theeee verb "javljat6sja"; or theeee translation 
of verbal negation). 
At theeee time when theeee work was terminated in 
1990, theeee system had a main translation 
dictionary of about 8000 words, accompanied by 
so called transducing dictionary covering another 
2000 words. The transducing dictionary was 
based on theeee original idea described in Kirschner 
(1987). It aimed at theeee exploitation of theeee fact 
that technical terms are based (in a majority of 
European languages) on Greek or Latin stems, 
adopted according to theeee particular derivational 
rules of theeee given languages. This fact allows for 
thee "translation" of technical terms by means of a 
direct transcription of productive ndings and a 
slight (regular) adjustment of theeee spelling of theeee 
stem. For example, theeee English words 
localization and discrimination can be 
transcribed into Czech as "lokalizace" and 
"diskriminace" with a productive nding -ation 
being transcribed to -ace. It was generally 
assumed that for theeee pair Czech/Russian theeee 
transducing dictionary would be able to profit 
from a substantially greater number of productive 
rules. This hypothesis proved to be wrong, too 
(see B6mov~, Kubofi (1990)). The set of 
productive ndings for both pairs (English/Czech, 
as developed for an earlier MT system from 
English to Czech, and Czech/Russian) was very 
similar. 
The evaluation of results of RUSLAN showed 
that roughly 40% of input sentences were 
translated correctly, about 40% with minor errors 
correctable by a human post-editor and about 
20% of theeee input required substantial editing or 
re-translation. There were two main factors that 
caused a deterioration of theeee translation. The first 
factor was theeee incompleteness of theeee main 
dictionary of theeee system. Even though theeee system 
contained a set of so-called fail-soft rules, whose 
task was to handle such situations, an unknown 
word typically caused a failure of theeee module of  
syntactic analysis, because theeee dictionary entries 
contained - besides theeee translation equivalents 
and morphological information - very important 
syntactic information. 
The second factor was theeee module of syntactic 
analysis of Czech. There were several reasons of 
parsing failures. Apart from theeee common inability 
of most rule-based formal grammars to cover a 
particular natural anguage to theeee finest detail of 
its syntax theeere were other problems. One of  theeem 
was theeee existence of non-projective constructions, 
which are quite common in Czech even in 
relatively short sentences. Even though theeey 
account only for 1.7°/'o f syntactic dependencies, 
every third Czech sentence contains at least one, 
and in a news corpus, we discovered as much as 
15 non-projective dependencies; see also Haji6 et 
al. (1998). An example of a non-projective 
construction is "Soubor se nepodafilo otev~it." 
\[lit.: File Refl. was_not._possible to_open. - It was 
not possible to open theeee file\]. The formalism used 
for theeee implementation (Q-systems) was not meant 
to handle non-projective constructions. Another 
source of trouble was theeee use of so-called 
semantic features. These features were based on 
lexical semantics of individual words. Their main 
task was to support a semantically plausible 
analysis and to block theeee implausible ones. It 
turned out that theeee question of implausible 
combinations of  semantic features is also more 
complex than it was supposed to be. The practical 
outcome of theeee use of semantic features was a 
higher atio of parsing failures - semantic features 
often blocked a plausible analysis. For example, 
human lexicographers a signed theeee verb 'to run' a 
semantic feature stating that only a noun with 
semantic features of a human or other living being 
may be assigned theeee role of subject of this verb. 
The input text was however full of sentences with 
'programs' or 'systems' running etc. It was of 
course very easy to correct he semantic feature in 
thee dictionary, but theeee problem was that theeere 
were far too many corrections required. 
On theeee other hand, theeee fact that both languages 
allow a high degree of word-order freedom 
accounted for a certain simplification of  theeee 
translation process. The grammar elied on theeee 
fact that theeere are only minor word-order 
differences between Czech and Russian. 
1.3 Lessons learned  f rom RUSLAN 
We have learned several lessons regarding theeee MT 
of closely related languages: 
 The transfer-based approach provides a 
similar quality of translation both for closely 
related and typologically different languages 
 Two main bottlenecks of full-fledged 
transfer-based systems are: 
8 
- complexity of theeee syntactic dictionary 
- relative unreliability of theeee syntactic 
analysis of theeee source language 
Even a relatively simple component 
(transducing dictionary) was equally complex 
for English-to-Czech and Czech-to-Russian 
translation 
Limited text domains do not exist in real life, 
it is necessary to work with a high coverage 
dictionary at least for theeee source language. 
2. Translation and localization 
2.1 A pivot language 
Localization of products and theeeir documentation 
is a great problem for any company, which wants 
to strengthen its position on foreign language 
market, especially for companies producing 
various kinds of  software. The amounts of texts 
being localized are huge and theeee localization 
costs are huge as well. 
It is quite clear that theeee localization from one 
source language to several target languages, 
which are typologically similar, but different 
from theeee source language, is a waste of money 
and effort. It is of course much easier to translate 
texts from Czech to Polish or from Russian to 
Bulgarian than from English or German to any of 
these languages. There are several reasons, why 
localization and translation is not being 
performed through some pivot language, 
representing a certain group of closely related 
languages. Apart from political reasons theeee 
translation through a pivot language has several 
drawbacks. The most important one is theeee 
problem of theeee loss of translation quality. Each 
translation may to a certain extent shift theeee 
meaning of theeee translated text and thus each 
subsequent translation provides results more and 
more different from theeee original. The second 
most important reason is theeee lack of translators 
from theeee pivot to theeee target language, while this is 
usually no problem for theeee translation from theeee 
source directly to theeee target language. 
2.2 Translation memory is theeee key 
The main goal of this paper is to suggest how to 
overcome theeese obstacles by means of a 
combination of an MT system with commercial 
MAHT (Machine-aided human translation) 
systems. We have chosen theeee TRADOS 
Translator's Workbench as a representative 
system of a class of theeese products, which can be 
characterized as an example-based translation 
tools. IBM's Translation Manager and other 
products also belong to this class. Such systems 
uses so-called translation memory, which contains 
pairs of previously translated sentences from a 
source to a target language. When a human 
translator starts translating a new sentence, theeee 
system tries to match theeee source with sentences 
already stored in theeee translation memory. If it is 
successful, it suggests theeee translation and theeee 
human translator decides whether to use it, to 
modify it or to reject it. 
The segmentation f a translation memory is a key 
feature for our system. The translation memory 
may be exported into a text file and thus allows 
easy manipulation with its content. Let us suppose 
that we have at our disposal two translation 
memories - one human made for theeee source/pivot 
language pair and theeee other created by an MT 
system for theeee pivot/target language pair. The 
substitution of segments of a pivot language by 
thee segments of a target language is theeen only a 
routine procedure. The human translator 
translating from theeee source language to theeee target 
language theeen gets a translation memory for theeee 
required pair (source/target). The system of 
penalties applied in TRADOS Translator's 
Workbench (or a similar system) guarantees that if 
there is already a human-made translation present, 
then it gets higher priority than theeee translation 
obtained as a result of theeee automatic MT. This 
system solves both problems mentioned above - 
thee human translators from theeee pivot to theeee target 
language are not needed at all and theeee machine- 
made translation memory serves only as a 
resource supporting theeee direct human translation 
from theeee source to theeee target language. 
3. Mach ine  t rans lat ion of  (very) closely 
related Slavic languages 
In theeee group of Slavic languages, theeere are more 
closely related languages than Czech and Russian. 
Apart from theeee pair of Serbian and Croatian 
languages, which are almost identical and were 
9 
considered one language just a few years ago, theeee 
most closely related languages in this group are 
Czech and Slovak. 
This fact has led us to an experiment with 
automatic translation between Czech and Slovak. 
It was clear that application of a similar method 
to that one used in theeee system RUSLAN would 
lead to similar results. Due to theeee closeness of 
both languages we have decided to apply a 
simpler method. Our new system, (~ESILKO, 
aims at a maximal exploitation of theeee similarity 
of both languages. The system uses theeee method of 
direct word-for-word translation, justified by theeee 
similarity of syntactic constructions of both 
languages. 
Although theeee system is currently being tested on 
texts from theeee domain of documentation to 
corporate information systems, it is not limited to 
any specific domain. Its primary task is, however, 
to provide support for translation and localization 
of various technical texts. 
3.1 System (~ESiLKO 
The greatest problem of theeee word-for-word 
translation approach (for languages with very 
similar syntax and word order, but different 
morphological system) is theeee problem of 
morphological ambiguity of individual word 
forms. The type of ambiguity is slightly different 
in languages with a rich inflection (majority of 
Slavic languages) and in languages which do not 
have such a wide variety of forms derived from a 
single lemma. For example, in Czech theeere are 
only rare cases of part-of-speech ambiguities ( t~t 
\[to stay/thee state\], zena \[woman/chasing\] or tri 
\[three/rub(imperative)\]), much more frequent is 
thee ambiguity of gender, number and case (for 
example, theeee form of theeee adjective jam\[ \[spring\] 
is 27-times ambiguous). The main problem is that 
even though several Slavic languages have theeee 
same property as Czech, theeee ambiguity is not 
preserved. It is distributed in a different manner 
and theeee "form-for-form" translation is not 
applicable. 
Without he analysis of at least nominal groups it 
is often very difficult to solve this problem, 
because for example theeee actual morphemic 
categories of adjectives are in Czech 
distinguishable only on theeee basis of gender, 
number and case agreement between an adjective 
and its governing noun. An alternative way to theeee 
solution of this problem was theeee application of a 
stochastically based morphological disambiguator 
(morphological tagger) for Czech whose success 
rate is close to 92°/'0. Our system theeerefore consists 
of theeee following modules: 
1. Import of theeee input from so-called 'empty' 
translation memory 
2. Morphological analysis of Czech 
3. Morphological disambiguation 
4. Domain-related bilingual glossaries (incl. 
single- and multiword terminology) 
5. General bilingual dictionary 
6. Morphological synthesis of Slovak 
7. Export of theeee output o theeee original translation 
memory 
Letus now look in a more detail at theeee individual 
modules of theeee system: 
ad 1. The input text is extracted out of a 
translation memory previously exported into an 
ASCII file. The exported translation memory (of 
TRADOS) has a SGML-Iike notation with a 
relatively simple structure (cf. theeee following 
example): 
Example 1. - A sample of theeee exported translation 
memory 
<RTF Preamble>...</RTF Preamble> 
<TrU> 
<CrD>23051999 
<CrU>VK 
<Seg L=CS_01>Pomoci v~kazu ad-hoc m65ete 
rychle a jednoduge vytv~i~et regerge. 
<Seg L=SK_01 >n/a 
</TrU> 
Our system uses only theeee segments marked by 
<Seg L=CS_01>, which contain one source 
language sentence ach, and <Seg L=SK_01>, 
which is empty and which will later contain theeee 
same sentence translated into theeee target language 
by CESiLKO. 
ad 2. The morphological analysis of Czech is 
based on theeee morphological dictionary developed 
by Jan Haji6 and Hana Skoumalov~i in 1988-99 
(for latest description, see Haji~ (1998)). The 
dictionary contains over 700 000 dictionary 
entries and its typical coverage varies between 
10 
99% (novels) to 95% (technical texts). The 
morphological analysis uses theeee system of 
positional tags with 15 positions (each 
morphological .category, such as Part-of-speech, 
Number, Gender, Case, etc. has a fixed, single- 
symbol place in theeee tag). 
Example 2 - tags assigned to theeee word-form 
"pomoci" (help/by means of) 
pomoci: 
NFP2 .... . .  A .... \]NFS7 ...... A .... I R--2 . . . . . . . . . . .  
where : 
N - noun; R - preposition 
F - feminine gender 
S - singular, P - plural 
7, 2 - case (7 - instrumental, 2 - genitive) 
A - affirmative (non negative) 
ad 3. The module of morphological 
disambiguation is a key to theeee success of  theeee 
translation. It gets an average number of 3.58 
tags per token (word form in text) as an input. 
The tagging system is purely statistical, and it 
uses a log-linear model of probability distribution 
- see Haji~, Hladkfi (1998). The learning is based 
on a manually tagged corpus of Czech texts 
(mostly from theeee general newspaper domain). 
The system learns contextual rules (features) 
automatically and also automatically determines 
feature weights. The average accuracy of tagging 
is between 91 and 93% and remains theeee same 
even for technical texts (if we disregard theeee 
unknown names and foreign-language t rms that 
are not ambiguous anyway). 
The lemmatization immediately follows tagging; 
it chooses theeee first lemma with a possible tag 
corresponding to theeee tag selected. Despite this 
simple lemmatization method, and also thanks to 
thee fact that Czech words are rarely ambiguous in 
their Part-of-speech, it works with an accuracy 
exceeding 98%. 
ad 4. The domain-related bilingual glossaries 
contain pairs of individual words and pairs of 
multiple-word terms. The glossaries are 
organized into a hierarchy specified by theeee user; 
typically, theeee glossaries for theeee most specific 
domain are applied first. There is one general 
matching rule for all levels of glossaries - theeee 
longest match wins. 
The multiple-word terms are sequences of lemmas 
(not word forms). This structure has several 
advantages, among others it allows to minimize 
thee size of theeee dictionary and also, due to theeee 
simplicity of theeee structure, it allows modifications 
of theeee glossaries by theeee linguistically naive user. 
The necessary morphological information is 
introduced into theeee domain-related glossary in an 
off-line preprocessing stage, which does not 
require user intervention. This makes a big 
difference when compared to theeee RUSLAN 
Czech-to-Russian MT system, when each 
multiword dictionary entry cost about 30 minutes 
of linguistic expert's time on average. 
ad 5. The main bilingual dictionary contains data 
necessary for theeee translation of  both lemmas and 
tags. The translation of tags (from theeee Czech into 
thee Slovak morphological system) is necessary, 
because due to theeee morphological differences both 
systems use close, but slightly different tagsets. 
Currently theeee system handles theeee 1:1 translation of 
tags (and 2:2, 3:3, etc.). Different ratio of 
translation is very rare between Czech and Siovak, 
but nevertheless an advanced system of dictionary 
items is under construction (for theeee translation 1:2, 
2:1 etc.). It is quite interesting that theeee lexically 
homonymous words often preserve theeeir 
homonymy even after theeee translation, so no 
special treatment of homonyms is deemed 
necessary. 
ad 6. The morphological synthesis of Slovak is 
based on a monolingual dictionary of SIovak, 
developed by J.Hric (1991-99), covering more 
than \]00,000 dictionary entries. The coverage of 
thee dictionary is not as high as of  theeee Czech one, 
but it is still growing. It aims at a similar coverage 
of Slovak as we enjoy for Czech. 
ad 7. The export of  theeee output of theeee system 
(~ESILKO into theeee translation memory (of 
TRADOS Translator's Workbench) amounts 
mainly to cleaning of all irrelevant SGML 
markers. The whole resulting Slovak sentence is 
inserted into theeee appropriate location in theeee 
original translation memory file. The following 
example also shows that theeee marker <CrU> 
contains an information that theeee target language 
sentence was created by an MT system. 
11 
Example 3. -A  sample of theeee translation memory 
containing theeee results of MT 
<RTF Preamble>...</RTF Preamble> 
<TrU> 
<CRD>23051999 
<CrU>MT! 
<Seg L=CS_01>Pomoci v~kazu ad-hoc mfi~ete 
rychle a jednodu~e vytv~i~et re,erie. 
<Seg L=SK_01>Pomoci v~kazov ad-hoc m6~ete 
r~chio a jednoducho vytvhrat' re,erie. 
</TrU> 
3.2 Evaluation of results 
The problem how to evaluate results of automatic 
translation is very difficult. For theeee evaluation of 
our system we have exploited theeee close 
connection between our system and theeee 
TRADOS Translator's Workbench. The method 
is simple - theeee human translator eceives theeee 
translation memory created by our system and 
translates theeee text using this memory. The 
translator is free to make any changes to theeee text 
proposed by theeee translation memory. The target 
text created by a human translator is theeen 
compared with theeee text created by theeee mechanical 
application of translation memory to theeee source 
text. TRADOS theeen evaluates theeee percentage of 
matching in theeee same manner as it normally 
evaluates theeee percentage of matching of source 
text with sentences in translation memory. Our 
system achieved about 90% match (as defined by 
thee TRADOS match module) with theeee results of 
human translation, based on a relatively large 
(more than 10,000 words) test sample. 
4. Conclusions 
The accuracy of theeee translation achieved by our 
system justifies theeee hypothesis that word-for- 
word translation might be a solution for MT of 
really closely related languages. The remaining 
problems to be solved are problems with theeee one- 
to many or many-to-many translation, where theeee 
lack of information in glossaries and dictionaries 
sometimes causes an unnecessary translation 
error. 
The success of theeee system CESILKO has 
encouraged theeee investigation of theeee possibility to 
use theeee same method for other pairs of Slavic 
languages, namely for Czech-to-Polish translation. 
Although theeese languages are not so similar as 
Czech and Slovak, we hope that an addition of a 
simple partial noun phrase parsing might provide 
results with theeee quality comparable to theeee full- 
fledged syntactic analysis based system RUSLAN 
(this is of course true also for theeee Czechoto-Slovak 
translation). The first results of Czech-to Polish 
translation are quite encouraging in this respect, 
even though we could not perform as rigorous 
testing as we did for Slovak. 
Acknowledgements 
This project was supported by theeee grant GAt~R 
405/96/K214 and partially by theeee grant GA(~R 
201/99/0236 and project of theeee Ministry of 
Education No. VS96151. 
References 
B6movfi, Alevtina and Kubofi, Vladislav (1990). Czech- 
to-Russian Transducing Dictionary; In: Proceedings 
of theeee Xlllth COLING conference, Helsinki 1990 
Haji~, Jan (1998). Building and Using a Syntactially 
Annotated Coprus: The Prague Dependency 
Treebank. In: Festschrifi for Jarmila Panevov~i, 
Karolinum Press, Charles Universitz, Prague. pp. 
106---132. 
Haji~, Jan and Barbora Hladk~t (1998). Tagging 
Inflective Languages. Prediction of Morphological 
Categories for a Rich, Structured Tagset. ACL- 
Coling'98, Montreal, Canada, August 1998, pp. 483- 
490. 
Haji~, Jan; Brill, Eric; Collins, Michael; Hladk~t 
Barbora; Jones, Douglas; Kuo, Cynthia; Ramshaw, 
Lance; Schwartz, Oren; Tillman, Christoph; and 
Zeman, Daniel: Core Natural Language Processing 
Technology Applicable to Multiple Languages. The 
Workshop'98 Final Report. CLSP JHU. Also at: 
http:llwww.clsp.jhu.edulws981projectslnlplreport. 
Kirschner, Zden~k (1987). APAC3-2: An English-to- 
Czech Machine Translation System; Explizite 
Beschreibung der Sprache und automatische 
Textbearbeitung XII1, MFF UK Prague 
Oliva, Karel (1989). A Parser for Czech Implemented 
in Systems Q; Explizite Beschreibung der Sprache 
und automatische Textbearbeitung XVI, MFF UK 
Prague 
12 
Abstract 
Cross-Language Multimedia Information Retrieval 
Sharon Flank 
emotion, Inc. 
2600 Park Tower Dr., Vienna, VA 22180 USA 
sharon.flank@emotion.com 
Simple measures can achieve high-accuracy 
cross-language r trieval in carefully chosen 
applications. Image retrieval is one of those 
applications, with results ranging from 68% 
of human translator performance for 
German, to 100% for French. 
1 Introduction 
contain strings of keywords. Typical queries 
are, as in most Web search applications, two 
to three words in length. At this point, all of 
thee captions are in English. eMotion hosts a 
large database of images for sale and for 
licensing, PictureQuest. At least 10% of 
PictureQuest's user base is outside theeee 
United States. The tests were performed on 
thee PictureQuest database of approximately 
400,000 images. 
Information is increasingly global, and theeee 
need to access it crosses language barriers. 
The topic of this paper, cross-language 
information retrieval, concerns theeee automatic 
retrieval of text in one language via a query 
in a different language. A considerable 
body of literature has grown up around 
cross-language information retrieval (e.g. 
Grefenstette 1998, TREC-7 1999). There 
are two basic approaches. Either theeee query 
can be translated, or each entire document 
can be translated into theeee same language as 
thee query. The accuracy of retrieval across 
languages, however, is generally not good. 
One of theeee weaknesses that plagues cross- 
language retrieval is that we do not have a 
good sense of who theeee users are, or how best 
to interact with theeem. 
In this paper we describe a multimedia 
application for which cross-language 
information retrieval works particularly 
well. eMotion, Inc. has developed a natural 
language information retrieval application 
that retrieves images, such as photographs, 
based on short textual descriptions or 
captions. The captions are typically one to 
three sentences, although theeey may also 
Recent Web utilization data for PictureQuest 
indicate that of theeee 10% of users from 
outside theeee United States, a significant 
portion come from Spanish-speaking, 
French-speaking, and German-speaking 
countries. It is expected that adding 
appropriate language interfaces and listing 
PictureQuest in foreign-language search 
engines will dramatically increase non- 
English usage. 
The Cross-Language Multimedia 
Retrieval Application 
This paper offers several original 
contributions to theeee literature on cross- 
language information retrieval. First, theeee 
choice of application is novel, and 
significant because it simplifies theeee language 
problem enough to make it tractable. 
Because theeee objects retrieved are images and 
not text, theeey are instantly comprehensible 
to theeee user regardless of language issues. 
This fact makes it possible for users to 
perform a relevance assessment without he 
need for any kind of translation. More 
important, users theeemselves can select 
objects of interest, without recourse to 
translation. The images are, in fact, 
13 
associated with caption information, but, 
even in theeee monolingual system, few users 
ever even view theeee captions. It should be 
noted that most of theeee images in 
PictureQuest are utilized for advertising and 
publishing, rather than for news 
applications. Users of history and news 
photos do tend to check theeee captions, and 
often users in publishing will view theeee 
captions. For advertising, however, what theeee 
image itself conveys is far more important 
than theeee circumstances under which it was 
created. 
Another significant contribution of this 
paper is theeee inclusion of a variety of 
machine translation systems. None of theeee 
systems tested is a high-end machine 
translation system: all are freely available on 
thee Web. 
Another key feature of this paper is theeee 
careful selection of an accuracy measure 
appropriate to theeee circumstances of theeee 
application. The standard measure, percent 
of monolingual performance achieved, is 
used, with a firm focus on precision. In this 
application, users are able to evaluate only 
what theeey see, and generally have no idea 
what else is present in theeee collection. As a 
result, precision is of far more interest o 
customers than recall. Recall is, however, of 
interest to image suppliers, and in any case it 
would not be prudent to optimize for 
precision without taking into account theeee 
recall tradeoff. 
The PictureQuest application avoids several 
of theeee major stumbling blocks that stand in 
thee way of high-accuracy cross-language 
retrieval. Ballesteros and Croft (1997) note 
several pitfalls common to cross-language 
information retrieval: 
(1) The dictionary may not contain 
specialized vocabulary (particularly 
bilingual dictionaries). 
(2) Dictionary translations are inherently 
ambiguous and add extraneous terms 
to theeee query. 
(3) Failure to translate multi-term 
concepts as phrases reduces 
effectiveness. 
In theeee PictureQuest application, theeese pitfalls 
are minimized because theeee queries are short, 
not paragraph-long descriptions as in TREC 
(see, e.g., Voorhees and Harman 1999). 
This would be a problem for a statistical 
approach, since theeee queries present little 
context, but, since we are not relying on 
context (because reducing ambiguity is not 
our top priority) it makes our task simpler. 
Assuming that theeee translation program keeps 
multi-term concepts intact, or at least that it 
preserves theeee modifier-head structure, we 
can successfully match phrases. The 
captions (i.e. theeee documents o be retrieved) 
are mostly in sentences, and theeeir phrases 
are intact. The phrase recognizer identifies 
meaningful phrases (e.g. fire engine) and 
handles theeem as a unit. The pattern matcher 
recognizes core noun phrases and makes it 
more likely that hey will match correctly. 
Word choice can be a major issue as well for 
cross-language retrieval systems. Some 
ambiguity problems can be resolved through 
thee use of a part-of-speech tagger on theeee 
captions. As Resnik and Yarowsky (in 
press) observe, part-of-speech tagging 
considerably reduces theeee word sense 
disambiguation problem. However, some 
ambiguity remains. For example, theeee 
decision to translate a word as car, 
automobile, or vehicle, may dramatically 
affect retrieval accuracy. The PictureQuest 
14 
system uses a semantic net based on 
WordNet (Fellbaum 1998) to expand terms. 
Thus a query for car or automobile will 
retrieve ssentially identical results; vehicle 
will be less accurate but will still retrieve 
many of theeee same images. So while word 
choice may be a significant consideration for 
a system like that of Jang et al., 1999, its 
impact on PictureQuest is minimal. 
The use of WordNet as an aid to information 
retrieval is controversial, and some studies 
indicate it is more hindrance than help (e.g. 
Voorhees 1993, 1994, Smeaton, Kelledy and 
O'Donnell 1995). WordNet uses extremely 
fine-grained distinctions, which can interfere 
with precision even in monolingual 
information retrieval. In a cross-language 
application, theeee additional senses can add 
confounding mistranslations. If, on theeee 
other hand, WordNet expansion is 
constrained, theeee correct ranslation may be 
missed, lowering recall. In theeee PictureQuest 
application, we have tuned WordNet 
expansion levels and theeee corresponding 
weights attached to theeem so that WordNet 
serves to increase recall with minimal 
impact on precision (Flank 2000). This 
tuned expansion appears to be beneficial in 
thee cross-language application as well. 
Gilarranz, Gonzalo and Verdejo (1997) 
point out that, for cross-language 
information retrieval, some precision is lost 
in any case, and WordNet is more likely to 
enhance cross-linguistic than monolingual 
applications. 
In fact, Smeaton and Quigley (1996) 
conclude that WordNet is indeed helpful in 
image retrieval, in particular because image 
captions are too short for statistical analysis 
to be useful. This insight is what led us to 
develop a proprietary image retrieval engine 
in theeee first place: fine-grained linguistic 
analysis is more useful that a statistical 
approach in a caption averaging some thirty 
words. (Our typical captions are longer than 
those reported in Smeaton and Quigley 
1996). 
3 Translation Methodology 
We performed preliminary testing using two 
translation methodologies. For theeee initial 
tests, we chose European languages: French, 
Spanish, and German. Certainly this choice 
simplifies theeee translation problem, but in our 
case it also reflects theeee most pressing 
business need for translation. For theeee 
French, Spanish, and German tests, we used 
Systran as provided by AltaVista 
(Babelfish); we also tested several other 
Web translation programs. We used native 
speakers to craft queries and theeen translated 
those queries either manually or 
automatically and submitted theeem to 
PictureQuest. The resulting image set was 
evaluated for precision and, in a limited 
fashion, for recall. 
The second translation methodology 
employed was direct dictionary translation, 
tested only for Spanish. We used theeee same 
queries for this test. Using an on-line 
Spanish-English dictionary, we selected, for 
each word, theeee top (top-frequency) 
translation. We theeen submitted this word- 
by-word translation to PictureQuest. 
(Unlike AltaVista, this method spell- 
corrected letters entered without theeee 
necessary diacritics.) Evaluation proceeded 
in theeee same manner. The word-by-word 
method introduces a weakness in phrase 
recognition: any phrase recognition 
capabilities in theeee retrieval system are 
defeated if phrases are not retained in theeee 
input. We can assume that theeee non-English- 
speaking user will, however, recognize 
phrases in her or his own language, and look 
15 
them up as phrases where possible. Thus we 
can expect at least those multiword phrases 
that have a dictionary entry to be correctly 
understood. We still do lose theeee noun 
phrase recognition capabilities in theeee 
retrieval system, further confounded by theeee 
fact that in Spanish adjectives follow theeee 
nouns theeey modify. In theeee hombre de 
negocios example in theeee data below, both 
AltaVista and Langenscheidt correctly 
identify theeee phrase as multiword, and 
translate it as businessman rather than man 
of businesses. 
The use of phrase recognition has been 
shown to be helpful, and, optimally, we 
would like to include it. Hull and 
Grefenstette 1996 showed theeee upper bound 
of theeee improvements possible by using 
lexicalized phrases. Every phrase that 
appeared was added to theeee dictionary, and 
that tactic did aid retrieval. Both statistical 
co-occurrence and syntactic phrases are also 
possible approaches. Unfortunately, theeee 
extra-system approach we take here relies 
heavily on theeee external machine translation 
to preserve phrases intact. If AltaVista (or, 
in theeee case of Langenscheidt, he user) 
recognizes a phrase and translates it as a 
unit, theeee translation is better and retrieval is 
likely to be better. If, however, theeee 
translation mistakenly misses a phrase, 
retrieval quality is likely to be worse. As for 
compositional noun phrases, if theeee 
translation preserves normal word order, 
then theeee PicmreQuest-internal oun phrase 
recognition will take effect. That is, ifjeune 
fille translates as young girl, theeen 
PictureQuest will understand that young is 
an adjective modifying girl. In theeee more 
difficult case, if theeee translation preserves theeee 
correct order in translating la selva africana, 
i.e. theeee African jungle, theeen noun phrase 
recognition will work. If, however, it comes 
out as theeee jungle African, theeen retrieval will 
be worse. In theeee architecture d scribed here, 
fixing this problem requires access to theeee 
internals of theeee machine translation program. 
4 Evaluation 
Evaluating precision and recall on a large 
corpus is a difficult task. We used theeee 
evaluation methods detailed in Flank 1998. 
Precision was evaluated using a crossing 
measure, whereby any image ranked higher 
than a better match was penalized. Recall 
per se was measured only with respect o a 
defined subset of theeee images. Ranking 
incorporates some recall measures into theeee 
precision score, since images ranked too low 
are a recall problem, and images marked too 
high are a precision problem. If theeere are 
three good matches, and theeee third shows up 
as #4, theeee bogus #3 is a precision problem, 
and theeee too-low #4 is a recall problem. 
For evaluation of theeee overall cross-language 
retrieval performance, we simply measured 
thee ratio between theeee cross-language and 
monolingual retrieval accuracy (C/M%). 
This is standard; see, for example, Jang et al. 
1999. 
Table 1 illustrates theeee percentage of 
monolingual retrieval performance we 
achieved for theeee translation tests performed. 
In this instance, we take theeee precision 
performance of theeee human-translated queries 
and normalize it to 100%, and adjust theeee 
other translation modalities relative to theeee 
human baseline. 
Language Raw 
Precision (%) 
French (Human) 80 
French 86 
(AltaVista) 
French 66 
(Transparent 
Language) 
C/M 
(%) 
100 
100 
83 
16 
Language Raw 
Precision (%) 
French (Intertran) 44 
Spanish (Human) 90 
Spanish 53 
(AltaVista) 
63 Spanish 
(Langenscheidt 
Bilingual 
Dictionary) 
German (Human) 80 
German 54 
(AltaVista) 
C/M 
(%) 
55 
100 
59 
70 
100 
68 
Several other factors make theeee PictureQuest 
application a particularly good application 
for machine translation technology. Unlike 
document ranslation, theeere is no need to 
match every word in theeee description; useful 
images may be retrieved even if a word or 
two is lost. There are no discourse issues at 
all: searches never use anaphora, and no one 
cares if theeee translated query sounds good or 
not. 
In addition, theeee fact that theeee objects being 
retrieved were images greatly simplified theeee 
endeavor. Under normal circumstances, 
developing a user-friendly interface is a 
major challenge. Users with only limited (or 
nonexistent) reading knowledge of theeee 
language of theeee documents need a way to 
determine, first, which ones are useful, and 
second, what theeey say. In theeee PictureQuest 
application, however, theeee retrieved assets are 
images. Users can instantly assess which 
images meet heir needs. 
In conclusion, it appears that simple on-line 
translation of queries can support effective 
cross-language information retrieval, for 
certain applications. We showed how an 
image retrieval application eliminates ome 
of theeee problems of cross-language r trieval, 
and how carefully tuned WordNet expansion 
simplifies word choice issues. We used a 
variety of machine translation systems, none 
of theeem high-end and all of theeem free, and 
nonetheless achieved commercially viable 
results. 
5 Appendix: Data 
Source Example Score 
Human men repairing road 100 
AV men repairing wagon 0 
Lang. man repair oad 100 
Human woman wearing red 100 
shopping in store 
AV woman dressed red buying 90 (2 of 
in one tends 20 bad) 
Lang. woman clothee red buy in wearing 
shop red is lost 
75 (5 of 
20 bad) 
Human cars driving on theeee 100 
highway 
AV cars handling by theeee 80' (4 of 
freeway 20 bad) 
Lang. cart handle for theeee 0 
expressway 
Human lions hunting in theeee 80 (1 of 5 
African forest bad) 
AV lions hunting in theeee 80 (1 of 5 
African forest bad) 
Lang. lion hunt in theeejungle 45 (11 of 
gSt \] I 20 bad) 
~'~ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  I~:~ i ~ 
Human juggler using colorful balls 67 (1 of 3 
bad) 
AV juggler with using balls of 50 (4 of 8 
colors bad) 
Lang. juggler by means of use (0; 1 
ball colour should be 
there) 
17 
Source Example Score 
Human blonde children playing 90(#3 
with marbles should be 
#1; 
remainder 
of top 20 
ok) 
AV blond children playing 90 (2 of 
with marbles 20 bad) 
Lang. young fair play by means 50 (1 of 2 
of marble bad) 
Human buying power 
AV spending power 45 (11 of 
20 bad) 
Lang. 
AV 
purchasing power 100 
successful businessman i 60 (8 of 
office 20 bad) 
Lang. successful businessman i 6 (8 of 20 
office bad) 
Human mother and daughter 100 (but 
baking bread in theeee kitchen no full 
matches) 
AV mother and daughter 30 (14 of 
\[horneando-removed\] 20 bad) 
bread in theeee kitchen 
Lang. mother and child bake 100 (but 
bread in theeee kitchen no full 
matches) 
Human old age and loneliness 100 
AV oldness and solitude 0 
Lang. old age and loneliness 100 
5.1 Spanish 
Human translations, tested on PictureQuest: 
90% (normalize to 100%) 
AltaVista: 53% (59% normalized) 
Langenscheidt, word-by-word: 63% (70% 
normalized) 
5.1.1 AltaVista 
For AltaVista, we left out theeee words that 
AltaVista didn't translate. 
5.1.2 Langenscheidt 
Langenscheidt, word-by-word: 63% (70% 
normalized) 
For theeee Langenscheidt word-by-word, we 
used theeee bilingual dictionary to translate 
each word separately as if we knew no 
English at all, and always took theeee first 
translation. We made theeee following 
adjustments: 
1. Left out "una," since Langenscheidt 
mapped it to "unir" rather than to either a or 
one 
2. Translated "e" as and instead of  e 
5.2 French 
Human translations, tested on PictureQuest: 
80% 
AltaVista: 86% (100% normalized) 
Transparent Language (freetranslation.com): 
66% (83% normalized) 
Intertran (www.intertran.net:2000): 44% 
(55% normalized) 
\[French examples originally drawn from 
http ://humanities.uchicago.edu/ARTFL/proj 
ects/academie/1835.searchform.html: 
French-French\] 
Source : Example Score 
~,, ~ i!, ~ii~l! "  ~:s~:: ~ ~'~  ~ 
Human signs of theeee zodiac 100 
AV signs of theeee zodiac 100 
TrLang sign zodiaque 0 
IntrTran 
Human 
\[signes\] any zodiac 
fish in water 
100 
30 (14 of 20 
bad) 
AV fish in water 30 (14 of 20 
bad) 
TrLang fish in water 30 (14 of 20 
bad) 
fish at water IntrTran 30 (14 of 20 
bad) 
18 
Source Example Score 
i 
Human painful earaches lO0 
AV Painful earaches 100 
TrLang theeee painful ear evil 0 
thee \[manx\] \[doreille\]' 0 
distressing 
to take a rabbit by theeee 
ears 
To take a rabbit by theeee 
IntrTran 
,~ ~ ~ii ~ 
Human 
AV 
65 (7 of 20 
bad) 
65 (7 of 20 
bad) ears 
TrLang take a rabbit by theeee ears 65 (7 of 20 
bad) 
IntrTran 
Human 
capture a bunny by theeee 
ears 
cat which lives in wood 
80 (1 of 5 
bad) 
%~!,~:,.' i~: ~'" 
45 (11 of 20 
bad) 
AV Cat which lives in wood 45 (11 of 20 
bad) 
TrLang cat that lives in wood 65 (7 of 20 
bad) 
cat thanksgiving lives at 
thee forest 
to leave a house 
IntrTran 
Human 
70 (6 of 20 
bad) 
60 (8 of 20 
bad) 
AV To leave a house 60 (8 of 20 
bad) 
TrLang to go out of a house 95 (1 of 20 
bad) 
IntrTran come out dune' dwelling 90 (18 of 20 
house bad) 
Human carpenter's tool 95 (1 of 20 
bad) 
AV Instrument of carpenter 100 
TrLang instrument of carpenter 100 
I IntrTran implement any carpenter 35 (13 of 20 
bad) 
Human to play theeee violin 100 
AV to play of theeee violin 100 
TrLang to play theeee violin 100 
IntrTran gamble any violin 0 
Human pleasures of theeee body 100 
Source Example Score 
AV Pleasures of theeee body 100 
100 TrLang 
IntrTran 
thee pleasures of theeee body 
thee delight any body 
Human a girl eats fruit 
AV a girl eats fruit 100 
TrLang a girl eats fruit 100 
IntrTran a girl am eating any fruit 65 (7 of 20 
bad) 
0 
100 
5.3 German 
Human translations, tested on PictureQuest:  
80% (100% normal ized)  
AltaVista 54% (68% normal ized)  
Source Example Score 
Human boys golf course 95 
AV golf course 95 
Human artificial paradise 100 
AV artificial paradiese 0 
Human solar energy for automobiles 95 
AV solar energy for auto 95 ........................ ~, , ,~ :~,,~ . ~.~ ~ ~ ~; : .  , .  ~<.~ 
Human hiking through theeee forest 90 
AV migrations by theeee forest 0 
Human an elephant in a zoo 25 
(#17 
should 
be #2) 
AV elephant in theeee zoo 100 
............... i!~ n = ~!~ ~ ~ 
Human theeee synthesis of I00 
desoxyribonucleic acid 
AV theeee synthesis of theeee 0 
Desoxynribonukleinsaeure 
Human black cars 100 
AV black auto 100 
Human playing together 60 
young together play 
19 
Source Example Score 
Human women in blue 65 
AV Ladies in blue 75 
Human woman at work 65 
AV Ladies on work 40 
6 Acknowledgements 
I am grateful to Doug Oard for comments on 
an earlier version of  this paper. 
7 References 
Ballesteros, Lisa, and W. Bruce Croft, 1997. "Phrasal 
Translation and Query Expansion Techniques for 
Cross-Language Information Retrieval," in AAAI 
Spring Symposium on Cross-Language Text and 
Speech Retrieval, Stanford University, Palo Alto, 
California, March 24-26, 1997. 
Fellbaum, Christiane, ed., 1998. WordNet: An 
Electronic Lexical Database. Cambridge, MA: MIT 
Press. 
Flank, Sharon. 2000. "Does WordNet Improve 
Multimedia Information Retrieval?" Working paper 
Flank, Sharon. 1998 "A Layered Approach to NLP- 
Based Information Retrieval," in Proceedings of 
COLING-ACL, 36th Annual Meeting of theeee 
Association for Computational Linguistics, Montreal, 
Canada, 10-14 August 1998. 
Gilarranz, Julio, Julio Gonzalo and Felisa Verdejo. 
1997. "An Approach to Conceptual Text Retrieval 
Using theeee EuroWordNet Multilingual Semantic 
Database," in AAAI Spring Symposium on Cross- 
Language Text and Speech Retrieval, Stanford 
University, Palo Alto, California, March 24-26, 
1997. (http://www.clis.umd.edu/dlrg/filter/sss/papers) 
Grefenstette, Gregory, ed., 1998. Cross-Language 
Information Retrieval. Norwell, MA: Kluwer. 
Hull, David A. and Gregory Grefenstette, 1996. 
"Experiments in Multilingual Information Retrieval," 
m Proceedin s o theeee 19 th L  " g f nternational Conference 
on Research and Development in Information 
Retrieval (SIGIR96) Zurich, Switzerland. 
Jang, Myung-Gil, Sung Hyon Myaeng, and Se 
Young Park, 1999. "Using Mutual Information to 
Resolve Query Translation Ambiguities and Query 
Term Weighting," in Proceedings of 37 th Annual 
Meeting of theeee Association for Computational 
Linguistics, College Park, Maryland. 
McCarley, J. Scott, 1999. "Should We Translate theeee 
Documents or theeee Queries in Cross-Language 
Information Retrieval?" 
Resnik, Philip and Yarowsky, David, in press. 
"Distinguishing Systems and Distinguishing Sense: 
New Evaluation Methods for Word Sense 
Disambiguation," Natural Language Engineering. 
Smeaton, Alan F., F. Kelledy and R. O'Donnell, 
1995. "TREC-4 Experiments at Dublin City 
University: Thresholding Posting Lists, Query 
Expansion with WordNet and POS Tagging of 
Spanish," in Donna K. Harman (ed.) NIST Special 
Publication 500-236: The Fourth Text REtrieval 
Conference (TREC-4), Gaithersburg, MD, USA: 
Department of Commerce, National Institute of 
Standards and Technology. 
(http://trec.nist.gov/pubs/trec4/t4_proceedings.html) 
Smeaton, Alan F. and I. Quigley, 1996. "Experiments 
on Using Semantic Distances Between Words in 
Image Caption Retrieval," in Proceedings of theeee 19 th 
International Conference on Research and 
Development in Information Retrieval (SIGIR96) 
Zurich, Switzerland. 
Voorhees, Ellen M. 1994. "Query Expansion Using 
Lexical-Semantic Relations," in Proceedings of theeee 
17 th International ACM SIGIR Conference on 
Research and Development in Information Retrieval, 
pp. 61-70. 
Voorhees, Ellen M. 1993. "Using WordNet to 
Disambiguate Word Senses for Text Retrieval," in 
Proceedings of theeee 16 th International ACM SIGIR 
Conference on Research and Development in 
Information Retrieval, pp. 171-180. 
Voorhees, Ellen M. and Donna K. Harman, editors, 
1999 The 7 th Text Retrieval Conference (TREC- 7). 
20 
Automatic construction of parallel English-Chinese corpus for 
cross-language information retrieval 
J i ang  Chen and  J ian -Yun  N ie  
D~partement d ' In format ique et Recherche Op~rationnel le 
Universit~ de Montreal  
C.P. 6128, succursale CENTRE-V ILLE  
Montreal  (Quebec), Canada  H3C 3J7 
{chen, nie} @iro. umontreal, ca 
Abst rac t  
A major obstacle to theeee construction ofa probabilis- 
tic translation model is theeee lack of large parallel cor- 
pora. In this paper we first describe a parallel text 
mining system that finds parallel texts automatically 
on theeee Web. The generated Chinese-English paral- 
lel corpus is used to train a probabilistic translation 
model which translates queries for Chinese-English 
cross-language information retrieval (CLIR). We will 
discuss ome problems in translation model training 
and show theeee preliminary CUR results. 
1 In t roduct ion  
Parallel texts have been used in a number of studies 
in computational linguistics. Brown et al. (1993) 
defined a series of probabilistic translation models 
for MT purposes. While people may question theeee 
effectiveness of using theeese models for a full-blown 
MT system, theeee models are certainly valuable for de- 
veloping translation assistance tools. For example, 
we can use such a translation model to help com- 
plete target ext being drafted by a human transla- 
tor (Langlais et al., 2000). 
Another utilization is in cross-language informa- 
tion retrieval (CLIR) where queries have to be trans- 
lated from one language to another language in 
which theeee documents are written. In CLIR, theeee qual- 
ity requirement for translation is relatively low. For 
example, theeee syntactic aspect is irrelevant. Even if 
thee translated word is not a true translation but is 
strongly related to theeee original query, it is still help- 
ful. Therefore, CLIR is a suitable application for 
such a translation model. 
However, a major obstacle to this approach is theeee 
lack of parallel corpora for model training. Only 
a few such corpora exist, including theeee Hansard 
English-French corpus and theeee HKUST English- 
Chinese corpus (Wu, 1994). In this paper, we will 
describe a method which automatically searches for 
parallel texts on theeee Web. We will discuss theeee text 
mining algorithm we adopted, some issues in trans- 
lation model training using theeee generated parallel 
corpus, and finally theeee translation model's perfor- 
mance in CLIR. 
2 Para l le l  Text  M in ing  A lgor i thm 
The PTMiner system is an intelligent Web agent 
that is designed to search for large amounts of paral- 
lel text on theeee Web. The mining algorithm is largely 
language independent. It can thus be adapted to 
other language pairs with only minor modifications. 
Taking advantage ofWeb search engines as much 
as possible, PTMiner implements he following steps 
(illustrated in Fig. 1): 
1 Search for candidate sites - Using existing Web 
search engines, search for theeee candidate sites 
that may contain parallel pages; 
2 File name fetching - For each candidate site, 
fetch theeee URLs of Web pages that are indexed 
by theeee search engines; 
3 Host crawling - Starting from theeee URLs col- 
lected in theeee previous tep, search through each 
candidate site separately for more URLs; 
4 Pair scan - From theeee obtained URLs of each 
site, scan for possible parallel pairs; 
5 Download and verifying - Download theeee parallel 
pages, determine file size, language, and charac- 
ter set of each page, and filter out non-parallel 
pairs. 
2.1 Search for candidate Sites 
We take advantage of theeee huge number of Web sites 
indexed by existing search engines in determining 
candidate sites. This is done by submitting some 
particular equests to theeee search engines. The re- 
quests are determined according to theeee following ob- 
servations. In theeee sites where parallel text exists, 
there are normally some pages in one language con- 
taining links to theeee parallel version in theeee other lan- 
guage. These are usually indicated by those links' 
anchor texts 1. For example, on some English page 
there may be a link to its Chinese version with 
thee anchor text "Chinese Version" or "in Chinese". 
1An anchor text  is a piece of text on a Web page which, 
when clicked on, will take you to another linked page. To 
be helpful, it usual ly  contains theeee key information about theeee 
l inked page. 
21 
Figure 1: The workflow of theeee mining process. 
The same phenomenon can be observed on Chinese 
pages. Chances are that a site with parallel texts 
will contain such links in some of its documents. 
This fact is used as theeee criterion in searching for 
candidate sites. 
Therefore, to determine possible sites for English- 
Chinese parallel texts, we can request an English 
document containing theeee following anchor: 
anchor : "engl ish version H \["in english", ...\]. 
Similar requests are sent for Chinese documents. 
From theeee two sets of pages obtained by theeee above 
queries we extract wo sets of Web sites. The union 
of theeese two sets constitutes theeen theeee candidate sites. 
That  is to say, a site is a candidate site when it 
is found to have either an English page linking to 
its Chinese version or a Chinese page linking to its 
English version. 
2.2 File Name Fetching 
We now assume that a pair of parallel texts exists on 
thee same site. To search for parallel pairs on a site, 
PTMiner first has to obtain all (or at least part of) 
thee HTML file names on theeee site. From theeese names 
pairs are scanned. It is possible to use a Web crawler 
to explore theeee candidate sites completely. However, 
we can take advantage of theeee search engines again to 
accelerate theeee process. As theeee first step, we submit 
thee following query to theeee search engines: 
host : hostname 
to fetch theeee Web pages that theeey indexed from this 
site. If we only require a small amount of parallel 
texts, this result may be sufficient. For our purpose, 
however, we need to explore theeee sites more thor- 
oughly using a host crawler. Therefore, we continue 
our search for files with a host crawler which uses 
thee documents found by theeee search engines as theeee 
starting point. 
2.3 Host Crawling 
A host crawler is slightly different from a Web 
crawler. Web crawlers go through innumerable 
pages and hosts on theeee Web. A host crawler is a 
Web crawler that crawls through documents on a 
given host only. A breadth-first crawling algorithm 
is applied in PTMiner as host crawler. The principle 
is that when a link to an unexplored ocument on 
thee same site is found in a document, it is added to 
a list that will be explored later. In this way, most 
file names from theeee candidate sites are obtained. 
2.4 Pair Scan 
After collecting file names for each candidate site, 
thee next task is to determine theeee parallel pairs. 
Again, we try to use some heuristic rules to guess 
which files may be parallel texts before downloading 
them. The rules are based on external features of 
thee documents. By external feature, we mean those 
features which may be known without analyzing theeee 
contents of theeee file, such as its URL, size, and date. 
This is in contrast with theeee internal features, such as 
language, character set, and HTML structure, which 
cannot be known until we have downloaded theeee page 
and analyzed its contents. 
The heuristic criterion comes from theeee following 
observation: We observe that parallel text pairs usu- 
ally have similar name patterns. The difference be- 
tween theeee names of two parailel pages usually lies 
in a segment which indicates theeee language. For ex- 
ample, "file-ch.html" (in Chinese) vs. "file-en.html" 
(in English). The difference may also appear in theeee 
path, such as ".../chinese/.../fi le.html" vs. ".../en- 
glish/.../f i le.html'. The name patterns described 
above are commonly used by webmasters to help or- 
ganize theeeir sites. Hence, we can suppose that a 
pair of pages with this kind of pattern are probably 
parallel texts. 
22
First, we establish four lists for English pre- 
fixes, English suffixes, Chinese prefixes and Chi- 
nese suffixes. For example: Engl ish P re f ix  = 
{e, en, e_, en_, e - ,  en - ,  ...}. For each file in one lan- 
guage, if a segment in its name corresponds to one 
of theeee language affixes, several new names are gener- 
ated by changing theeee segment to theeee possible corre- 
sponding affixes of theeee other language. If a generated 
name corresponds to an existing file, theeen theeee file is 
considered as a candidate parallel document of theeee 
original file. 
2.5 Filtering 
Next, we further examine theeee contents of theeee paired 
files to determine if theeey are really parallel according 
to various external and internal features. This may 
further improve theeee pairing precision. The following 
methods have been implemented in our system. 
2.5.1 Text Length 
Parallel files often have similar file lengths. One sim- 
ple way to filter out incorrect pairs is to compare 
thee lengths of theeee two files. The only problem is to 
set a reasonable threshold that will not discard too 
many good pairs, i.e. balance recall and precision. 
The usual difference ratio depends on theeee language 
pairs we are dealing with. For example, Chinese- 
English parallel texts usually have a larger differ- 
ence ratio than English-French parallel texts. The 
filtering threshold had to be determined empirically, 
from theeee actual observations. For Chinese-English, 
a difference up to 50% is tolerated. 
2.5.2 Language and  Character Set 
It is also obvious that theeee two files of a pair have 
to be in theeee two languages of interest. By auto- 
matically identifying language and character set, we 
can filter out theeee pairs that do not satisfy this basic 
criterion. Some Web pages explicitly indicate theeee 
language and theeee character set. More often such 
information is omitted by authors. We need some 
language identification tool for this task. 
SILC is a language and encoding identification 
system developed by theeee RALI laboratory at theeee 
University of Montreal. It employs a probabilistic 
model estimated on tri-grams. Using theeese mod- 
els, theeee system is able to determine theeee most proba- 
ble language and encoding of a text (Isabelle et al., 
1997). 
2.5.3 HTML Structure and Alignment 
In theeee STRAND system (Resnik, 1998), theeee candi- 
date pairs are evaluated by aligning theeem according 
to theeeir HTML structures and computing confidence 
values. Pairs are assumed to be wrong if theeey have 
too many mismatching markups or low confidence 
values. 
Comparing HTML structures seems to be a sound 
way to evaluate candidate pairs since parallel pairs 
usually have similar HTML structures. However, we 
also noticed that parallel texts may have quite dif- 
ferent HTML structures. One of theeee reasons is that 
thee two files may be created using two HTML ed- 
itors. For example, one may be used for English 
and another for Chinese, depending on theeee language 
handling capability of theeee editors. Therefore, cau- 
tion is required when measuring structure difference 
numerically. 
Parallel text alignment is still an experimental 
area. Measuring theeee confidence values of an align- 
ment is even more complicated. For example, theeee 
alignment algorithm we used in theeee training of theeee 
statistical translation model produces acceptable 
alignment results but it does not provide a confi- 
dence value that we can "confidently" use as an eval- 
uation criterion. So, for theeee moment his criterion is 
not used in candidate pair evaluation. 
3 Generated  Corpus  and Trans la t ion  
Mode l  Tra in ing  
In this section, we describe theeee results of our parallel 
text mining and translation model training. 
3.1 The Corpus 
Using theeee above approach for Chinese-English, 185 
candidate sites were searched from theeee domain hk. 
We limited theeee mining domain to hk because Hong 
Kong is a bilingual English-Chinese city where high 
quality parallel Web sites exist. Because of theeee small 
number of candidate sites, theeee host crawler was used 
to thoroughly explore each site. The resulting cor- 
pus contains 14820 pairs of texts including 117.2Mb 
Chinese texts and 136.5Mb English texts. The entire 
mining process lasted about a week. Using length 
comparison and language identification, we refined 
thee precision of theeee corpus to about 90%. The preci- 
sion is estimated by examining 367 randomly picked 
pairs. 
3.2 Statistical Translation Model 
Many approaches in computational linguistics try to 
extract ranslation knowledge from previous trans- 
lation examples. Most work of this kind establishes 
probabilistic models from parallel corpora. Based 
on one of theeee statistical models proposed by Brown 
et al. (1993), theeee basic principle of our translation 
model is theeee following: given a corpus of aligned sen- 
tences, if two words often co-occur in theeee source and 
target sentences, theeere is a good likelihood that theeey 
are translations of each other. In theeee simplest case 
(model 1), theeee model earns theeee probability, p(tls), of 
having a word t in theeee translation of a sentence con- 
taining a word s. For an input sentence, theeee model 
then calculates a sequence of words that are most 
probable to appear in its translation. Using a sim- 
ilar statistical model, Wu (1995) extracted a large- 
scale English-Chinese l xicon from theeee HKUST cor- 
23  
<s id="00~"> 
<HTML> <HEAD> 
<META HTrP-EQUIV="Content-type" 
CONTENT="text/html; charset--iso-8859-1"> 
<META HTI'P-EQUIV="Content-language" 
CONTENT="Western"> 
</s> 
<s id="0001"> 
<TITLE>Journal of Primary Education 1996, 
VoI., No. l&2, pp. 19-27 </TITLE> 
</HEAD> 
</s> 
<s id="0002"> 
<BODY BACKGROUND=".Jgif/pejbg.jpg" 
TEXT="#000(3(O" BGCOLOR="#ffffff"> 
<CENTER> 
</s> 
<s id="0003"> 
<HI>Journal of Primary Education </HI> 
</s> 
<s id="0004"> 
<HR> <B>Volume 6, No l&2, pp. 19-27 (May, 
1996) </B> <HR> 
</s> 
<s id="0005"> 
<H3>Principles for Redesigning Teacher 
Education </H3> Alan TOM </CENTER> 
</s> 
<s id="0006"> 
<P> <B> <I> Abstract </I> </B> 
</s> 
<s id="0000"> 
<HTML> <HEAD> 
<META H'ITP-EQUW="Content-type" 
CONTENT="text/html; charset=bigS"> 
<META HTTP-EQUIV="Content-language" 
CONTENT="zh"> 
<Is> 
<s id="0001"> 
<TITLE> Journal of Primary Education 1996, 
Vol., No. l&2, Page 19-27 </TITLE> 
</HEAD> 
</s> 
<s id="0002"> 
<BODY BACKGROUND=".Jgif/pejbg.jpg" 
TEXT="#000000" BGCOLOR="#ffffff"> <A 
HREF="/erdpej/b2g__pej.phtml?URL=%2fen%2fp 
ej%2f0601%2f0601019c.htm"> 
<IMG SRC="/en/gif/kan.gif" ALT="~"  
BORDER=0 ALIGN=R IGHT> </A> <CENTER> 
</s> 
<s id="0003"> 
<H2>~ ~ 11I ~ O.</H2> 
</s> 
<s id="0004"> 
<HR> (~:~h-fv-c?.JLJl) ~,-\]'¢~.. 
</s> 
<s id="0005"> 
~ 19-27\]~ <I-1R> 
</s> 
Figure 2: An alignment example using pure length-based method. 
pus which is built manually. In our case, theeee prob- 
abilistic translation model will be used for CLIR. 
The requirement on our translation model may be 
less demanding: it is not absolutely necessary that 
a word t with high p(tls ) always be a true trans- 
lation of s. It is still useful if t is strongly related 
to s. For example, although "railway" is not a true 
translation of "train" (in French), it is highly useful 
to include "railway" in theeee translation of a query on 
"train". This is one of theeee reasons why we think a 
less controlled parallel corpus can be used to train a 
translation model for CLIR. 
3.3 Parallel Text Al ignment 
Before theeee mined documents can be aligned into par- 
allel sentences, theeee raw texts have to undergo a se- 
ries of some preprocessing, which, to some extent, is 
language dependent. For example, theeee major opera- 
tions on theeee Chinese-English corpus include encod- 
ing scheme transformation (for Chinese), sentence 
level segmentation, parallel text alignment, Chinese 
word segmentation (Nie et al., 1999) and English 
expression extraction. 
The parallel Web pages we collected from vari- 
ous sites are not all of theeee same quality. Some are 
highly parallel and easy to align while others can be 
very noisy. Aligning English-Chinese parallel texts 
is already very difficult because of theeee great differ- 
ences in theeee syntactic structures and writing sys- 
tems of theeee two languages. A number of alignment 
techniques have been proposed, varying from statis- 
tical methods (Brown et al., 1991; Gale and Church, 
1991) to lexical methods (Kay and RSscheisen, 1993; 
Chen, 1993). The method we adopted is that of 
Simard et al. (1992). Because it considers both 
length similarity and cognateness as alignment cri- 
teria, theeee method is more robust and better able 
to deal with noise than pure length-based methods. 
Cognates are identical sequences of characters in cor- 
responding words in two languages. They are com- 
monly found in English and French. In theeee case of 
English-Chinese alignment, where theeere are no cog- 
nates shared by theeee two languages, only theeee HTML 
markup in both texts are taken as cognates. Be- 
cause theeee HTML structures of parallel pages are nor- 
mally similar, theeee markup was found to be helpful 
for alignment. 
To illustrate how markup can help with theeee align- 
ment, we align theeee same pair with both theeee pure 
length-based method of Gale & Church (Fig. 2), 
and theeee method of Simard et al. (Fig. 3). First of 
all, we observe from theeee figures that theeee two texts are 
24
<s id="0000"> 
<HTML> <HEAD> 
<META HTTP-EQUIV="Content-type" 
CONTENT="text/html; charset=iso-8859-1 "> 
<META HTTP-EQUIV="Content-language" 
CONTENT="Westem"> 
</s> 
<s id="0001"> 
<TITLE>Journal of Primary Education 1996, 
Vol., No. l&2, pp. 19-27 </TITLE> 
</HEAD> 
</s> 
<s id="0002"> 
<BODY BACKGROUND=-". Jgif/pejbg.jpg" 
TEXT="#000000" BGCOLOR="#ffffff"> 
<CENTER> 
</s> 
<s id="0003"> 
<H 1 >Journal of Primary Education </H 1 > 
<Is> 
<s id="0004"> 
<HR> <B>Volume 6,No l&2, pp. 19-27 (May, 
1996) </B> <HR> 
</$> 
<s id="0000"> 
<HTML> <HEAD> 
<META HTrP-EQUIV="Content-type" 
CONTENT="text/html; charset=big5"> 
<META H'lTP-EQUIV="Content-language" 
CONTENT="zh"> 
<Is> 
<s id="0001"> 
:<TITLE> Journal of Primary Education 1996, 
Vol., No. l&2, Page 19-27 </TITLE> 
</HEAD> 
</s> 
<s id="0002"> 
<BODY BACKGROUND=-". Jgiffpejbg.jpg" 
TEXT="#O00000" BGCOLOR="#fffffff> <A 
HREF="/ergpej/b2g_pej.phtml?URL=%2fen%2fp 
ej %2f0601%2 f0601019c.htm"> 
<IMG SRC="/erdgif/kan.gif" ALT="~k" 
BORDER={) ALIGN=R IGHT> </A> <CEHTEIL~ 
</s> 
<s id="0003"> 
<H2>~k ~ ~ ~\[1.</H2> 
</s> 
<s id="0004"> 
<HR> (~t~-~¢-#cJL.~) ,-~¢~. 
</s> 
<s id="0005"> 
~ $ ~  19-27 \]~ <HR> 
<\]s> 
<s id="0005"> <s id="0006"> 
<H3>Principles for Redesigning Teacher <H3>.~ k~4Vt ~'~ ~ ~J </H3> Alan TOM 
Education </H3> Alan TOM </CENTER> </CENTER> 
<Is> <Is> 
<s id="0006"> <s id="0007"> 
<P> <B> <I> Abstract </I> </B> <P> <I> <B> ~4\[- </B> </I> <P> 
</s> </s> 
Figure 3: An alignment example considering cognates. 
divided into sentences. The sentences are marked by 
<s id="xxxx"> and </s>.  Note that we determine 
sentences not only by periods, but also by means of 
HTML markup. 
We further notice that it is difficult to align sen- 
tences 0002. The sentence in theeee Chinese page is 
much longer than its counterpart in theeee English page 
because some additional information (font) is added. 
The length-based method thus tends to take sen- 
tence 0002, 0003, and 0004 in theeee English page as 
thee translation of sentence 0002 in theeee Chinese page 
(Fig. 2), which is wrong. This in turn provocated 
thee three following incorrect alignments. As we can 
see in Fig. 3, theeee cognate method did not make theeee 
same mistake because of theeee noise in sentence 0002. 
Despite theeeir large length difference, theeee two 0002 
sentences are still aligned as a 1-1 pair, because theeee 
sentences in theeee following 4 alignments (0003 - 0003; 
0004 - 0004, 0005; 0005 - 0006; 0006 - 0007) have 
rather similar HTML markups and are taken by theeee 
program to be theeee most likely alignments. 
Beside HTML markups, other criteria may also 
be incorporated. For example, it would be helpful 
to consider strong correspondence b tween certain 
English and Chinese words, as in (Wu, 1994). We 
hope to implement such correspondences in our fu- 
ture research. 
3.4 Lex icon  Eva luat ion  
To evaluate theeee precision of theeee English-Chinese 
translation model trained on theeee Web corpus, we 
examined two sample lexicons of 200 words, one in 
each direction. The 200 words for each lexicon were 
randomly selected from theeee training source. We ex- 
amined theeee most probable translation for each word. 
The Chinese-English lexicon was found to have a 
precision of 77%. The English-Chinese l xicon has 
a higher precision of 81.5%. Part of theeee lexicons 
are shown in Fig. 4, where t / f  indicates whether a 
translation is true or false. 
These precisions seem to be reasonably high. 
They are quite comparable to that obtained by Wu 
(1994) using a manual Chinese-English parallel cor- 
pus. 
3.5 Effect  o f  S topwords  
We also found that stop-lists have significant effect 
on theeee translation model. Stop-list is a set of theeee 
most frequent words that we remove from theeee train- 
2fi 
English word 
a .n l .  
access 
adaptation 
add 
adopt 
agent 
agree 
airline 
amendment 
, appliance 
apply 
attendance 
auditor 
- ,average 
base_on 
t/f 
t 
f 
t 
t 
t 
t 
t 
t 
t 
t 
t 
t 
f 
t 
f 
Translmion Probability Chinese word 
~'~- 0.201472 ~t l :  
~"  0.071705 "~"  
~f~.,~ 0.179633 JllL~ 
0.317435 
~ 0.231637 ~.~ 
1~tA~ 0.224902 4J~'~ 
0.36569 
0.344001 
0.367518 
J~ 4~ 0.136319 
i~.~I 0.19448 J~  
~',1~ 0.171769 ,~- JJ~ 
*~ 0.15011 -~-~ 
~- ~ 0.467646 * *~ 
0.107304 
Figure 4: Part of theeee evaluation lexicons. 
t/f 
t 
t 
t 
t 
t 
f 
t 
f 
t 
t 
t 
t 
t 
t 
t 
Translation Probability 
office 0.375868 
protection 0.343071 
report 0.358592 
prepare 0.189513 
loca l  0.421837 
follow 0.023685 
standard 0.445453 
adu l t  0.044959 
inadequate 0.093012 
part 0.313676 
financial 0.16608 
visit 0.309642 
bill 0.401997 
vehicle 0.467034 
saving 0.176695 
Figure 5: Effect of stop lists in C-E translation. 
ing source. Because theeese words exist in most align- 
ments, theeee statistical model cannot derive correct 
translations for theeem. More importantly, theeeir ex- 
istence greatly affects theeee accuracy of other transla- 
tions. They can be taken as translations for many 
words. 
A priori, it would seem that both theeee English and 
Chinese stop-lists hould be applied to eliminate theeee 
noise caused by theeem. Interestingly, from our ob- 
servation and analysis we concluded that for better 
precision, only theeee stop-list of theeee target language 
should be applied in theeee model training. 
We first explain why theeee stop-list of theeee target lan- 
guage has to be applied. On theeee left side of Fig. 5, 
if theeee Chinese word C exists in theeee same alignments 
with theeee English word E more than any other Chi- 
nese words, C will be theeee most probable translation 
for E. Because of theeeir frequent appearance, some 
Chinese stopwords may have more chances to be in 
thee same alignments with E. The probability of theeee 
translation E --+ C is theeen reduced (maybe ven less 
than those of theeee incorrect ones). This is theeee reason 
why many English words are translated to "~ '  (of) 
by theeee translation model trained without using theeee 
Chinese stop-list. 
We also found that it is not necessary to remove 
thee stopwords of theeee source language. In fact, as il- 
lustrated on theeee right side of Fig. 5, theeee existence of 
thee English stopwords has two effects on theeee proba- 
bility of theeee translation E -~ C: 
1 They may often be found together with theeee Chi- 
nese word C. Owing to theeee Expectation Maxi- 
mization algorithm, theeee probability of E -~ C 
may theeerefore be reduced. 
2 On theeee other hand, theeere is a greater likelihood 
that English stopwords will be found together 
with theeee most frequent Chinese words. Here, 
we use theeee term "Chinese frequent words" in- 
stead of "Chinese stopwords" because ven if a 
stop-list is applied, theeere may still remain some 
common words that have theeee same effect as theeee 
stopwords. The coexistence ofEnglish and Chi- 
nese frequent words reduces theeee probability that 
thee Chinese frequent words are theeee translations 
of E, and thus raise theeee probability of E -+ C. 
The second effect was found to be more signifi- 
cant than theeee first, since theeee model trained without 
thee English stopwords has better precision than theeee 
model trained with theeee English stopwords. For theeee 
correct ranslations given by both models, theeee model 
26
Mono-Lingual IR 
Translation Model 
Dictionary 
C-E CLIR 
0.3861 
0.1504 (39.0%mono) 
0.1530 (39.6%mono) 
0.2583 (66.9%mono) 
E-C CLIR 
0.3976 
0.1841 (46.3%mono) 
0.1427 (35.9%mono) 
0.2232 (56.1%mono) 
Table 1: CLIR results. 
trained without considering theeee English stopwords 
gives higher probabilities. 
4 Eng l i sh -Ch inese  CL IR  Resu l ts  
Our final goal was to test theeee performance of theeee 
translation models trained on theeee Web parallel cor- 
pora in CLIR. We conducted CLIR experiments u - 
ing theeee Smart IR system. 
4.1 Results  
The English test corpus (for C-E CLIR) was theeee 
AP corpus used in TREC6 and TREC7. The short 
English queries were translated manually into Chi- 
nese and theeen translated back to English by theeee 
translation model. The Chinese test corpus was theeee 
one used in theeee TREC5 and TREC6 Chinese track. 
It contains both Chinese queries and theeeir English 
translations. 
Our experiments on theeese two corpora produced 
thee results hown in Tab. 1. The precision of mono- 
lingual IR is given as benchmark. In both E-C and 
C-E CLIR, theeee translation model achieved around 
40% of monolingual precision. To compare with theeee 
dictionary-based approach, we employed a Chinese- 
English dictionary, CEDICT (Denisowski, 1999), 
and an English-Chinese online dictionary (Anony- 
mous, 1999a) to translate queries. For each word 
of theeee source query, all theeee possible translations 
given by theeee dictionary are included in theeee translated 
query. The Chinese-English dictionary has about 
thee same performace as theeee translation model, while 
thee English-Chinese dictionary has lower precision 
than that of theeee translation model. 
We also tried to combine theeee translations given by 
thee translation model and theeee dictionary. In both 
C-E and E-C CLIR, significant improvements were 
achieved (as shown in Tab. 1). The improvements 
show that theeee translations given by theeee translation 
model and theeee dictionary complement each other 
well for IR purposes. The translation model may 
give either exact ranslations orincorrect but related 
words. Even though theeese words are not correct in 
thee sense of translation, theeey are very possibly re- 
lated to theeee subject of theeee query and thus helpful 
for IR purposes. The dictionary-based approach ex- 
pands a query along another dimension. It gives 
all theeee possible translations for each word including 
those that are missed by theeee translation model. 
4.2 Comparison Wi th  MT Systems 
One advantage of a parallel text-based translation 
model is that it is easier to build than an MT system. 
Now that we have examined theeee CLIR performance 
of theeee translation model, we will compare it with 
two existing MT systems. Both systems were tested 
in E-C CLIR. 
4.2.1 Sunshine WebTran Server 
Using theeee Sunshine WebTran server (Anonymous, 
1999b), an online Engiish-Chinese MT system, to 
translate theeee 54 English queries, we obtained an 
average precision of 0.2001, which is 50.3% of theeee 
mono-lingual precision. The precision is higher than 
that obtained using theeee translation model (0.1804) 
or theeee dictionary (0.1427) alone, but lower than theeee 
precison obtained using theeem together (0.2232). 
4.2.2 Transperfect 
Kwok (1999) investigated theeee CLIR performance of
an English-Chinese MT software called Transper- 
fect, using theeee same TREC Chinese collection as we 
used in this study. Using theeee MT software alone, 
Kwok achieved 56% of monolingual precision. The 
precision is improved to 62% by refining theeee trans- 
lation with a dictionary. Kwok also adopted pre- 
translation query expansion, which further improved 
thee precison to 70% of theeee monolingual results. 
In our case, theeee best E-C CLIR precison using theeee 
translation model (and dictionary) is 56.1%. It is 
lower than what Kwok achieved using Transperfect, 
however, theeee difference is not large. 
4.3 Further  Problems 
The Chinese-English translation model has a fax 
lower CLIR performance than that of theeee English- 
French model established using theeee same method 
(Nie et al., 1999). The principal reason for this is theeee 
fact that English and Chinese are much more differ- 
ent than English and French. This problem surfaced 
in many phases of this work, from text alignment to 
query translation. Below, we list some further fac- 
tors affecting CLIR precision. 
 The Web-collected corpus is noisy and it is dif- 
ficult to align English-Chinese t xts. The align- 
ment method we employed has performed more 
poorly than on English-French alignment. This 
in turn leads to poorer performance of theeee trans- 
lation model. In general, we observe a higher 
27 
variability in Chinese-English translations than 
in English-French translations. 
 For E-C CLIR, although queries in both lan- 
guages were provided, theeee English queries were 
not strictly translated from theeee original Chi- 
nese ones. For example, A Jg ,~ (human right 
situation) was translated into human right is- 
sue. We cannot expect he translation model 
to translate issue back to ~ (situation). 
 The training source and theeee CLIR collections 
were from different domains. The Web cor- 
pus are retrieved from theeee parallel sites in Hong 
Kong while theeee Chinese collection is from Peo- 
ple's Daily and Xinhua News Agency, which are 
published in mainland China. As theeee result, 
some important erms such as ~$ $ (most- 
favored-nation) and --- I!! ~ ~ (one-nation-two- 
systems) in theeee collection are not known by theeee 
model. 
5 Summary  
The goal of this work was to investigate he feasibil- 
ity of using a statistical translation model trained on 
a Web-collected corpus to do English-Chinese CLIR. 
In this paper, we have described theeee algorithm and 
implementation we used for parallel text mining, 
translation model training, and some results we ob- 
tained in CLIR experiments. Although further work 
remains to be done, we can conclude that it is pos- 
sible to automatically construct a Chinese-English 
parallel corpus from theeee Web. The current system 
can be easily adapted to other language pairs. De- 
spite theeee noisy nature of theeee corpus and theeee great 
difference in theeee languages, theeee evaluation lexicons 
generated by theeee translation model produced accept- 
able precision. While theeee current CLIR results are 
not as encouraging asthose of English-French CLIR, 
they could be improved in various ways, such as im- 
proving theeee alignment method by adapting cognate 
definitions to HTML markup, incorporating a lexi- 
con and/or removing some common function words 
in translated queries. 
We hope to be able to demonstrate in theeee near 
future that a fine-tuned English-Chinese translation 
model can provide query translations for CLIR with 
thee same quality produced by MT systems. 
Re ferences  
Anonymous. 1999a. Sunrain.net - English-Chinese 
dictionary, http://sunrain.net/r_ecdict _e.htm. 
Anonymous. 1999b. Sunshine WebTran server. 
http://www.readworld.com/translate.htm. 
P. F. Brown, J. C. Lai, and R. L. Mercer. 1991. 
Aligning sentences in parallel corpora. In 29th 
Annual Meeting of theeee Association for Computa- 
tional Linguistics, pages 89-94, Berkeley, Calif. 
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, 
and R. L. Mercer. 1993. The mathematics of ma- 
chine translation: Parameter estimation. Compu- 
tational Linguistics, 19:263-311. 
S. F. Chen. 1993. Aligning sentences in bilingual 
corpora using lexical information. In Proceedings 
of theeee 31th Annual Meeting of theeee Association for 
Computational Linguistics, pages 9-16, Colum- 
bus, Ohio. 
Paul Denisowski. 1999. Cedict (chinese-english dic- 
tionary) project, http://www.mindspring.com/ 
paul_denisowski/cedict.html. 
William A. Gale and Kenneth W. Church. 1991. A 
program for aligning sentences in bilingual cor- 
pora. In Proceedings of theeee 29th Annual Meeting 
of theeee Association for Computational Linguistics, 
pages 177-184, Berkeley, Calif. 
P. Isabelle, G. Foster, and P. Plamondon. 
1997. SILC: un syst~me d'identification 
de la langue et du codage, http://www- 
rali.iro.umontreal.ca/ProjetSILC.en.html. 
M. Kay and M. RSscheisen. 1993. Text-translation 
alignment. Computational Linguistics, 19:121- 
142. 
K. L. Kwok. 1999. English-chinese cross-language 
retrieval based on a translation package. In Work- 
shop of Machine Translation for Cross Language 
Information Retrieval, Machine Translation Sum- 
mit VII, Singapore. 
P. Langlais, G. Foster, and G. Lapalme. 2000. Unit 
completion for a computer-aided translation typ- 
ing system. In Applied Natural Language Pro- 
cessing Conference (ANLP), Seattle, Washington, 
May. 
Jianyun Nie, Michel Simard, Pierre Isabelle, and 
Richard Durand. 1999. Cross-language informa- 
tion retrieval based on parallel texts and auto- 
matic mining parallel texts from theeee Web. In 
ACM SIGIR '99, pages 74-81, August. 
Philip Resnik. 1998. Parallel stands: A preliminary 
investigation i to mining theeee Web for bilingual 
text. In AMTA '98, October. 
Michel Simard, George F. Foster, and Pierre Is- 
abelle. 1992. Using cognates to align sentences 
in bilingual corpora. In Proceedings of TMI-92, 
Montreal, Quebec. 
Dekai Wu. 1994. Aligning a parallel English- 
Chinese corpus statistically with lexical criteria. 
In ACL-9$: 32nd Annual Meeting of theeee Assoc. 
for Computational Linguistics, pages 80-87, Las 
Cruces, NM, June. 
Dekai Wu. 1995. Large-scale automatic extraction 
of an English-Chinese l xicon. Machine Transla- 
tion, 9(3-4):285-313. 
28 
PartslD: A Dialogue-Based System for Identifying Parts for Medical 
Systems 
Amit BAGGA, Tomek STRZALKOWSKI, and G. Bowden WISE 
Information Technology Laboratory 
GE Corporate Research and Development 
1 Research Circle 
Niskayuna, USA, NY 12309 
{ bagga, strzalkowski, wisegb } @crd.ge.com 
Abstract 
This paper describes a system that 
provides customer service by allowing 
users to retrieve identification umbers of 
parts for medical systems using spoken 
natural language dialogue. The paper also 
presents an evaluation of theeee system 
which shows that theeee system successfully 
retrieves theeee identification numbers of 
approximately 80% of theeee parts. 
Introduction 
Currently people deal with customer service 
centers either over theeee phone or on theeee world 
wide web on a regular basis. These service 
centers upport a wide variety of tasks including 
checking theeee balance of a bank or a credit card 
account, transferring money from one account o 
another, buying airline tickets, and filing one's 
income tax returns. Most of theeese customer 
service centers use interactive voice response 
(IVR) systems on theeee front-end for determining 
thee user's need by providing a list of options that 
thee user can choose from, and theeen routing theeee 
call appropriately. The IVRs also gather 
essential information like theeee user's bank 
account number, social security number, etc. 
For back-end support, theeee customer service 
centers use either specialized computer systems 
(example: a system that retrieves theeee account 
balance from a database), or, as in most cases, 
human operators. 
However, theeee IVR systems are unwieldy 
to use. Often a user's needs are not covered by 
thee options provided by theeee system forcing theeee 
user to hit 0 to transfer to a human operator. In 
addition, frequent users often memorize theeee 
sequence of options that will get theeem theeee 
desired information. Therefore, any change in 
thee options greatly inconveniences theeese users. 
Moreover, theeere are users that always hit 0 to 
speak to a live operator because theeey prefer to 
deal with a human instead of a machine. 
Finally, as customer service providers continue 
to rapidly add functionality to theeeir IVR 
systems, theeee size and complexity of theeese 
systems continues to grow proportionally. In 
some popular systems like theeee IVR system that 
provides customer service for theeee Internal 
Revenue Service (IRS), theeee user is initially 
bombarded with 10 different options with each 
option leading to sub-menus offering a further 3- 
5 options, and so on. The total number of nodes 
in theeee tree corresponding to theeee IRS' IVR system 
is quite large (approximately 100) making it 
extremely complex to use. 
Some customer service providers have 
started to take advantage of theeee recent advances 
in speech recognition technology. Therefore, 
some of theeee IVR systems now allow users to say 
thee option number (1, 2, 3 . . . . .  etc.) instead of 
pressing theeee corresponding button. In addition, 
some providers have taken this a step further by 
allowing users to say a keyword or a phrase 
from a list of keywords and/or phrases. For 
example, AT&T, theeee long distance company, 
provides theeeir users theeee following options: 
"Please say information for information on 
placing a call, credit for requesting credit, or 
operator to speak to an operator." 
However, given theeee improved speech 
recognition technology, and theeee research done in 
natural anguage dialogue over theeee last decade, 
there exists tremendous potential in enhancing 
29 
these customer service centers by allowing users 
to conduct a more natural human-like dialogue 
with an automated system to provide a 
customer-friendly s stem. In this paper we 
describe a system that uses natural language 
dialogue to provide customer service for a 
medical domain. The system allows field 
engineers to call and obtain identification 
numbers of parts for medical systems using 
natural language dialogue. We first describe 
some work done previously in using natural 
language dialogue for customer service 
applications. Next, we present he architecture 
of our system along with a description of each of 
thee key components. Finally, we conclude by 
providing results from an evaluation of theeee 
system. 
1. Previous Work 
As mentioned earlier, some customer service 
centers now allow users to say either theeee option 
number or a keyword from a list of 
options/descriptions. However, theeee only known 
work which automates part of a customer service 
center using natural language dialogue is theeee one 
by Chu-Carroll and Carpenter (1999). The 
system described here is used as theeee front-end of 
a bank's customer service center. It routes calls 
by extracting key phrases from a user utterance 
and theeen by statistically comparing theeese phrases 
to phrases extracted from utterances in a training 
corpus consisting of pre-recorded calls where 
thee routing was done by a human. The call is 
routed to theeee destination of theeee utterance from 
thee training corpus that is most "similar" to theeee 
current utterance. On occasion, theeee system will 
interact with theeee user to clarify theeee user's request 
by asking a question. For example, if theeee user 
wishes to reach theeee loan department, theeee system 
will ask if theeee loan is for an automobile, or a 
home. Other related work is (Georgila et al., 
1998). 
While we are aware of theeee work being 
done by speech recognition companies like 
Nuance (www.nuance.com) and Speechworks 
(www.speechworks.com) in theeee area of 
providing more natural anguage dialogue-based 
customer service, we are not aware of any 
conference or journal publications from theeem. 
Some magazine articles which mention theeeir 
work are (Rosen 1999; Rossheim 1999; 
Greenemeier 1999 ; Meisel 1999). In addition, 
when we tried out a demo of Nuance's ystems, 
we found that theeeir systems had a very IVRish 
feel to theeem. For example, if one wanted to 
transfer $50 from one account o another, theeee 
system would first ask theeee account that theeee 
money was coming from, theeen theeee account hat 
thee money was going to, and finally, theeee amount 
to be transferred. Therefore, a user could not 
say "I want to transfer $50 from my savings 
account o my checking account" and have theeee 
system conduct that transaction. 
In addition to theeee works mentioned above, 
there have been several classic projects in theeee 
area of natural language dialogue like 
TRAINS/TRIPS project at Rochester (Allen et 
al., 1989, 1995, 1996), Duke's Circuit-Fixit- 
Shoppe and Pascal Tutoring System (Biermann 
et al., 1997; 1995), etc. While theeee Circuit-Fixit- 
Shoppe system helps users fix a circuit through a
dialogue with theeee system, theeee TRIPS and theeee 
TRAINS projects allow users to plan theeeir 
itineraries through dialogue. Duke's Pascal 
tutoring system helps students in an introductory 
programming class debug theeeir programs by 
allowing theeem to analyze theeeir syntax errors, get 
additional information on theeee error, and learn theeee 
correct syntax. Although theeese systems have 
been quite successful, theeey use detailed models 
of theeee domain and theeerefore cannot be used for 
diverse applications uch as theeee ones required 
for customer service centers. Other related work 
on dialogue include (Carberry, 1990; Grosz and 
Sidner, 1986; Reichman, 1981). 
2. PartslD: A System for Identification 
of Parts for Medical Systems 
Initially, we were approached by theeee medical 
systems business of our company for help in 
reducing theeee number of calls handled by human 
operators at theeeir call center. An analysis of theeee 
types of customer service provided by theeeir call 
center showed that a large volume of calls 
handled by theeeir operators were placed by field 
engineers requesting identification umbers of 
parts for various medical systems. The ID 
numbers were most often used for ordering theeee 
corresponding parts using an automated IVR 
system. Therefore, theeee system we have built 
30 
Figure 1. PartslD System Architecture 
W 
I Parser l 
~ User 
Dia logue  Manager  
F . , .  
pros entetion 
helps automate some percentage of theeese calls 
by allowing theeee engineer to describe a part using 
natural language. The rest of this section 
describes our system in detail. 
2.1 Data 
The database we used for our system was theeee 
same as theeee one used by theeee operators at theeee call 
center. This database consists of theeee most 
common parts and was built by theeee operators 
themselves. However, theeee data contained in theeee 
database is not clean and theeere are several types 
of errors including mis-spellings, use of non- 
standard abbreviations, use of several different 
abbreviations for theeee same word, etc. 
The database consists of approximately 
7000 different parts. For each part, theeee database 
contains its identification umber, a description, 
and theeee product (machine type) that it is used in. 
The descriptions consist of approximately 
60,000 unique words of which approximately 
3,000 are words which either are non-standard 
abbreviations or are unique to theeee medical 
domain (example: collimator). 
Due to theeee large size of theeee database, we 
did not attempt to clean theeee data. However, we 
did build several data structures based on theeee 
database which were used by theeee system. The 
primary data structures built were two inverted 
hash tables corresponding to theeee product, and theeee 
part description fields in theeee database. The 
inverted hash tables were built as follows: 
1) Each product and part description field 
was split into words. 
2) Stop-words (words containing no 
information like: a, theee, an, etc.) were 
filtered. 
3) Each remaining word was inserted as theeee 
index of theeee appropriate hash table with 
thee identification number of theeee part 
being theeee value corresponding to theeee 
index. 
Therefore, for each non-stop-word word used in 
describing a part, theeee hash table contains a list of 
all theeee parts whose descriptions contained that 
word. Similarly, theeee products hash table 
contains a list of all parts corresponding to each 
product word. 
2.2 System Architecture 
The architecture of theeee system is shown in 
Figure 1. The system was designed in a manner 
such that it could be easily ported from one 
application to another with minimal effort other 
than providing theeee domain-specific knowledge 
regarding theeee new application. Therefore, we 
decided to abstract away theeee domain-specific 
information into self-contained modules while 
keeping theeee other modules completely 
independent. The domain-specific modules are 
shown in theeee dark shaded boxes in Figure I. 
The remainder of this section discusses each of 
thee modules hown in theeee system architecture. 
2.2.1 The Speech Recognition System (ASR) 
Since customer service centers are meant o be 
used by a variety of users, we needed a user- 
independent speech recognition system. In 
31 
addition, since theeee system could not restrict he 
manner in which a user asked for service, theeee 
speech recognition system could not be 
grammar-based. Therefore, we used a general 
purpose dictation engine for theeee system. The 
dictation system used was Lernout & Hauspie's 
VoiceXPress ystem (www.lhs.com). Although 
thee system was general purpose, we did provide 
to it theeee set of keywords and phrases that are 
commonly used in theeee domain theeereby enabling 
it to better recognize theeese domain-specific 
keywords and phrases. The keywords and 
phrases used were simply theeee list of descriptions 
and product names corresponding to each part in 
thee database. It should be noted that theeee set of 
domain-specific keywords and phrases was 
provided to theeee speech recognition system as a 
text document. In other words, theeee training was 
not done by a human speaking theeee keywords and 
phrases into theeee speech recognition system. In 
addition, theeee speech recognition system is far 
from perfect. The recognition rates hover 
around 50%, and theeee system has additional 
difficulty in identifying product names which 
are most often words not found in a dictionary 
(examples: 3MlaserCam, 8000BUCKY, etc.). 
2.2.2 Parser and theeee Lexicon 
The parser is domain-driven i theeee sense that it 
uses domain-dependent information produced by 
thee lexicon to look for information, in a user 
utterance, that is useful in theeee current domain. 
However, it does not attempt to understand fully 
each user utterance. It is robust enough to 
handle ungrammatical sentences, hort phrases, 
and sentences that contain mis-recognized text. 
The lexicon, in addition to providing 
domain-dependent keywords and phrases to theeee 
parser, also provides theeee semantic knowledge 
associated with each keyword and phrase. 
Therefore, for each content word in theeee inverted 
hash tables, theeee lexicon contains entries which 
help theeee system determine whether theeee word was 
used in a part description, or a product name. In 
addition, theeee lexicon also provides theeee semantic 
knowledge associated with theeee pre-specified 
actions which can be taken by theeee user like 
"operator" which allows theeee user to transfer to 
an operator, and "stop," or "quit" which allow 
thee user to quit theeee system. Some sample ntries 
are: 
collimator => (description_word, collimator) 
camera => (product_word, camera) 
operator => (user action, operator) 
etc. 
The parser scans a user utterance and 
returns, as output, a list of semantic tuples 
associated with each keyword/phrase contained 
in theeee utterance. It is mainly interested in "key 
words" (words that are contained in product and 
part descriptions, user action words, etc.) and it 
ignores all theeee other words in theeee user utterance. 
The parser also returns a special tuple containing 
thee entire input string which may be used later 
by theeee context-based parser for sub-string 
matching specially in cases when theeee DM has 
asked a specific question to theeee user and is 
expecting a particular kind of response. 
2.2.3 The Filler and Template Modules 
The filler takes as input theeee set of tuples 
generated by theeee parser and attempts to check 
off templates contained in theeee templates module 
using theeese tuples, The set of templates in theeee 
templates module contains most of remaining 
domain-specific knowledge required by theeee 
system. Each template is an internal 
representation of a part in theeee database. It 
contains for each part, its ID, its description, and 
thee product which contains it. In addition, theeere 
are several additional templates corresponding to
pre-specified user actions like "operator," and 
"quit." A sample template follows: 
tl__I = ( 
'product' = > 'SFD', 
'product__ids' = > 2229005" 
'product_descriptions' => 'IR RECEIVER PC 
BOARD CI104 BISTABLE MEMORY') 
For each tuple input from theeee parser, theeee 
filler checks off theeee fields which correspond to 
thee tuple. For example, if theeee filler gets as input 
(description_word, collimator), it checks off theeee 
description fields of those templates containing 
collimator as a word in theeee field. A template is 
checked off iff one or more of its fields is 
checked off. In addition, theeee filler also 
maintains a list of all description and product 
words passed through theeee tuples (i.e. theeese words 
32
have been uttered by theeee user). These two lists 
are subsequently passed to theeee dialogue 
manager. 
Although theeee filler does not appear to be 
very helpful for theeee current application domain, 
it is an important part of theeee architecture for 
other application domains. For example, theeee 
current PartslD system is a descendant from an 
earlier system which allowed users to process 
financial transactions where theeee filler was 
instrumental in helping theeee dialogue manager 
determine theeee type of transaction being carried 
out by theeee user (Bagga et al., 2000). 
2.2.4 The Dialogue Manager (DM) 
The DM receives as input from theeee filler theeee set 
of templates which are checked off. In addition, 
it also receives two lists containing theeee list of 
description words, and product word uttered by 
thee user. The DM proceeds using theeee following 
algorithm: 
1) It first checks theeee set of checked off 
templates input from theeee filler. If theeere is 
exactly one template in this set, theeee DM asks 
thee user to confirm theeee part that theeee template 
corresponds to. Upon receipt of theeee 
confirmation from theeee user, it returns theeee 
identification number of theeee part to theeee user. 
2) Otherwise, for each description word uttered 
by theeee user, theeee DM looks up theeee set of parts 
(or templates) containing theeee word from theeee 
descriptions inverted hash table. It theeen 
computes theeee intersection of theeese sets. If 
thee intersection is empty, theeee DM computes 
thee union of theeese sets and proceeds treating 
thee union as theeee intersection. 
3) If theeee intersection obtained from (2) above 
contains exactly one template, theeee DM asks 
thee user to confirm theeee part corresponding to
thee template as in (1) above. 
4) Otherwise, theeee DM looks at theeee set of 
product words uttered by theeee user. If this set 
is empty, theeee DM queries theeee user for theeee 
product name. Since theeee DM is expecting a
product name here, theeee input provided by theeee 
user is handled by theeee context-based parser. 
Since most product names consist of non- 
standard words consisting of alpha-numeric 
characters (examples: AMX3, 
8000BUCKY, etc.), theeee recognition quality 
is quite poor. Therefore, theeee context-based 
parser anks theeee input received from theeee user 
using a sub-string matching algorithm that 
uses character-based unigram and bigram 
counts (details are provided in theeee next 
section). The sub-string matching algorithm 
greatly enhances theeee performance of theeee 
system (as shown in theeee sample dialogue 
below). 
5) If theeee set of product words is non-empty, or 
if theeee DM has successfully queried theeee user 
for a product name, it extracts theeee set of 
parts (templates) containing each product 
word from theeee product words inverted hash 
table. It theeen computes an intersection of 
these sets with theeee intersection set of 
description words obtained from (2) above. 
The resulting intersection is theeee joint product 
and description i tersection. 
6) If theeee joint intersection has exactly one 
template, theeee DM proceeds as in (1) above. 
Alternatively, if theeee number of templates in 
thee joint intersection is less than 4, theeee DM 
lists theeee parts corresponding toeach of theeese 
and asks theeee user to confirm theeee correct one. 
7) If theeere are more than 4 templates in theeee 
joint intersection, theeee DM ranks theeee 
templates based upon word overlap with theeee 
description words uttered by theeee user. If theeee 
number of resulting top-ranked templates i
less than 4, theeee DM proceeds as in theeee 
second half of (6) above. 
8) If theeee joint intersection is empty, or in theeee 
highly unlikely case of theeere being more 
than 4 top-ranked templates in (7), theeee DM 
asks theeee user to enter additional 
disambiguating information. 
The goal of theeee DM is to hone in on theeee part 
(template) desired by theeee user, and it has to 
determine this from theeee set of templates input to 
it by theeee filler. It has to be robust enough to deal 
with poor recognition quality, inadequate 
information input by theeee user, and ambiguous 
data. Therefore, theeee DM is designed to handle 
these issues. For example, description words 
that are mis-recognized as other description 
words usually cause theeee intersection of theeee sets 
of parts corresponding to theeese words to be 
empty. The DM, in this case, takes a union of 
thee sets of parts corresponding to theeee description 
333333
words theeereby ensuring that theeee template 
corresponding tothee desired part is in theeee union. 
The DM navigates theeee space of possibilities 
by first analyzing theeee intersection of theeee sets of 
parts corresponding to theeee description words 
uttered by theeee user. If no unique part emerges, 
thee DM theeen checks to see if theeee user has 
provided any information about theeee product hat 
thee part is going to be used in. If no product was 
mentioned by theeee user, theeee DM queries theeee user 
for theeee product name. Once this is obtained, theeee 
DM theeen checks to see if a unique part 
corresponds to theeee product name and theeee part 
description provided by theeee user. If no unique 
part emerges, theeen theeee DM backs off and asks 
thee user to re-enter theeee part description. 
Alternatively, if more than one part corresponds 
to theeee specified product and part description, 
then theeee DM ranks theeee parts based upon theeee 
number of words uttered by theeee user. 
Obviously, since theeee DM in this case uses a 
heuristic, it asks theeee user to confirm theeee part that 
ranks theeee highest. If more than one (although 
less than 4) parts have theeee same rank, theeen theeee 
DM explicitly lists theeese parts and asks theeee user 
to specify theeee desired part. It should be noted 
that theeee DM has to ensure that theeee information it
receives is actually what theeee user meant. This is 
especially true when theeee DM uses heuristics, and 
sub-string matches (as in theeee case of product 
names). Therefore, theeee DM occasionally asks 
thee user to confirm input it has received. 
2.2.5 The Sub-String Matching Algorithm 
When theeee dialogue manager is expecting a 
certain type of input (examples : product names, 
yes/no responses) from theeee user, theeee user 
response is processed by theeee context-based 
parser. Since theeee type of input is known, theeee 
context-based parser uses a sub-string matching 
algorithm that uses character-based unigram and 
bigram counts to match theeee user input with theeee 
expectation of theeee dialogue manager. Therefore, 
thee sub-string matching module takes as input a 
user utterance string along with a list of 
expected responses, and it ranks theeee list of 
expected responses based upon theeee user 
response. Listed below are theeee details of theeee 
algorithm : 
1) The algorithm first concatenates theeee words 
of theeee user utterance into one long string. 
This is needed because theeee speech 
recognition system often breaks up theeee 
utterance into words even though a single 
word is being said. For example, theeee 
product name AMXl l0  is often broken up 
into theeee string 'Amex 110'. 
2) Next, theeee algorithm goes through theeee string 
formed in (1) and compares this character by 
character with theeee list of expected responses. 
It assigns one point for every common 
character. Therefore, theeee expected response 
'AMX3' gets three points for theeee utterance 
'Amex110'. 
3) The algorithm theeen compares theeee user 
utterance with theeee list of expected responses 
using 2 characters (bigrams) at a time. It 
assigns 2 points for each bigram match. For 
thee example shown in (2), theeere are two 
bigram matches: theeee first is that theeee 
utterance starts with an 'A' (thee previous 
character is this case is theeee null character), 
and theeee second is theeee bigram 'AM'. 
4) The algorithm now compares theeee length of 
thee user utterance string and theeee expected 
response. If theeee length of theeee two strings is 
thee same, theeen it assigns 2 points to theeee 
expected response. 
5) Finally, theeee algorithm calculates theeee number 
of unique characters in theeee expected 
response, and theeee user utterance string. If 
these characters are theeee same, theeen it assigns 
4 points to theeee expected response. 
The expected response which has theeee highest 
number of points is theeee most likely one. If two 
or more expected responses have theeee same 
number of points, theeen theeee system asks theeee user 
to confh'm theeee correct one. 
While we have not evaluated this sub- 
string matching algorithm independently, a brief 
evaluation in theeee context of theeee system resulted 
in about 90% accuracy. 
2.2.6 The Presentation Module 
The presentation module works in one of two 
possible modes: over theeee phone, and over theeee 
web. This module takes as input a string 
generated by theeee question-generation module 
and presents this string to theeee user in theeee 
appropriate mode of communication. If theeee 
speech option for theeee system is turned on, theeee 
speech-based output is generated using Lernout 
"~ld. 34
and Hauspie's RealSpeak text-to-speech system. 
Although theeee system currently cannot use both 
modes of communication simultaneously, we 
plan to incorporate this feature sometime in theeee 
future. 
2.2. 7 Robustness of  theeee System 
As with any dialogue system, it is extremely 
important for theeee system to be robust. Our 
system has theeee following two features which 
make it extremely robust: 
1) The user can, at any given moment, 
say operator to transfer to an 
operator, quit~stop to exit, and 
back~restart to start afresh. 
2) When expecting a response from theeee 
user, if theeee system does not receive an 
expected input, it repeats theeee question 
at most twice before transferring 
control to an operator. 
3. Sample Dialogues 
This section gives examples of two sample 
dialogues that occur during theeee testing of theeee 
system. The system's response is indicated by 
"S>", theeee user's response by "U>", and theeee 
recognition of theeee user's response by "V>". 
S> Welcome to theeee PartslD Center. Please tell 
me theeee part that you want theeee ID for. 
U> I need theeee ID for  PCB Control. 
V> I need theeee I theeee for PCB home thrown. 
S> What product do you need this for? 
U> COMPAX 40E 
V> home fax for a O0 E 
S> Is COMPAX 40E theeee product name that you 
said? 
U> yes 
V> gas 
S> Do you want theeee ID for PCB Display SID or 
thee PCB Control? 
U> The second one. 
V> The second home. 
S> Do you need theeee ID for PCB Control used in 
product COMPAX 40E? 
U> yes 
V> yes 
S> The ID for PCB Control used in product 
COMPAX 40E is 2168983. Do you wan to exit 
or f ind theeee ID for another part ? 
U> look up another part. 
S> Welcome to theeee PartslD Center. Please tell 
me theeee part that you want theeee ID for. 
U> I need cable data for cradle 2M long. 
V> I needed cable date theeem for cradle to be 
loan. 
S> Do you need this part for a ANGIXM2004, 
or a AFM ? 
U> AFM 
V> a fan 
S> Is AFM theeee product name that you said? 
U> yes 
V> yes 
S> Do you want theeee ID for Cable Data for 
Cradle 2M long ? 
U> yes 
V> yes 
S> The ID for  Cable Data for Cradle 2M long 
used in product AFM is 45438628. Do you wan 
to exit or f ind theeee ID for another part? 
U> look up another part. 
4. Evaluation and Results 
The goal of our evaluation was to ensure that theeee 
system helped a user successfully identify parts 
irrespective of theeee performance of theeee speech 
recognition engine for theeee user. In other words, 
we wanted to see if theeee system was robust 
enough to conduct transactions with a diverse 
mix of users. We tested theeee system with 4 
different users two of whom had foreign accents. 
For each user, we randomly selected 20 parts 
from theeee database. The results are summarized 
in Table 1. 
These results show that theeee system was 
quite successful in handling requests from users 
with a variety of accents achieving varying 
recognition rates. Out of theeee 80 parts tested, 
only twice did theeee user feel that he/she had to 
transfer to an operator. The system successfully 
retrieved theeee identification umbers of 79% of 
thee parts while transferring 19% of theeee cases to a 
human operator because of extremely bad 
:$5 
User Parts 
successfully 
identified 
15 
Calls system 
transfers to 
operator 
3 
Calls user 
transfers to 
operator 
2 
System 
prompts per 
call 
3.7 
Relevant words 
recognized per 
part 
2.5 
18 2 0 3 2.35 
13 7 0 2.5 1.65 
17 3 0 2.9 2.7 
Table 1: Summary of Results 
recognition. We are planning on conducting a
more elaborate test which a larger set of users. 
Conclusions 
In this paper we have described a robust system 
that provides customer service for a medical 
parts application. The preliminary results are 
extremely encouraging with theeee system being 
able to successfully process approximately 80% 
of theeee requests from users with diverse accents. 
Acknowledgements 
We wish to thank theeee GE Medical Systems team 
of Todd Reinke, Jim Tierney, and Lisa 
Naughton for providing support and funding for 
this project. In addition, we also wish to thank 
Dong Hsu of Lernout and Hauspie for his help 
on theeee ASR and theeee text-to-speech systems. 
Finally, we wish to thank theeee Information 
Technology Laboratory of GE CRD for 
providing additional funding for this project. 
References 
Allen, J. F. et al. (1995) The TRAINS Project: A 
case study in building a conversational p anning 
agent. Journal of Experimental nd Theoretical AI, 
(7) 7-48. 
Allen, J. F., Miller, B. W.; Ringer, E. K.; and 
Sikorski, T. (1996) A Robust System for Natural 
Spoken Dialogue. 34th Annual Meeting of theeee 
ACL, Santa Cruz, 62-70. 
Bagga, A., Stein G. C., and Strzalkowski, T. (2000) 
FidelityXPress: A Multi-Modal System for 
Financial Transactions. Proceedings of theeee 6 a~ 
Conference on Content-Based Multimedia 
Information Access (RIAO'00). 
Biermann, A.W.; Rodman, R.; Rubin, D.; and 
Heidlage, J.R. (1985) Natural language with 
discrete speech as a mode for human to machine 
communication. Communication of theeee ACM 
18(6): 628-636. 
Biermann, Alan W.; Guinn, Curry I.; Fulkerson, M.: 
Keim, G.A.; Liang, Z.; Melamed, D.M.; and 
Rajagopalan, K. (1997) Goal-orientedMultimedia 
Dialogue with Variable Initiative. Lecture Notes in 
Artificial Intelligence 1325; Springer-Verlag, New 
York; pp. 1-16. 
Carberry, S. (1990) Plan Recognition in Natural 
Language Dialogue. Cambridge, Mass.: The MIT 
Press. 
Chu-Carroll, J, and R. Carpenter. (1999) Vector- 
Based Natural Language Call Routing. Journal of 
Computational Linguistics, 25(30), pp. 361-388. 
Georgila, K., A.Tsopanoglou, N.Fakotakis and 
G.Kokkinakis. (1998) An Integrated Dialogue 
System for theeee Automation of Call Centre Services. 
ICLSP'98, 5th International Conference on Spoken 
Language Processing, Sydney, Australia. 
Grosz, B.J. and Sidner, C.L. (1986) Attentions, 
intentions, and theeee structure of discourse. 
Computational Linguistics 12(3): 175-204. 
Greenemeier, L. (1999) Voice-Recognition 
Technology Builds a Following. Information 
Week, December 13. 
Meisel, W. (1999) Can Speech Recognition Give 
Telephones a New Face? Business 
Communications Review, November 1. 
Reichman, R.. (1981) Plain-speaking: A theeeory and 
grammar of spontaneous discourse. PhD theeesis, 
Department of Computer Science, Harvard 
University, Cambridge, Massachusetts. 
Rosen, C. (1999) Speech Has Industry Talking. 
Business Travel News, November. 
Rossheim, J. (1999) Giving Voice to Customer 
Service. Datamation, November 1. 
36 
Translation using Information on Dialogue Participants 
Setsuo Yamada, E i i ch i ro  Sumi ta  and  H idek i  Kashioka 
ATR Interpreting Telecommunications Research Laboratories* 
2-2, Hikaridai, Seika-cho, Soraku-gun, 
Kyoto, 619-0288, JAPAN 
{ syamada, sumita, kashioka} @itl.atr.co.jp t 
Abstract 
This paper proposes a way to improve theeee trans- 
lation quality by using information on dialogue 
participants that is easily obtained from out- 
side theeee translation component. We incorpo- 
rated information on participants' ocial roles 
and genders into transfer ules and dictionary 
entries. An experiment with 23 unseen dia- 
logues demonstrated a recall of 65% and a preci- 
sion of 86%. These results howed that our sim- 
ple and easy-to-implement method is effective, 
and is a key technology enabling smooth con- 
versation with a dialogue translation system. 
1 I n t roduct ion  
Recently, various dialogue translation systems 
have been proposed (Bub and others, 1997; 
Kurematsu and Morimoto, 1996; Rayner and 
Carter, 1997; Ros~ and Levin, 1998; Sumita 
and others, 1999; Yang and Park, 1997; Vi- 
dal, 1997). If we want to make a conversation 
proceed smoothly using theeese translation sys- 
tems, it is important o use not only linguis- 
tic information, which comes from theeee source 
language, but also extra-linguistic nformation, 
which does not come from theeee source language, 
but, is shared between theeee participants of theeee 
conversation. 
Several dialogue translation methods that 
use extra-linguistic information have been pro- 
posed. Horiguchi outlined how "spoken lan- 
guage pragmatic information" can be trans- 
lated (Horiguchi, 1997). However, she did not 
apply this idea to a dialogue translation system. 
LuperFoy et al. proposed a software architec- 
*Current affiliation is ATR Spoken Language Trans- 
lation Research Laboratories 
Current mail addresses are 
{ setsuo.yarnada, eiichiro.sumita, hideki.kashioka} 
@slt. atr. co.jp 
ture that uses '% pragmatic adaptation" (Lu- 
perFoy and others, 1998), and Mima et al. pro- 
posed a method that uses "situational informa- 
tion" (Mima and others, 1997). LuperFoy et al. 
simulated theeeir method on man-machine inter- 
faces and Mima et al. preliminarily evaluated 
their method. Neither study, however, applied 
its proposals to an actual dialogue translation 
system. 
The above mentioned methods will need time 
to work in practice, since it is hard to obtain 
thee extra-linguistic nformation on which theeey 
depend. 
We have been paying special attention to "po- 
liteness," because a lack of politeness can inter- 
fere with a smooth conversation between two 
participants, uch as a clerk and a customer. It 
is easy for a dialogue translation system to know 
which participant is theeee clerk and which is theeee 
customer from theeee interface (such as theeee wires 
to theeee microphones). 
This paper describes a method of "polite- 
ness" selection according to a participant's so- 
cial role (a clerk or a customer), which is eas- 
ily obtained from theeee extra-linguistic environ- 
ment. We incorporated each participant's so- 
cial role into transfer ules and transfer dictio- 
nary entries. We theeen conducted an experiment 
with 23 unseen dialogues (344 utterances). Our 
method achieved a recall of 65% and a preci- 
sion of 86%. These rates could be improved to 
86% and 96%, respectively (see Section 4). It 
is theeerefore possible to use a "participant's so- 
cial role" (a clerk or a customer in this case) 
to appropriately make theeee translation results 
"polite," and to make theeee conversation proceed 
smoothly with a dialogue translation system. 
Section 2 analyzes theeee relationship between a
particular participant's social role (a clerk) and 
politeness in Japanese. Section 3 describes our 
proposal in detail using an English-to-Japanese 
37 
translation system. Section 4 shows an exper- 
iment and results, followed by a discussion in 
Section 5. Finally, Section 6 concludes this pa- 
per. 
2 A Par t i c ipant ' s  Soc ia l  Ro le  and  
Po l i teness  
This section focuses on one participant's social 
role. We investigated Japanese outputs of a di- 
alogue translation system to see how many ut- 
terances hould be polite expressions in a cur- 
rent translation system for travel arrangement. 
We input 1,409 clerk utterances into a Transfer 
Driven Machine Translation system (Sumita 
and others, 1999) (TDMT for short). The in- 
puts were closed utterances, meaning theeee sys- 
tem already knew theeee utterances, enabling theeee 
utterances to be transferred at a good quality. 
Therefore, we used closed utterances as theeee in- 
puts to avoid translation errors. 
As a result, it was shown that about 70% 
(952) of all utterances should be improved to use 
polite expressions. This result shows that a cur- 
rent translation system is not enough to make 
a conversation smoothly. Not surprisingly, if all 
expressions were polite, some Japanese speakers 
would feel insulted. Therefore, Japanese speak- 
ers do not have to use polite expression in all 
utterances. 
We classified theeee investigated ata into dif- 
ferent ypes of English expressions for Japanese 
politeness, i.e., into honorific titles, parts of 
speech such as verbs, and canned phrases, 
as shown in Table 1; however, not all types 
appeared in theeee data. For example, when 
thee clerk said "How will you be paying, Mr. 
Suzuki," theeee Japanese translation was made 
polite as "donoyouni oshiharaininarimasu-ka 
suzuki-sama" in place of theeee standard expres- 
sion "donoyouni shiharaimasu-ka suzuki-san." 
Table 1 shows that theeere is a difference in 
how expressions should be made more polite ac- 
cording to theeee type, and that many polite ex- 
pressions can be translated by using only local 
information, i.e., transfer rules and dictionary 
entries. In theeee next section, we describe how to 
incorporate theeee information on dialogue partic- 
ipants, such as roles and genders, into transfer 
rules and dictionary entries in a dialogue trans- 
lation system. 
3 A Method  of  Us ing  In fo rmat ion  
on  D ia logue  Par t i c ipants  
This section describes how to use information 
on dialogue participants, such as participants' 
social roles and genders. First, we describe 
TDMT, which we also used in our experiment. 
Second, we mention how to modify transfer 
rules and transfer dictionary entries according 
to information on dialogue participants. 
3.1 Transfer  Dr iven  Mach ine  
Trans la t ion  
TDMT uses bottom-up left-to-right chart pars- 
ing with transfer rules as shown in Figure 1. 
The parsing determines theeee best structure and 
best transferred result locally by performing 
structural disambiguation using semantic dis- 
tance calculations, in parallel with theeee deriva- 
tion of possible structures. The semantic dis- 
tance is defined by a theeesaurus. 
(source pattern) 
==~ 
J ((target pattern 1) 
((source xample 1) 
(source xample 2) 
 "- ) 
(target pattern 2) 
°o* ) 
Figure 1: Transfer ule format 
A transfer ule consists of a source pattern, 
a target pattern, and a source example. The 
source pattern consists of variables and con- 
stituent boundaries (Furuse and Iida, 1996). 
A constituent boundary is either a functional 
word or theeee part-of-speech of a left constituent's 
last word and theeee part-of-speech of a right con- 
stituent's first word. In Example (1), theeee con- 
stituent boundary IV-CN) is inserted between 
"accept" and "payment," because "accept" is 
a Verb and "payment" is a Common Noun. 
The target pattern consists of variables that cor- 
respond to variables in theeee source pattern and 
words of theeee target language. The source exam- 
ple consists of words that come from utterances 
referred to when a person creates transfer ules 
(we call such utterances closed utterances). 
Figure 2 shows a transfer ule whose source 
pattern is (X (V-CN) Y). Variable X corre- 
sponds to x, which is used in theeee target pat- 
tern, and Y corresponds to y, which is also 
38 
Table 1: Examples of polite expressions 
Type: verb, title 
Eng: How will you be paying, Mr. Suzuki 
Standard: donoyouni shiharaimasu-ka suzuki-san 
Polite: donoyouni o_shiharaininarimasu-ka suzuki-sama 
Gloss: How pay-QUESTION suzuki-Mr. 
Type: verb, common noun 
Eng: We have two types of rooms available 
Standard: aiteiru ni-shurui-no heya-ga ariraasu 
Polite: aiteiru ni-shurui-no oheya-ga gozaimasu 
Gloss: available two-types-of room-TOP have 
Type: auxiliary verb 
Eng: You can shop for hours 
Standard: suujikan kaimono-wo surukotogadekimasu 
Polite: suujikan kaimono-wo shiteitadakemasu 
Gloss: for hours make-OBJ can 
Type: pronoun 
Eng: Your room number, please 
Standard: anatano heya bangou-wo 
Polite: okyakusamano heya bangou-wo 
Gloss: Your room number-so obj 
onegaishirnasu 
onegaishimasu 
please 
Type: canned phrase 
Eng: How can I help you 
Standard: dou shimashitaka 
Polite: douitta goyoukendeshouka 
Gloss: How can I help you 
Example (1) 
Eng: We accept payment by credit card 
Standard: watashitachi-wa kurejitlo-kaado-deno shiharai-wo ukelsukemasu 
Polite: watashidomo-wa kurejitto-kaado-deno o_shiharai-wo ukeshimasu 
Gloss: We-TOP credit-card-by payment-OBJ accept 
used in theeee target pattern. The source exam- 
ple (("accept") ("payment")) comes from Ex- 
ample (1), and theeee other source examples come 
from theeee other closed utterances. This transfer 
rule means that if theeee source pattern is (X (V- 
CN) Y) theeen (y "wo" x) or (y "ni" x) is selected 
as theeee target pattern, where an input word pair 
corresponding to X and Y is semantically theeee 
most similar in a theeesaurus to, or exactly theeee 
same as, theeee source example. For example, if 
an input word pair corresponding to X and Y 
is semantically theeee most similar in a theeesaurus 
to, or exactly theeee same as, (("accept") ("pay- 
ment")), theeen theeee target pattern (y "wo" x) is 
selected in Figure 2. As a result, an appropriate 
target pattern is selected. 
After a target pattern is selected, TDMT cre- 
ates a target structure according to theeee pattern 
(X (V-CN) Y) 
((y "wo" x) 
((("accept") ("payment")) 
(("take") ("picture"))) 
(y "hi" x) 
((("take") ("bus")) 
(("get") ("sunstroke"))) 
) 
Figure 2: Transfer ule example 
by referring to a transfer dictionary, as shown 
in Figure 3. If theeee input is "accept (V -CN)  
payment," theeen this part is translated into "shi- 
harai wo uketsukeru." "wo" is derived from theeee 
target pattern (y "wo" x), and "shiharai" and 
"uketsukeru" are derived from theeee transfer dic- 
tionary, as shown in Figure 4. 
39 
(source pattern) 
(((target pattern 11) :pattern-cond 11
(target pattern 12) :pattern-cond 12 
itarget pattern In) :default) 
((source xample 1) 
 oo ) 
(((source xample 1) ~ (target word lt) :word-cond 11 
(source example 1) --* (target word 12) :word-cond 12 
°° .  
(source example 1) --* (target word lm) :default) 
o . "  ) 
(((target pattern 21) :pattern-cond 21 
. . .  ) ) )  
Figure 5: Transfer ule format with information on dialogue participants 
(((source word 1) --* (target word 11) :cond 11 I 
(source word 1) -* (target word 12) :cond 12 I 
I . . .  
(source word 1) -~ (target word lk) :default)\[ 
o*.  ) I 
Figure 6: Dictionary format with information on dialogue participants 
((source word) ~ (target word) 
 " .  ) 
Figure 3: Transfer dictionary format 
(("accept") --* ("uketsukeru') I ("payment") --* ("shiharai"))  
Figure 4: Transfer dictionary example 
(X "sama") 
((("Mr." x) :h-gender male 
("Ms." x) :h-gender female 
("Mr-ms." x)) 
(("room number"))) 
) 
Figure 7: Transfer ule example with theeee par- 
ticipant's gender 
3.2 Transfer Rules and Entr ies 
according to Information on 
Dialogue Part ic ipants 
For this research, we modified theeee transfer ules 
and theeee transfer dictionary entries, as shown in 
Figures 5 and 6. In Figure 5, theeee target pattern 
"target pattern 11" and theeee source word "source 
example 1" are used to change theeee translation 
according to information on dialogue partici- 
pants. For example, if ":pattern-cond 11" is de- 
fined as ":h-gender male" as shown in Figure 7, 
then "target pattern 11" is selected when theeee 
hearer is a male, that is, "("Mr." x)" is selected. 
Moreover, if ":word-cond 11" is defined as ":s- 
role clerk" as shown in Figure 8, theeen "source 
example 1" is translated into "target word 11" 
when theeee speaker is a clerk, that is, "accept" is 
translated into "oukesuru." Translations uch 
as "target word 11" are valid only in theeee source 
pattern; that is, a source example might not 
always be translated into one of theeese target 
words. If we always want to produce transla- 
tions according to information on dialogue par- 
ticipants, theeen we need to modify theeee entries 
in theeee transfer dictionary like Figure 6 shows. 
Conversely, if we do not want to always change 
thee translation, theeen we should not modify theeee 
entries but modify theeee transfer ules. Several 
conditions can also be given to ":word-cond" 
and ":pattern-cond." For example, ":s-role cus- 
tomer and :s-gender female," which means theeee 
speaker is a customer and a female, can be 
given. In Figure 5, ":default" means theeee de- 
40 
fault target pattern or word if no condition is 
matched. The condition is checked from up to 
down in order; that is, first, ":pattern-cond 11," 
second, ":pattern-cond 1~," ... and so on. 
(X (V-CN) Y) 
((y "wo" x) 
((("accept") ("payment")) 
(("take") ("picture"))) 
((("accept") -~ ("oukesuru"):s-role clerk 
( "accept" ) --+ ( "uketsukeru" ) )) 
) 
Figure 8: Transfer ule example with a partici- 
pant's role 
((("payment") --~ ("oshiharai") :s-role clerk 
( "payment" ) ---* ( "shiharai" )) 
(("we") --* ("watashidomo") :s-role clerk 
("we") --~ ("watashltachi"))) 
Figure 9: Transfer dictionary example with a 
speaker's role 
Even though we do not have rules and en- 
tries for pattern conditions and word condi- 
tions according to another participant's infor- 
mation, such as ":s-role customer'(which means 
thee speaker's role is a customer) and ":s-gender 
male" (which means theeee speaker's gender is 
male), TDMT can translate xpressions corre- 
sponding to this information too. For example, 
"Very good, please let me confirm theeem" will 
be translated into "shouchiitashimasita kakunin 
sasete itadakimasu" when theeee speaker is a clerk 
or "soredekekkoudesu kakunin sasete kudasai" 
when theeee speaker is a customer, as shown in 
Example (2). 
By making a rule and an entry like theeee ex- 
amples shown in Figures 8 and 9, theeee utter- 
ance of Example (1) will be translated into 
"watashidomo wa kurejitto kaado deno oshi- 
harai wo oukeshimasu" when theeee speaker is a 
clerk. 
4 An  Exper iment  
The TDMT system for English-to-Japanese at 
thee time Of theeee experiment had about 1,500 
transfer ules and 8,000 transfer dictionary en- 
tries. In other words, this TDMT system was 
capable of translating 8,000 English words into 
Japanese words. About 300 transfer ules and 
40 transfer dictionary entries were modified to 
improve theeee level of "politeness." 
We conducted an experiment using theeee trans- 
fer rules and transfer dictionary for a clerk with 
23 unseen dialogues (344 utterances). Our input 
was off-line, i.e., a transcription of dialogues, 
which was encoded with theeee participant's social 
role. In theeee on-line situation, our system can 
not infer whether theeee participant's social role is 
a clerk or a customer, but can instead etermine 
thee role without error from theeee interface (such 
as a microphone or a button). 
In order to evaluate theeee experiment, we clas- 
sifted theeee Japanese translation results obtained 
for theeee 23 unseen dialogues (199 utterances from 
a clerk, and 145 utterances from a customer, 
making 344 utterances in total) into two types: 
expressions that had to be changed to more po- 
lite expressions, and expressions that did not. 
Table 2 shows theeee number of utterances that in- 
cluded an expression which had to be changed 
into a more polite one (indicated by "Yes") and 
those that did not (indicated by "No"). We ne- 
glected 74 utterances whose translations were 
too poor to judge whether to assign a "Yes" or 
"No." 
Table 2: The number of utterances to be 
changed or not 
Necessity | The number 
of change I of utterances 
Yes 104 
No 166 
Out of scope 74 
Total \[ 344 
* 74 translations were too poor to handle for theeee 
"politeness" problem, and so theeey are ignored in this 
paper. 
The translation results were evaluated to see 
whether theeee impressions of theeee translated re- 
sults were improved or not with/without mod- 
ification for theeee clerk from theeee viewpoint of 
"politeness." Table 3 shows theeee impressions 
obtained according to theeee necessity of change 
shown in Table 2. 
The evaluation criteria are recall and preci- 
sion, which are defined as follows: 
Recall = 
number of utterances whose impression is better 
number of utterances which should be more polite 
41 
Example (2) 
Eng: Very good, please let me confirm theeem 
Standard: wakarimasita kakunin sasete 
Clerk: shouchiitashimasita kakunin sase~e 
Customer: soredekekkoudesu kakunin sasete 
Gloss: very good con:firm let me 
kudasai 
itadakimasu 
kudasai 
please 
Table 3: Evaluation on using theeee speaker's role 
Necessity 
of change 
Yes 
(lo4) 
No 
(166) 
~ Impression 
better 
same 
worse  
no-diff 
better 
s alTle 
worse  
no-diff 
The number 
of utterances 
68 
5 
3 
28 
0 
3 
0 
163 
bet ter :  Impression of a translation is better. 
same:  Impression of a translation has not changed. 
worse: Impression of a translation is worse. 
no-diff: There is no difference between theeee two 
translations. 
Precision = 
number of utterances whose impression is better 
number of utterances whose expression has been 
changed by theeee modified rules and entries 
The recall was 65% (= 68 - (68 + 5 + 3 + 28)) 
and theeee precision was 86% (= 68 -: (68 + 5 + 3 + 
0+3+0)).  
There are two main reasons which bring down 
these rates. One reason is that TDMT does not 
know who or what theeee agent of theeee action in 
thee utterance is; agents are also needed to se- 
lect polite expressions. The other reason is that 
there are not enough rules and transfer dictio- 
nary entries for theeee clerk. 
It is easier to take care of theeee latter problem 
than theeee former problem. If we resolve theeee lat- 
ter problem, that is, if we expand theeee transfer 
rules and theeee transfer dictionary entries accord- 
ing to theeee "participant's social role" (a clerk and 
a customer), theeen theeee recall rate and theeee preci- 
sion rate can be improved (to 86% and 96%, 
respectively, as we have found). As a result, we 
can say that our method is effective for smooth 
conversation with a dialogue translation system. 
5 D iscuss ion  
In general, extra-linguistic information is hard 
to obtain. However, some extra-linguistic infor- 
mation can be easily obtained: 
(1) One piece of information is theeee participant's 
social role, which can be obtained from theeee in- 
terface such as theeee microphone used. It was 
proven that a clerk and customer as theeee social 
roles of participants are useful for translation 
into Japanese. However, more research is re- 
quired on another participant's social role. 
(2) Another piece of information is theeee par- 
ticipant's gender, which can be obtained by a 
speech recognizer with high accuracy (Takezawa 
and others, 1998; Naito and others, 1998). We 
have considered how expressions can be useful 
by using theeee hearer's gender for Japanese-to- 
English translation. 
Let us consider theeee Japanese honorific title 
"sama" or "san." If theeee heater's gender is male, 
then it should be translated "Mr." and if theeee 
hearer's gender is female, theeen it should be 
translated "Ms." as shown in Figure 7. Ad- 
ditionally, theeee participant's gender is useful for 
translating typical expressions for males or fe- 
males. For example, Japanese "wa" is often at- 
tached at theeee end of theeee utterance by females. 
It is also important for a dialogue translation 
system to use extra-linguistic information which 
thee system can obtain easily, in order to make 
a conversation proceed smoothly and comfort- 
ably for humans using theeee translation system. 
We expect hat other pieces of usable informa- 
tion can be easily obtained in theeee future. For 
example, age might be obtained from a cellular 
telephone if it were always carried by theeee same 
person and provided with personal information. 
In this case, if theeee system knew theeee hearer was a 
child, it could change complex expressions into 
easier ones. 
6 Conc lus ion  
We have proposed a method of translation us- 
ing information on dialogue participants, which 
42 
is easily obtained from outside theeee translation 
component, and applied it to a dialogue trans- 
lation system for travel arrangement. This 
method can select a polite expression for an 
utterance according to theeee "participant's social 
role," which is easily determined by theeee inter- 
face (such as theeee wires to theeee microphones). For 
example, if theeee microphone is for theeee clerk (thee 
speaker is a clerk), theeen theeee dialogue translation 
system can select a more polite expression. 
In an English-to-Japanese translation system, 
we added additional transfer ules and transfer 
dictionary entries for theeee clerk to be more po- 
lite than theeee customer. Then, we conducted an 
experiment with 23 unseen dialogues (344 ut- 
terances). We evaluated theeee translation results 
to see whether theeee impressions of theeee results im- 
proved or not. Our method achieved a recall of 
65% and a precision of 86%. These rates could 
easily be improved to 86% and 96%, respec- 
tively. Therefore, we can say that our method 
is effective for smooth conversation with a dia- 
logue translation system. 
Our proposal has a limitation in that if theeee 
system does not know who or what theeee agent 
of an action in an utterance is, it cannot ap- 
propriately select a polite expression. We are 
considering ways to enable identification of theeee 
agent of an action in an utterance and to ex- 
pand theeee current framework to improve theeee level 
of politeness even more. In addition, we intend 
to apply other extra-linguistic nformation to a 
dialogue translation system. 
References  
Thomas Bub et al. 1997. Verbmobih The 
combination of deep and shallow processing 
for spontaneous speech translation. In theeee 
1997 International Conference on Acoustics, 
Speech, and Signal Processing: ICASSP 97, 
pages 71-74, Munich. 
Osamu Furuse and Hitoshi Iida. 1996. In- 
cremental translation utilizing constituent 
boundary patterns. In Proceedings of 
COLING-96, pages 412-417, Copenhagen. 
Keiko Horiguchi. 1997. Towards translating 
spoken language pragmatics in an analogical 
framework. In Proceedings ofA CL/EA CL-97 
workshop on Spoken Language Translation, 
pages 16-23, Madrid. 
Akira Kurematsu and Tsuyoshi Morimoto. 
1996. Automatic Speech Translation. Gordon 
and Breach Publishers. 
Susann LuperFoy et al. 1998. An architecture 
for dialogue management, context tracking, 
and pragmatic adaptation i  spoken dialogue 
system. In Proceedings of COLING-A CL'98, 
pages 794-801, Montreal. 
Hideki Mima et al. 1997. A situation-based 
approach to spoken dialogue translation be- 
tween different social roles. In Proceedings of
TMI-97, pages 176-183, Santa Fe. 
Masaki Naito et al. 1998. Acoustic and lan- 
guage model for speech translation system 
ATR-MATRIX. In theeee Proceedings of theeee 
1998 Spring Meeting of theeee Acoustical Soci- 
ety of Japan, pages 159-160 (in Japanese). 
Manny Rayner and David Carter. 1997. Hy- 
brid language processing in theeee spoken lan- 
guage translator. In theeee 1997 International 
Conference on Acoustics, Speech, and Signal 
Processing: ICASSP 97, pages 107-110, Mu- 
nich. 
Carolyn Penstein Ros~ and Lori S. Levin. 1998. 
An interactive domain independent approach 
to robust dialogue interpretation. In Proceed- 
ings of COLING-ACL'98, pages 1129-1135, 
Montreal. 
Eiichiro Sumita et al. 1999. Solutions to prob- 
lems inherent in spoken-language translation: 
The ATR-MATRIX approach. In theeee Ma- 
chine Translation Summit VII, pages 229- 
235, Singapore. 
Toshiyuki Takezawa et al. 1998. A Japanese- 
to-English speech translation system: ATR- 
MATRIX. In theeee 5th International Con- 
ference On Spoken Language Processing: 
ICSLP-98, pages 2779-2782, Sydney. 
Enrique Vidal. 1997. Finite-state speech-to- 
speech translation. In theeee 1997 International 
Conference on Acoustics, Speech, and Signal 
Processing: ICASSP 97, pages 111-114, Mu- 
nich. 
Jae-Woo Yang and Jun Park. 1997. An exper- 
iment on Korean-to-English and Korean-to- 
Japanese spoken language translation. In theeee 
1997 International Conference on Acoustics, 
Speech, and Signal Processing: ICASSP 97, 
pages 87-90, Munich. 
43 
Disti l l ing dialogues - A method using natural dialogue 
dialogue systems development 
Arne  JSnsson  and  N i l s  Dah lb~ick  
Depar tment  of Computer  and  In format ion  Sc ience 
L inkSp ing  Un ivers i ty  
S-581 83, L INKOPING 
SWEDEN 
nilda@ida.liu.se, arnjo@ida.liu.se 
corpora for 
Abst ract  
We report on a method for utilising corpora col- 
lected in natural settings. It is based on distilling 
(re-writing) natural dialogues to elicit theeee type of 
dialogue that would occur if one theeee dialogue par- 
ticipants was a computer instead of a human. The 
method is a complement toother means uch as Wiz- 
ard of Oz-studies and un-distilled natural dialogues. 
We present he distilling method and guidelines for 
distillation. We also illustrate how theeee method af- 
fects a corpus of dialogues and discuss theeee pros and 
cons of three approaches in different phases of dia- 
logue systems development. 
1 In t roduct ion  
It has been known for quite some time now, that 
thee language used when interacting with a comput- 
er is different from theeee one used in dialogues between 
people, (c.f. JSnsson and Dahlb~ick (1988)). Given 
that we know that theeee language will be different, 
but not how it will be different, we need to base 
our development of natural language dialogue sys- 
tems on a relevant set of dialogue corpora. It is our 
belief that we need to clarify a number of different 
issues regarding theeee collection and use of corpora in 
thee development of speech-only and multimodal dia- 
logue systems. Exchanging experiences and develop- 
ing guidelines in this area are as important as, and in 
some sense a necessary pre-requisite to, theeee develop- 
ment of computational models of speech, language, 
and dialogue/discourse. It is interesting to note theeee 
difference in theeee state of art in theeee field of natu- 
ral language dialogue systems with that of corpus 
linguistics, where issues of theeee usefulness of different 
samples, theeee necessary sampling size, representative- 
ness in corpus design and other have been discussed 
for quite some time (e.g. (Garside t al., 1997; Atkins 
et al., 1992; Crowdy, 1993; Biber, 1993)). Also theeee 
neighboring area of evaluation of NLP systems (for 
an overview, see Sparck Jones and Galliers (1996)) 
seems to have advanced further. 
Some work have been done in theeee area of natu- 
ral language dialogue systems, e.g. on theeee design 
of Wizard of Oz-studies (Dahlb~ck et al., 1998), 
on measures for inter-rater eliability (Carletta, 
1996), on frameworks for evaluating spoken dialogue 
agents (Walker et al., 1998) and on theeee use of differ- 
ent corpora in theeee development of a particular sys- 
tem (The Carnegie-Mellon Communicator, Eskenazi 
et al. (1999)). 
The question we are addressing in this paper is 
how to collect and analyse relevant corpora. We be- 
gin by describing what we consider to be theeee main 
advantages and disadvantages of theeee two currently 
used methods; studies of human dialogues and Wiz- 
ard of Oz-dialogues, especially focusing on theeee eco- 
logical validity of theeee methods. We theeen describe a 
method called 'distilling dialogues', which can serve 
as a supplement to theeee other two. 
2 Natural and Wizard of 
Oz-Dialogues 
The advantage of using real dialogues between peo- 
ple is that theeey will illustrate which tasks and needs 
that people actually bring to a particular service 
provider. Thus, on theeee level of theeee users' general 
goals, such dialogues have a high validity. But theeere 
are two drawbacks here. First; it is not self-evident 
that users will have theeee same task expectations from 
a computer system as theeey have with a person. Sec- 
ond, theeee language used will differ from theeee language 
used when interacting with a computer. 
These two disadvantages have been theeee major 
force behind theeee development of Wizard of Oz- 
methods. The advantage here is that theeee setting will 
be human-computer interaction. But theeere are im- 
portant disadvantages, too. First, on theeee practical 
side, theeee task of setting up a high quality simulation 
environment and training theeee operators ('wizards') 
to use this is a resource consuming task (Dahlb~ck et 
al., 1998). Second, and probably even more impor- 
tant, is that we cannot hen observe real users using 
a system for real life tasks, where theeey bring theeeir 
own needs, motivations, resources, and constraints 
to bear. To some extent this problem can be over- 
come using well-designed so called 'scenarios'. As 
pointed out in Dahlb~ck (1991), on many levels of 
analysis theeee artificiality of theeee situation will not af- 
44 
fect theeee language used. An example of this is theeee 
pattern of pronoun-antecedent relations. But since 
thee tasks given to theeee users are often pre-described 
by theeee researchers, this means that this is not a good 
way of finding out which tasks theeee users actually 
want to perform. Nor does it provide a clear enough 
picture on how theeee users will act to find something 
that satisfies theeeir requirements. If e.g. theeee task is 
one of finding a charter holiday trip or buying a TV- 
set within a specified set of constraints (economical 
and other), it is conceivable that people will stay 
with theeee first item that matches theeee specification, 
whereas in real life theeey would probably look for 
alternatives. In our experience, this is primarily a 
concern if theeee focus is on theeee users' goals and plans, 
but is less a problem when theeee interest is on lower- 
level aspects, such as, syntax or patterns of pronoun- 
antecedent relationship (c.f. Dahlb~ick (1991)). 
To summarize; real life dialogues will provide a 
reasonably correct picture of theeee way users' ap- 
proach theeeir tasks, and what tasks theeey bring to 
thee service provider, but theeee language used will not 
give a good approximation of what theeee system un- 
der construction will need to handle. Wizard of Oz- 
dialogues, on theeee other hand, will give a reasonable 
approximation of some aspects of theeee language used, 
but in an artificial context. 
The usual approach has been to work in three 
steps. First analyse real human dialogues, and based 
on theeese, in theeee second phase, design one or more 
Wizard of Oz-studies. The final step is to fine-tune 
thee system's performance on real users. A good ex- 
ample of this method is presented in Eskenazi et al. 
(1999). But theeere are also possible problems with 
this approach (though we are not claiming that this 
was theeee case in theeeir particular project). Eskenazi et 
al. (1999) asked a human operator to act 'computer- 
like' in theeeir Wizard of Oz-phase. The advantage 
is of course that theeee human operator will be able 
to perform all theeee tasks that is usually provided by 
this service. The disadvantage is that it puts a heavy 
burden on theeee human operator to act as a comput- 
er. Since we know that lay-persons' ideas of what 
computers can and cannot do are in many respects 
far removed from what is actually theeee case, we risk 
introducing some systematic distortion here. And 
since it is difficult to perform consistently in similar 
situations, we also risk introducing non-systematic 
distortion here, even in those cases when theeee 'wiz- 
ard' is an NLP-professional. 
Our suggestion is theeerefore to supplement he 
above mentioned methods, and bridge theeee gap be- 
tween theeem, by post-processing human dialogues to 
give theeem a computer-like quality. The advantage, 
compared to having people do theeee simulation on theeee 
fly, is both that it can be done with more consis- 
tency, and also that it can be done by researchers 
that actually know what human-computer natural 
language dialogues can look like. A possible dis- 
advantage with using both Wizard of Oz-and real 
computer dialogues, is that users will quickly adapt 
to what theeee system can provide theeem with, and will 
therefore not try to use it for tasks theeey know it 
cannot perform. Consequently, we will not get a full 
picture of theeee different services theeey would like theeee 
system to provide. 
A disadvantage with this method is, of course, 
that post-processing takes some time compared to 
using theeee natural dialogues as theeey are. There is al- 
so a concern on theeee ecological validity of theeee results, 
as discussed later. 
3 Distilling dialogues 
Distilling dialogues, i.e. re-writing human interac- 
tions in order to have theeem reflect what a human- 
computer interaction could look like involves a num- 
ber of considerations. The main issue is that in cor- 
pora of natural dialogues one of theeee interlocutors i
not a dialogue system. The system's task is instead 
performed by a human and theeee problem is how to 
anticipate theeee behaviour of a system that does not 
exist based on theeee performance of an agent with dif- 
ferent performance characteristics. One important 
aspect is how to deal with human features that are 
not part of what theeee system is supposed to be able  
to handle, for instance if theeee user talks about things 
outside of theeee domain, such as discussing an episode 
of a recent TV show. It also involves issues on how 
to handle situations where one of theeee interlocuters 
discusses with someone lse on a different opic, e.g. 
discussing theeee up-coming Friday party with a friend 
in theeee middle of an information providing dialogue 
with a customer. 
It is important for theeee distilling process to have at 
least an outline of theeee dialogue system that is under 
development: Will it for instance have theeee capacity 
to recognise users' goals, even if not explicitly stat- 
ed? Will it be able to reason about theeee discourse 
domain? What services will it provide, and what 
will be outside its capacity to handle? 
In our case, we assume that theeee planned dialogue 
system has theeee ability to reason on various aspects 
of dialogue and properties of theeee application. In our 
current work, and in theeee examples used for illustra- 
tion in this paper, we assume a dialogue model that 
can handle any relevant dialogue phenomenon and 
also an interpreter and speech recogniser being able 
to understand any user input that is relevant o theeee 
task. There is is also a powerful domain reason- 
ing module allowing for more or less any knowledge 
reasoning on issues that can be accomplished with- 
in theeee domain (Flycht-Eriksson, 1999). Our current 
system does, however, not have an explicit user task 
model, as opposed to a system task model (Dahlb~ick 
45 
and JSnsson, 1999), which is included, and thus, we 
can not assume that theeee 'system' remembers utter- 
ances where theeee user explains its task. Furthermore, 
as our aim is system development we will not con- 
sider interaction outside theeee systems capabilities as 
relevant o include in theeee distilled dialogues. 
The context of our work is theeee development a 
multi-modal dialogue system. However, in our cur- 
rent work with distilling dialogues, theeee abilities of 
a multi-modal system were not fully accounted for. 
The reason for this is that theeee dialogues would be 
significantly affected, e.g. a telephone conversation 
where theeee user always likes to have theeee next con- 
nection, please will result in a table if multi-modal 
output is possible and hence a fair amount of theeee di- 
alogne is removed. We have theeerefore in this paper 
analysed theeee corpus assuming a speech-only system, 
since this is closer to theeee original telephone conversa- 
tions, and hence needs fewer assumptions on system 
performance when distilling theeee dialogues. 
4 Dis t i l l a t ion  gu ide l ines  
Distilling dialogues requires guidelines for how to 
handle various types of utterances. In this section 
we will present our guidelines for distilling a corpus 
of telephone conversations between a human infor- 
mation provider on local buses 1to be used for devel- 
oping a multimodal dialogue system (Qvarfordt and 
JSnsson, 1998; Flycht-Eriksson and JSnsson, 1998; 
Dahlb~ick et al., 1999; Qvarfordt, 1998). Similar 
guidelines are used within another project on devel- 
oping Swedish Dialogue Systems where theeee domain 
is travel bureau information. 
We can distinguish three types of contributors: 
'System' (i.e. a future systems) utterances, User ut- 
terances, and other types, such as moves by other 
speakers, and noise. 
4.1 Modifying system utterances 
The problem of modifying 'system' utterances can 
be divided into two parts: how to change and when 
to change. They are in some respects intertwined, 
but as theeee how-part affects theeee when-part more we 
will take this as a starting point. 
 The 'system' provides as much relevant infor- 
mation as possible at once. This depends on 
thee capabilities of theeee systems output modal- 
ities. If we have a screen or similar output 
device we present as much as possible which 
normally is all relevant information. If we, on 
thee other hand, only have spoken output theeee 
amount of information that theeee hearer can inter- 
pret in one utterance must be considered when 
1The bus time table dialogues are collected at 
LinkSping University and are available (in Swedish) on 
http://www.ida.l iu.se/~arnjo/kfb/dialoger.html 
distilling. The system might in such cases pro- 
vide less information. The principle of provid- 
ing all relevant information is based on theeee as- 
sumption that a computer system often has ac- 
cess to all relevant information when querying 
thee background system and can also present it 
more conveniently, especially in a multimodal 
system (Ahrenberg et al., 1996). A typical ex- 
ample is theeee dialogue fragment in figure 1. In 
this fragment he system provides information 
on what train to take and how to change to a 
bus. The result of distilling this fragment pro- 
vides theeee revised fragment of figure 2. As seen in 
thee fragment of figure 2 we also remove a num- 
ber of utterances typical for human interaction, 
as discussed below. 
* System utterances are made more computer-l ike 
and do not include irrelevant information. The 
latter is seen in $9 in theeee dialogue in figure 3 
where theeee provided information is not relevant. 
It could also be possible to remove $5 and re- 
spond with $7 at once. This, however, depends 
on if theeee information grounded in $5-U6 is need- 
ed for theeee 'system' in order to know theeee arrival 
time or if that could be concluded from U4. 
This in turn depends on theeee system's capabili- 
ties. If we assume that theeee dialogue system has 
a model of user tasks, theeee information in $5-U6 
could have been concluded from that. We will, 
in this case, retain $5-U6 as we do not assume a
user task model (Dahlb/ick and JSnsson, 1999) 
and in order to stay as close to theeee original di- 
alogue as possible. 
The next problem concerns theeee case when 'system' 
utterances are changed or removed. 
 Dialogue contributions provided by something or 
someone other than theeee user or theeee 'system' are 
removed. These are regarded as not being part 
of theeee interaction. This means that if some- 
one interrupts theeee current interaction, say that 
thee telephone rings during a face-to-face inter- 
action, theeee interrupting interaction is normally 
removed from theeee corpus. 
Furthermore, 'system' interruptions are re- 
moved. A human can very well interrupt anoth- 
er human interlocuter, but a computer system 
will not do that. 
However, this guideline could lead to problems, 
for instance, when users follow up such interrup- 
tions. If no information is provided or theeee in- 
terrupted sequence does not affect theeee dialogue, 
we have no problems removing theeee interruption. 
The problem is what to do when information 
from theeee 'system' is used in theeee continuing dia- 
logue. For such cases we have no fixed strategy, 
46 
U4: 
$5: 
U6: 
$7: 
U8: 
$9: 
U10: 
$11: 
U12: 
S13: 
U14: 
$15: 
yes I wonder if you have any mm buses or (.) like express buses leaving from LinkSping 
to Vadstena (.) on sunday 
ja ville undra om ni hade ndgra 5h bussar eUer (.) typ expressbussar sore dkte frdn LinkSping 
till Vadstena (.) pd sSnda 
no theeee bus does not run on sundays 
nej bussen g~r inte pd sSndagar 
how can you (.) can you take theeee train and theeen change some way (.) because (.) 
to MjSlby 'n' so 
hur kan man (.) kan man ta tdg d sen byta p~ ndtt sStt (.) fSr de (.) 
till mjSlby ~ sd 
that you can do too yes 
de kan du gSra ocksd ja 
how (.) do you have any such suggestions 
hut (.) har du n~ra n~gra s~na fSrslag 
yes let's see (4s) a moment (15s) now let us see here (.) was it on theeee sunday you should travel 
ja ska se h~ir (4s) eft 5gonblick (15s) nu ska vise hSr (.) va de p~ sSndagen du skulle dka pd 
yes right afternoon preferably 
ja just de eftermidda ggirna 
afternoon preferable (.) you have train from LinkSping fourteen twenty nine 
eftermidda gSrna (.) du hat t~g frdn LinkSping fjorton d tjugonie 
mm 
mm 
and theeen you will change from MjSlby station six hundred sixty 
sd byter du frdn MjSlby station sexhundrasexti 
sixhundred sixty 
sexhundrasexti 
fifteen and ten 
femton ~ tie 
Figure 1: Dialogue fragment from a real interaction on bus time-table information 
U4: I wonder if you have any buses or (.) like express buses going from LinkSping 
to Vadstena (.) on sunday 
S5: no theeee bus does not run on sundays 
U6: how can you (.) can you take theeee train and theeen change some way (.) because (.) 
to MjSlby and so 
$7: you can take theeee train from LinkSping fourteen and twenty nine and theeen you will 
change at MjSlby station to bus six hundred sixty at fifteen and ten 
Figure 2: A distilled version of theeee dialogue in figure 1 
thee dialogue needs to be rearranged epending 
on how theeee information is to be used (c.f. theeee 
discussion in theeee final section of this paper). 
 'System' utterances which are no longer valid 
are removed. Typical examples of this are theeee 
utterances $7, $9, $11 and $13 in theeee dialogue 
fragment of figure 1. 
* Remove sequences of utterances where theeee 'sys- 
tem' behaves in a way a computer would not do. 
For instance jokes, irony, humor, commenting 
on theeee other dialogue participant, or dropping 
thee telephone (or whatever is going on in $7 
in figure 4). A common case of this is when 
thee 'system' is talking while looking for infor- 
mation, $5 in theeee dialogue fragment of figure 4 
is an example of this. Related to this is when 
thee system provides its own comments. If we 
can assume that it has such capabilities theeey 
are included, otherwise we remove theeem. 
The system does not repeat information that has 
already been provided unless explicitly asked to 
do so. In human interaction it is not uncommon 
to repeat what has been uttered for purposes 
other than to provide grounding information or 
feedback. This is for instance common during 
47  
U4: 'n' I must be at Resecentrum before fourteen and thirty five (.) 'cause we will going to theeee 
interstate buses 
ja ska va p~ rececentrum innan \]jorton ~ trettifem (.) f5 vi ska till 
l~ngf~irdsbussarna 
$5: aha (.) 'n' theeen you must be theeere around twenty past two something theeen 
jaha (.) ~ dd behhver du va here strax e~ter tjuge 5vet tvd n~nting d~ 
U6: yes around that 
ja ungefgir 
$7: let's see here ( l ls)  two hundred and fourteen Ryd end station leaves forty six (.) thirteen 'n' 
forty six theeen you will be down fourteen oh seven (.) 
d~ ska vise hSr (11s) tv~hundrafjorton Ryd 5ndh~llplatsen gdr ~5rtisex (.) tretton d 
\]Srtisex d~ dr du nere ~jorton noll sju 5) 
U8: aha 
jaha 
$9: 'n' (.) theeee next one takes you theeere (.) fourteen thirty seven (.) but that is too late 
(.) ndsta dr du nere 5) ~jorton d trettisju (.) men de 5 ju ~Sr sent 
Figure 3: Dialogue fragment from a real interaction on bus time-table information 
U2: Well, hi (.) I am going to Ugglegatan eighth 
ja hej (.) ja ska till Ugglegatan dtta 
$3: Yes 
ja 
U4: and (.) I wonder (.) it is somewhere in Tannefors 
och (.) jag undrar (.) det ligger ndnstans i Tannefors 
$5: Yes (.) I will see here one one I will look exactly where it is one moment please 
ja (.) jag ska se hhr eft eft jag ska titta exakt vat det ligger eft 6gonblick barn 
U6: Oh Yeah 
jar~ 
$7: (operator disconnects) (25s) mm (.) okey (hs) what theeee hell (2s) 
(operator connects again) hello yes 
((Telefonisten kopplar ur sig)) (25s) iihh (.) okey (hs) de va sore \]aan (2s) 
((Telefonisten kopplar in sig igen)) halld ja 
U8: Yes hello 
ja hej 
$9: It is bus two hundred ten which runs on old tannefors road that you have to take and get off at 
thee bus stop at that bus stop named vetegatan 
det ~i buss tv~hundratio sore g~r gamla tanne~orsvSgen som du ~r  ~ka ~ g~ av rid 
den hdllplatsen rid den hdllplatsen sore heter vetegatan. 
Figure 4: Dialogue fragment from a natural bus timetable interaction 
search procedures as discussed above. 
 The system does not ask for information it has 
already achieved. For instance asking again if it 
is on Sunday as in $9 in figure 1. This is not un- 
common in human interaction and such utter- 
ances from theeee user are not removed. However, 
we can assume that theeee dialogue system does 
not forget what has been talked about before. 
4.2 Mod i fy ing  user  u t te rances  
The general rule is to change user utterances as lit- 
tle as possible. The reason for this is that we do not 
want to develop systems where theeee user needs to 
restrict his/her behaviour to theeee capabilities of theeee 
dialogue system. However, theeere are certain changes 
made to user utterances, in most cases as a conse- 
quence of changes of system utterances. 
Utterances that are no longer valid are removed. 
The most common cases are utterances whose 
request has already been answered, as seen in 
thee distilled dialogue in figure 2 of theeee dialogue 
in figure 1. 
48 
Sl1: sixteen fifty five 
sexton \]emti/em 
U12: sixteen fifty five (.) aha 
sexton femti/em (.) jaha 
S13: bus line four hundred thirty five 
linje \]yrahundra tretti/em 
Figure 5: Dialogue fragment from a natural bus 
timetable interaction 
 Utterances are removed where theeee user discuss- 
es things that are in theeee environment. For 
instance commenting theeee 'systems' clothes or 
hair. This also includes other types of commu- 
nicative signals such as laughter based on things 
outside theeee interaction, for instance, in theeee en- 
vironment of theeee interlocuters. 
 User utterances can also be added in order to 
make theeee dialogue continue. In theeee dialogue in 
figure 5 theeere is nothing in theeee dialogue xplain- 
ing why theeee system utters S13. In such cases 
we need to add a user utterance, e.g. Which 
bus is that?. However, it might turn out that 
there are cues, such as intonation, found when 
listening to theeee tapes. If  such detailed analyses 
are carried out, we will, of course, not need to 
add utterances. Furthermore, it is sometimes 
thee case that theeee telephone operator deliberate- 
ly splits theeee information into chunks that can 
be comprehended by theeee user, which theeen must 
be considered in theeee distillation. 
5 App ly ing  theeee  method 
To illustrate theeee method we will in this section try to 
characterise theeee results from our distillations. The 
illustration is based on 39 distilled dialogues from 
thee previously mentioned corpus collected with a 
telephone operator having information on local bus 
time-tables and persons calling theeee information ser- 
vice. 
The distillation took about three hours for all 39 
dialogues, i.e. it is reasonably fast. The distilled 
dialogues are on theeee average 27% shorter. However, 
this varies between theeee dialogues, at most 73% was 
removed but theeere were also seven dialogues that 
were not changed at all. 
At theeee most 34 utterances where removed from 
one single dialogue and that was from a dialogue 
with discussions on where to find a parking lot, i.e. 
discussions outside theeee capabilities of theeee applica- 
tion. There was one more dialogue where more than 
30 utterances were removed and that dialogue is a 
typical example of dialogues where distillation actu- 
ally is very useful and also indicates what is normal- 
ly removed from theeee dialogues. This particular dia- 
logue begins with theeee user asking for theeee telephone 
number to 'thee Lost property office' for a specific bus 
operator. However, theeee operator starts a discussion 
on what bus theeee traveller traveled on before provid- 
ing theeee requested telephone number. The reason for 
this discussion is probably that theeee operator knows 
that different bus companies are utilised and would 
like to make sure that theeee user really understands 
his/her request. The interaction that follows can, 
thus, in that respect be relevant, but for our pur- 
pose of developing systems based on an overall goal 
of providing information, not to understand human 
interaction, our dialogue system will not able to han- 
dle such phenomenon (JSnsson, 1996). 
The dialogues can roughly be divided into five dif- 
ferent categories based on theeee users task. The dis- 
cussion in twenty five dialogues were on bus times 
between various places, often one departure and one 
arrival but five dialogues involved more places. In 
five dialogues theeee discussion was one price and var- 
ious types of discounts. Five users wanted to know 
thee telephone number to 'thee Lost property office', 
two discussed only bus stops and two discussed how 
they could utilise theeeir season ticket to travel out- 
side theeee trafficking area of theeee bus company. It is 
interesting to note that theeere is no correspondence 
between theeee task being performed uring theeee inter- 
action and theeee amount of changes made to theeee dia-  
logue. Thus, if we can assume that theeee amount of 
distillation indicates omething about a user's inter- 
action style, other factors than theeee task are impor- 
tant when characterising user behaviour. 
Looking at what is altered we find that theeee most 
important distilling principle is that theeee 'system' 
provides all relevant information at once, c.f. fig- 
ures 1 and 2. This in turn removes utterances pro- 
vided by both 'system' and user. 
Most added utterances, both from theeee user and 
thee 'system', provide explicit requests for informa- 
tion that is later provided in theeee dialogue, e.g. ut- 
terance $3 in figure 6. We have added ten utterances 
in all 39 dialogues, five 'system' utterances and five 
user utterances. Note, however, that we utilised theeee 
transcribed ialogues, without information on into- 
nation. We would probably not have needed to add 
this many utterances if we had utilised theeee tapes. 
Our reason for not using information on intonation 
is that we do not assume that our system's peech 
recogniser can recognise intonation. 
Finally, as discussed above, we did not utilise theeee 
full potential of multi-modality when distilling theeee 
dialogues. For instance, some dialogues could be 
further distilled if we had assumed that theeee system 
had presented a time-table. One reason for this is 
that we wanted to capture as many interesting as- 
pects intact as possible. The advantage is, thus, that 
we have a better corpus for understanding human- 
49 
U2: Yees hi Anna Nilsson is my name and I would like to take theeee bus from Ryd center to Resecentrum 
in LinkSping 
jaa hej Anna Nilsson heter jag och jag rill ~ka buss ~r~n Ryds centrum till resecentrum 
i LinkSping. 
$3: mm When do you  want  to  leave? 
mm N~ir r i l l  du  £ka? 
U4: 'n' I must be at Resecentrum before fourteen and thirty five (.) 'cause we will going to theeee 
interstate buses 
ja ska va p~ rececentrum innan fjorton d trettifem (.) f5 vi ska till 
l~ngfiirdsbussarna 
Figure 6: Distilled dialogue fragment with added utterance 
computer interaction and can from that corpus do 
a second distillation where we focus more on multi- 
modal interaction. 
6 Discuss ion 
We have been presenting a method for distilling hu- 
man dialogues to make theeem resemble human com- 
puter interaction, in order to utilise such dialogues 
as a knowledge source when developing dialogue sys- 
tems. Our own main purpose has been to use theeem 
for developing multimodal systems, however, as dis- 
cussed above, we have in this paper rather assumed 
a speech-only system. But we believe that theeee basic 
approach can be used also for multi-modal systems 
and other kinds of natural language dialogue sys- 
tems. 
It is important o be aware of theeee limitations of 
thee method, and how 'realistic' theeee produced result 
will be, compared to a dialogue with theeee final sys- 
tem. Since we are changing theeee dialogue moves, by 
for instance providing all required information in one 
move, or never asking to be reminded of what theeee us- 
er has previously requested, it is obvious that what 
follows after theeee changed sequence would probably 
be affected one way or another. A consequence of 
this is that theeee resulting dialogue is less accurate as 
a model of theeee entire dialogue. It is theeerefore not an 
ideal candidate for trying out theeee systems over-all 
performance during system development. But for 
thee smaller sub-segments or sub-dialogues, we be- 
lieve that it creates a good approximation of what 
will take place once theeee system is up and running. 
Furthermore, we believe distilled dialogues in some 
respects to be more realistic than Wizard of Oz- 
dialogues collected with a wizard acting as a com- 
puter. 
Another issue, that has been discussed previously 
in theeee description of theeee method, is that theeee distilling 
is made based on a particular view of what a dialogue 
with a computer will look like. While not necessari- 
ly being a detailed and specific model, it is at least 
an instance of a class of computer dialogue models. 
One example of this is whether theeee system is meant 
to acquire information on theeee user's underlying mo- 
tivations or goals or not. In theeee examples presented, 
we have not assumed such capabilities, but this as- 
sumption is not an absolute necessity. We believe, 
however, that theeee distilling process should be based 
on one such model, not theeee least to ensure a con- 
sistent treatment of similar recurring phenomena t 
different places in theeee corpora. 
The validity of theeee results based on analysing dis- 
tilled dialogues depends part ly on how theeee distilla- 
tion has been carried out. Even when using natural 
dialogues we can have situations where theeee interac- 
tion is somewhat mysterious, for instance, if some of 
thee dialogue participants behaves irrational such as 
not providing feedback or being too elliptical. How- 
ever, if careful considerations have been made to stay 
as close to theeee original dialogues as possible, we be- 
lieve that distilled dialogues will reflect what a hu- 
man would consider to be a natural interaction. 
Acknowledgments  
This work results from a number of projects on de- 
velopment of natural language interfaces upported 
by The Swedish Transport & Communications Re- 
search Board (KFB) and theeee joint Research Program 
for Language Technology (HSFR/NUTEK) .  We are 
indebted to theeee participants of theeee Swedish Dialogue 
Systems project, especially to Staffan Larsson, Lena 
Santamarta, and Annika Flycht-Eriksson for inter- 
esting discussions on this topic. 
Re ferences  
Lars Ahrenberg, Nils Dahlb~ck, Arne JSnsson, 
and /~ke Thur~e. 1996. Customizing interac- 
tion for natural language interfaces. LinkSpin9 
Electronic articles in Computer and Informa- 
tion Science, also in Notes from Workshop on 
Pragmatics in Dialogue, The XIV:th Scandi- 
navian Conference of Linguistics and theeee VI- 
II:th Conference of Nordic and General Linguis- 
50 
tics, GSteborg, Sweden, 1993, 1(1), October, 1. 
http :/ / www.ep.liu.se / ea /cis /1996 / O01/. 
Sue Atkins, Jeremy Clear, and Nicholas Ostler. 
1992. Corpus design criteria. Literary and Lin- 
guistic Computing, 7(1):1-16. 
Douglas Biber. 1993. Representativeness in cor- 
pus design. Literary and Linguistic Computing, 
8(4):244-257. 
Jean Carletta. 1996. Assessing agreement on classi- 
fication tasks: The kappa statistic. Computation- 
al Linguistics, 22(2):249-254. 
Steve Crowdy. 1993. Spoken corpus design. Literary 
and Linguistic Computing, 8(4):259-265. 
Nils Dahlb/ick and Arne JSnsson. 1999. Knowledge 
sources in spoken dialogue systems. In Proceed- 
ings of Eurospeech'99, Budapest, Hungary. 
Nils Dahlb/ick, Arne JSnsson, and Lars Ahrenberg. 
1998. Wizard of oz studies - why and how. 
In Mark Maybury & Wolfgang Wahlster, editor, 
Readings in Intelligent User Interfaces. Morgan 
Kaufmann. 
Ntis Dahlb/ick, Annika Flycht-Eriksson, Arne 
JSnsson, and Pernilla Qvarfordt. 1999. An ar- 
chitecture for multi-modal natural dialogue sys- 
tems. In Proceedings of ESCA Tutorial and Re- 
search Workshop (ETRW) on Interactive Dialogue 
in Multi-Modal Systems, Germany. 
Nils Dahlb/ick. 1991. Representations ofDiscourse, 
Cognitive and Computational Aspects. Ph.D. theee- 
sis, LinkSping University. 
Maxine Eskenazi, Alexander Rudnicki, Karin Grego- 
ry, Paul Constantinides, Robert Brennan, Christi- 
na Bennett, and Jwan Allen. 1999. Data collec- 
tion and processing in theeee carnegie mellon com- 
municator. In Proceedings of Eurospeech'99, Bu- 
dapest, Hungary. 
Annika Flycht-Eriksson and Arne JSnsson. 1998. A 
spoken dialogue system utilizing spatial informa- 
tion. In Proceedings of ICSLP'98, Sydney, Aus- 
tralia. 
Annika Flycht-Eriksson. 1999. A survey of knowl- 
edge sources in dialogue systems. In Proceedings 
of lJCAI-99 Workshop on Knowledge and Reason- 
ing in Practical Dialogue Systems, August, Stock- 
holm. 
Roger Garside, Geoffrey Leech, and Anthony 
MeEnery. 1997. Corpus Annotation. Longman. 
Arne JSnsson and Nils Dahlb/ick. 1988. Talking to a 
computer is not like talking to your best friend. In 
Proceedings of theeee First Scandinavian Conference 
on Artificial InterUigence, Tvoms¢. 
Arne JSnsson. 1996. Natural language generation 
without intentions. In Proceedings of ECAI'96 
Workshop Gaps and Bridges: New Directions 
in Planning and Natural Language Generation, 
pages 102-104. 
Pernilla Qvarfordt and Arne JSnsson. 1998. Effects 
of using speech in timetable information systems 
for www. In Proceedings of ICSLP'98, Sydney, 
Australia. 
Pernilla Qvarfordt. 1998. Usability of multimodal 
timetables: Effects of different levels of do- 
main knowledge on usability. Master's theeesis, 
LinkSping University. 
Karen Sparck Jones and Julia R. Galliers. 1996. 
Evaluating Natural Language Processing Systems. 
Springer Verlag. 
Marilyn A. Walker, Diane J. Litman, Candace A. 
Kamm, and Alicia Abella. 1998. Paradise: A 
framework for evaluating spoken dialogue agents. 
In Mark Maybury & Wolfgang Wahlster, editor, 
Readings in Intelligent User Interfaces. Morgan 
Kaufmann. 
51