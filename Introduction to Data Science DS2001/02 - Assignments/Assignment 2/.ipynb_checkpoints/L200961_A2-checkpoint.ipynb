{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWWLTwYZorzC",
    "tags": []
   },
   "source": [
    "# Introduction To Data Science ‚Äì Assignment 2\n",
    "\n",
    "---\n",
    "\n",
    "#### Sections A ‚Äì B ‚Äì C ‚Äì D\n",
    "\n",
    "---\n",
    "\n",
    "## ***Instructions: Read These Carefully Before Starting!***\n",
    "\n",
    "1. Due Date: Thursday 20th October 2022 ‚Äì 11:59PM\n",
    "\n",
    "2. **Name the file in the format Lyyxxxx_A2.ipynb and save it as .ipynb (e.g. L216666_A2.ipynb)**\n",
    "\n",
    "3. Submission will be taken on Google Classroom (**submit SINGLE .ipynb file ONLY**)\n",
    "\n",
    "4. **Assignment will not be evaluated if**:\n",
    "\n",
    "> * You submit python (.py) files\n",
    "> * You submit multiple .ipynb files\n",
    "> * You submit compressed (.rar or .zip) files\n",
    "\n",
    "5. **Work in the spaces provided and do not delete/modify any cells from this template.**\n",
    "\n",
    "6. Upload data files directly to Google Colab - do not use Google Drive or GitHub linking method\n",
    "\n",
    "*Not following these instructions will lead to mark deduction.*\n",
    "\n",
    "---\n",
    "\n",
    "All source files needed to complete this assignment can be found on the following [Google Drive link](https://drive.google.com/drive/folders/1qBib_6ZOhvHb73ZRLWiCMWl9NFyU1IDO?usp=sharing). Download these files and upload them to your Google Colab Notebook. \n",
    "\n",
    "**Do not link Google Drive or GitHub with Colab.**\n",
    "\n",
    "**Do not add these files with your submission on Google Classroom.**\n",
    "\n",
    "---\n",
    "\n",
    "Happy Coding üå∫\n",
    "\n",
    "---\n",
    "\n",
    "TA Emails\n",
    "\n",
    "Section A, C - Muhammad Maarij l192347@lhr.nu.edu.pk\n",
    "\n",
    "Section B, D - Hira Ijaz l192377@lhr.nu.edu.pk\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwtAOew56gkd"
   },
   "source": [
    "---\n",
    "## Question 0\n",
    "\n",
    "Add all library imports here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "swlE8Tvq6g2u"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR8C9ctqsy3V",
    "tags": []
   },
   "source": [
    "---\n",
    "## Question 1\n",
    "\n",
    "#### Single Linear Regression with Gradient Descent\n",
    "\n",
    "> Take help from slides 26 and 30\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzGOilP7sy3Y"
   },
   "source": [
    "**Part A -**\n",
    "Write a function that calculates and returns value for hypothesis $h_\\theta(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3bczSIhosy3Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# complete this function implementation\n",
    "def hypothesis(x):\n",
    "    global theta\n",
    "    return theta[0] + theta[1]*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXORHsxSsy3a"
   },
   "source": [
    "**Part B -**\n",
    "Write a function that calculates and returns value for loss/cost $J(\\theta_0, \\theta_1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "__DPftoLsy3c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# complete this function implementation\n",
    "def loss(x, y):\n",
    "    global theta\n",
    "    m = len(y)\n",
    "    return (1/2*m) * np.sum(np.square(hypothesis(x) - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WjWa6pMGsy3d"
   },
   "source": [
    "**Part C-**\n",
    "Write a function that applies the gradient descent algorithm and updates values of $\\theta_0$ and $\\theta_1$ until they converge.\n",
    "\n",
    "* take default vaue of $Œ±$ to be 0.015\n",
    "* take default number of iterations to be 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "U7qtzuCWsy3e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# complete this function implementation\n",
    "def gradientDescent(x, y, theta, numIterations=1500, alpha=0.015):\n",
    "    m = len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zwvS5cqsy3g"
   },
   "source": [
    "**Part D -**\n",
    "FactoryRevenue.csv contains information about the number of workers in a factory and the annual profit for that factory. Import the file FactoryRevenue.csv as a Pandas DataSet and print out the information for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Uef-aGHisy3h",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99 entries, 0 to 98\n",
      "Data columns (total 2 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   TotalFactoryWorkers  98 non-null     float64\n",
      " 1   AnnualProfit         98 non-null     float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.7 KB\n",
      "None\n",
      "   TotalFactoryWorkers  AnnualProfit\n",
      "0              65894.0       59966.0\n",
      "1              92482.0      121340.0\n",
      "2              58918.0       18495.0\n",
      "3              82111.0       65426.0\n",
      "4              79334.0       45623.0\n"
     ]
    }
   ],
   "source": [
    "fr = pd.read_csv('FactoryRevenue.csv')\n",
    "print(fr.info())\n",
    "print(fr.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E -**\n",
    "Remove rows that have any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    TotalFactoryWorkers  AnnualProfit\n",
      "64                  NaN       43565.0\n",
      "90              12546.0           NaN\n"
     ]
    }
   ],
   "source": [
    "print(fr[fr.isna().any(axis=1)])\n",
    "fr=fr.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0Y68nh87HJX"
   },
   "source": [
    "**Part F -**\n",
    "\n",
    "First identify the independant and dependant variables. \n",
    "\n",
    "Then create two arrays named x and y and add independant variable data to array x, dependant variable data to array y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "m49bbkSy7xxp"
   },
   "outputs": [],
   "source": [
    "# independant variable:\n",
    "# dependant variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vRXmn9z8H4q"
   },
   "source": [
    "**Part G -** \n",
    "\n",
    "Create an array called 'theta' that will hold $Œ∏_0$ and $Œ∏_1$. Initalize both values to 0.\n",
    "\n",
    "Then call the gradientDescent function using array x, array y, and array theta. Do not provide any other input parameters.\n",
    "\n",
    "Print out the values of y-intercept and slope/gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7nBeh3b9KXK"
   },
   "outputs": [],
   "source": [
    "theta = [0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lksKYteB9NOx"
   },
   "source": [
    "**Part H -** Plot a scatter plot and regression line on the same graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jdah8R6L9XSl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upsln2T-38-M"
   },
   "source": [
    "---\n",
    "## Question 2\n",
    "\n",
    "Logistic Regression on Flowers Dataset\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plh_l8AV4MU5"
   },
   "source": [
    "**Part A** - Load the file FlowersData.csv and describe the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "p7Cgq8di3771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sepal_length  sepal_width  petal_length  petal_width\n",
      "count    150.000000   150.000000    150.000000   150.000000\n",
      "mean       5.843333     3.054000      3.758667     1.198667\n",
      "std        0.828066     0.433594      1.764420     0.763161\n",
      "min        4.300000     2.000000      1.000000     0.100000\n",
      "25%        5.100000     2.800000      1.600000     0.300000\n",
      "50%        5.800000     3.000000      4.350000     1.300000\n",
      "75%        6.400000     3.300000      5.100000     1.800000\n",
      "max        7.900000     4.400000      6.900000     2.500000\n",
      "   sepal_length  sepal_width  petal_length  petal_width flower_name\n",
      "0           5.1          3.5           1.4          0.2    hibiscus\n",
      "1           4.9          3.0           1.4          0.2    hibiscus\n",
      "2           4.7          3.2           1.3          0.2    hibiscus\n",
      "3           4.6          3.1           1.5          0.2    hibiscus\n",
      "4           5.0          3.6           1.4          0.2    hibiscus\n"
     ]
    }
   ],
   "source": [
    "fd=pd.read_csv('FlowersData.csv')\n",
    "print(fd.describe())\n",
    "print(fd.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LsiIV9n4QMz"
   },
   "source": [
    "**Part B** - Split data into training and test data using SKLearn train_test_split. Specify parameter test_size to be 25%\n",
    "\n",
    "Hint: You will be needing 4 arrays: X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "f49YQ4GT4k5s"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = fd.drop(columns=['flower_name'])\n",
    "y = fd['flower_name']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ez5Fa2ePDzXu"
   },
   "source": [
    "**Part C** - Perform scaling on the X_test and X_train values using StandardScacler from SKLearn Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "97-2bUgtDzXv"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9BlQYh54lLX"
   },
   "source": [
    "**Part D** - Train Model using SKLearn LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "hD_MUVu64xkw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "loreg = LogisticRegression(random_state = 0)\n",
    "loreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HKhBOzW4xSx"
   },
   "source": [
    "**Part E** - Predict Labels for test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03 0.   0.97]\n",
      " [0.95 0.01 0.04]\n",
      " [0.   1.   0.  ]\n",
      " [0.08 0.   0.92]\n",
      " [0.02 0.98 0.  ]\n",
      " [0.01 0.   0.99]\n",
      " [0.02 0.98 0.  ]\n",
      " [0.71 0.01 0.28]\n",
      " [0.73 0.   0.27]\n",
      " [0.89 0.02 0.08]\n",
      " [0.44 0.   0.56]\n",
      " [0.76 0.02 0.22]\n",
      " [0.85 0.01 0.13]\n",
      " [0.69 0.   0.3 ]\n",
      " [0.75 0.01 0.24]\n",
      " [0.05 0.95 0.  ]\n",
      " [0.72 0.02 0.26]\n",
      " [0.86 0.03 0.11]\n",
      " [0.06 0.94 0.  ]\n",
      " [0.01 0.99 0.  ]\n",
      " [0.17 0.   0.83]\n",
      " [0.71 0.04 0.25]\n",
      " [0.02 0.98 0.  ]\n",
      " [0.04 0.96 0.  ]\n",
      " [0.35 0.   0.65]\n",
      " [0.   1.   0.  ]\n",
      " [0.01 0.99 0.  ]\n",
      " [0.87 0.02 0.11]\n",
      " [0.9  0.09 0.02]\n",
      " [0.03 0.97 0.  ]\n",
      " [0.21 0.   0.79]\n",
      " [0.69 0.06 0.25]\n",
      " [0.02 0.98 0.  ]\n",
      " [0.35 0.   0.65]\n",
      " [0.04 0.   0.96]\n",
      " [0.81 0.07 0.11]\n",
      " [0.03 0.97 0.  ]\n",
      " [0.42 0.   0.58]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = loreg.predict(X_test)\n",
    "probs_list_y= loreg.predict_proba(X_test)\n",
    "probs_list_y=np.round(probs_list_y,2)\n",
    "print(probs_list_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34It-TAowlCw"
   },
   "source": [
    "---\n",
    "## Question 3\n",
    "\n",
    "Confusion Matrix Construction\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vi_ix0XsxF8x"
   },
   "source": [
    "**Part A** - Using the prediction result of logistic regression (Question 2) construct a confusion matrix using SKLearn confusion_matrix\n",
    "\n",
    "Print out this confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "o23T4fDsxD-L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  1]\n",
      " [ 0 13  0]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conmat=confusion_matrix(y_test,y_pred)\n",
    "print (conmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlYB9BY4xEh1"
   },
   "source": [
    "**Part B** - Calculate and print Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cupearHPxUKj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy ',accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvEXBB3CxUk-"
   },
   "source": [
    "**Part C** - Calculate and print Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "PyBufaj8xbKC"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10664/2423054051.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Recall '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1772\u001b[0m     \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \"\"\"\n\u001b[1;32m-> 1774\u001b[1;33m     _, r, _, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1775\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1776\u001b[0m                                                  \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1462\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1464\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1465\u001b[0m                                     pos_label)\n\u001b[0;32m   1466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1292\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m                 \u001b[0maverage_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'samples'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1294\u001b[1;33m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0m\u001b[0;32m   1295\u001b[0m                              \u001b[1;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m                              % (y_type, average_options))\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print('Recall ',recall_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6BgzGjMxbfu"
   },
   "source": [
    "**Part D** - Calculate and print Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHJg8C-1xg_6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print('Precision' , precision_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RPHz7hVxhbk"
   },
   "source": [
    "**Part E** - Calculate and print $ùêπ_1$ Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmwjCpMixmeJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('F1 Score', f1_score(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
